{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLogkosUAH-"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Uqx7woUAIF"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## Pima Diabetes Dataset\n",
        "\n",
        "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvQhWj5UAIF"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Xv268rbuUAIG"
      },
      "outputs": [],
      "source": [
        "#Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B8p6y-7qUAIH"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "C39rLYeaUAIH",
        "outputId": "dc600f54-5d03-47d5-ec98-cfd65f6e544d"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Load in the data set (Internet Access needed)\n",
        "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
        "\n",
        "seed_value = 11111\n",
        "url = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(url, names=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QCr0krluUAIH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ]
        }
      ],
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "# diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "N9gywmErXEpJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "0               6                     148              72              35   \n",
              "1               1                      85              66              29   \n",
              "2               8                     183              64               0   \n",
              "3               1                      89              66              23   \n",
              "4               0                     137              40              35   \n",
              "\n",
              "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "0        0  33.6              0.627   50             1  \n",
              "1        0  26.6              0.351   31             0  \n",
              "2        0  23.3              0.672   32             1  \n",
              "3       94  28.1              0.167   21             0  \n",
              "4      168  43.1              2.288   33             1  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TBnwBgsWUAIH"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values #train features\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AUeCzRaPV4d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rEa33td5UAII"
      },
      "outputs": [],
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "# stratify คือ การกำหนดการกระจายของข้อมูลที่ split ให้มีการกระจายเหมือน original dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OAcXPGFWUAII"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSIknieUAII"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1Q2BRmB1UAII"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=11111)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=seed_value)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uxEybpR4UAII"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.795\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1YR5seGYUAIJ"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MMLGxSUAIJ"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 8 nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uviwG3g_UAIJ"
      },
      "outputs": [],
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qW2ikMYhaZYm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.17553013, -0.88319193, -0.4797748 , ..., -0.41547152,\n",
              "         0.23300528, -0.95829939],\n",
              "       [-1.17553013, -1.35145275,  0.9447112 , ...,  0.60441055,\n",
              "        -0.07457346, -1.04227634],\n",
              "       [-0.58157806, -0.50858328, -0.5815238 , ...,  0.35565882,\n",
              "        -0.73053221, -0.70636856],\n",
              "       ...,\n",
              "       [ 0.60632606, -0.1964094 , -0.4797748 , ...,  0.20640779,\n",
              "        -0.66776104,  0.55328559],\n",
              "       [-0.87855409,  0.86498179, -0.0727788 , ..., -0.340846  ,\n",
              "        -0.34135094,  0.72123948],\n",
              "       [ 1.49725416,  0.95863395,  0.4359662 , ...,  0.26859572,\n",
              "         1.36602495, -0.03455301]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zzAKCitoajRT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.012374  ,  1.02106873,  0.1307192 , ..., -0.09209428,\n",
              "        -0.37587509,  0.30135476],\n",
              "       [ 1.79423019,  0.36550358, -0.0727788 , ..., -0.62691048,\n",
              "        -0.66776104,  0.21737782],\n",
              "       [-0.58157806,  1.64541648,  0.9447112 , ...,  1.54966709,\n",
              "         0.59080097, -0.79034551],\n",
              "       ...,\n",
              "       [ 0.012374  , -0.78953977, -0.6832728 , ..., -1.39804083,\n",
              "        -0.36959797, -0.62239162],\n",
              "       [-0.87855409, -0.29006156,  0.1307192 , ...,  0.29347089,\n",
              "         0.22045105, -0.70636856],\n",
              "       [ 0.9033021 , -0.47736589, -0.4797748 , ..., -0.68909841,\n",
              "        -0.50769455, -0.37046079]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3nIrw2ZEUAIJ"
      },
      "outputs": [],
      "source": [
        "# Define the Model\n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 8 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "import os, random, numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Ha9-w35OUAIJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81 (324.00 Byte)\n",
            "Trainable params: 81 (324.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHF08OSCUAIK"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 81 parameters?  Does that make sense?\n",
        "\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "iQ4Tj8EiUAIK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.8103 - accuracy: 0.4983 - val_loss: 0.7811 - val_accuracy: 0.4844\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7961 - accuracy: 0.5069 - val_loss: 0.7669 - val_accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7828 - accuracy: 0.5260 - val_loss: 0.7536 - val_accuracy: 0.5052\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7703 - accuracy: 0.5399 - val_loss: 0.7412 - val_accuracy: 0.5052\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7585 - accuracy: 0.5503 - val_loss: 0.7295 - val_accuracy: 0.5365\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.5556 - val_loss: 0.7186 - val_accuracy: 0.5573\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7371 - accuracy: 0.5712 - val_loss: 0.7083 - val_accuracy: 0.5885\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7273 - accuracy: 0.5781 - val_loss: 0.6987 - val_accuracy: 0.6042\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7183 - accuracy: 0.5851 - val_loss: 0.6896 - val_accuracy: 0.6406\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.5885 - val_loss: 0.6810 - val_accuracy: 0.6406\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7013 - accuracy: 0.5990 - val_loss: 0.6729 - val_accuracy: 0.6458\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.6059 - val_loss: 0.6652 - val_accuracy: 0.6562\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.6163 - val_loss: 0.6579 - val_accuracy: 0.6562\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.6267 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.6302 - val_loss: 0.6444 - val_accuracy: 0.6719\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.6372 - val_loss: 0.6382 - val_accuracy: 0.6771\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6598 - accuracy: 0.6441 - val_loss: 0.6323 - val_accuracy: 0.6823\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6540 - accuracy: 0.6493 - val_loss: 0.6266 - val_accuracy: 0.6875\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6615 - val_loss: 0.6212 - val_accuracy: 0.6927\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6431 - accuracy: 0.6667 - val_loss: 0.6160 - val_accuracy: 0.7083\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6379 - accuracy: 0.6684 - val_loss: 0.6111 - val_accuracy: 0.7135\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.6701 - val_loss: 0.6064 - val_accuracy: 0.7240\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6283 - accuracy: 0.6736 - val_loss: 0.6018 - val_accuracy: 0.7292\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.6806 - val_loss: 0.5975 - val_accuracy: 0.7396\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.6858 - val_loss: 0.5934 - val_accuracy: 0.7396\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.6858 - val_loss: 0.5894 - val_accuracy: 0.7448\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.6962 - val_loss: 0.5857 - val_accuracy: 0.7552\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6074 - accuracy: 0.6979 - val_loss: 0.5820 - val_accuracy: 0.7552\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.7066 - val_loss: 0.5785 - val_accuracy: 0.7604\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.7101 - val_loss: 0.5752 - val_accuracy: 0.7552\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5967 - accuracy: 0.7118 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5933 - accuracy: 0.7153 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.7170 - val_loss: 0.5660 - val_accuracy: 0.7552\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5871 - accuracy: 0.7188 - val_loss: 0.5631 - val_accuracy: 0.7552\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7240 - val_loss: 0.5604 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7257 - val_loss: 0.5578 - val_accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.7274 - val_loss: 0.5554 - val_accuracy: 0.7552\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.7274 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5734 - accuracy: 0.7257 - val_loss: 0.5507 - val_accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.7292 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5686 - accuracy: 0.7326 - val_loss: 0.5463 - val_accuracy: 0.7552\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7378 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7396 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5619 - accuracy: 0.7396 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7378 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5577 - accuracy: 0.7378 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.7396 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7378 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5519 - accuracy: 0.7378 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7378 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7396 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.7413 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7448 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7465 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7448 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7448 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7448 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7448 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7465 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7483 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7500 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7483 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7517 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7517 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7552 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7569 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7587 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7587 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7569 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7587 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7587 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7604 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7604 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7639 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7656 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.7639 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.7708 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7708 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7726 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7760 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7760 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.7778 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7778 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7778 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7778 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7778 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7778 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7726 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7726 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7448\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7448\n"
          ]
        }
      ],
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, batch_size=32)\n",
        "# the fit function returns the run history.\n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "WJMeGW7MUAIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SsYmQ73OUAIK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bhKNo_5BUAIK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.544924  ],\n",
              "       [0.46085215],\n",
              "       [0.78104424],\n",
              "       [0.15001746],\n",
              "       [0.39762586],\n",
              "       [0.8129517 ],\n",
              "       [0.6315116 ],\n",
              "       [0.15228054],\n",
              "       [0.11431644],\n",
              "       [0.95573366]], dtype=float32)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "n_vOd-upUAIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.745\n",
            "roc-auc is 0.817\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SLVuVLnUAIK"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXfBqaFsUAIL"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xbW5F77kUAIL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11UgwSDSUAIL"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CstB8zXcUAIL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x32107e080>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG5HzDNFUAIL"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "slHFioCFUAIL",
        "outputId": "6a709f3d-230e-4c21-c90a-045dee77cddc",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7448\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7448\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7448\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7448\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7448\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7448\n"
          ]
        }
      ],
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jBy7i6XSUAIL",
        "outputId": "b49a7eac-d8bc-4ff0-d632-3494f7f132e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x30f5fd8a0>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history\n",
        " [\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x696YhRJUAIM"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720x50Nrg7oG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6K5p_8gw0i"
      },
      "source": [
        "**Student Answer:**\n",
        "\n",
        "---\n",
        "จากกราฟ n epoh ที่เหมาะสม คือ 200 เพราะมากกว่านี้  validation loss ก็ไม่ขยับลงแล้ว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CylpfYBYUAIM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp9yOAXQUAIM"
      },
      "source": [
        "# <span style=\"color:blue\">แบบฝึกปฏิบัติ</span>\n",
        "\n",
        "(รวม 100 คะแนน) ให้นิสิตใช้พื้นที่ต่อไปนี้ ในการเพิ่มโค้ดให้เป็นไปตามข้อกำหนดต่อไปนี้\n",
        "1. (50 คะแนน) เพิ่มเซลโค้ด เพื่อ\n",
        "   * สร้างโมเดลที่มีเลเยอร์ hidden 2 ชั้น แต่ละชั้นมี 6 โหนด\n",
        "   * ปรับโค้ดให้สามารถรับอินพุตที่มีจำนวน feature ตามข้อมูลเทรนที่จะถูกส่งเข้ามา (ปราศจากการใช้ค่าคงที่ 8 ที่ถูกระบุอยู่ในโค้ด ณ ตอนนี้)\n",
        "   * สำหรับเลเยอร์ hidden ให้ใช้ activation function เป็น \"relu\" และเลเยอร์ output เป็น \"sigmoid\"\n",
        "   * ใช้ learning rate เท่ากับ 0.003 และเทรนด้วยจำนวน 1500 epochs ส่วนสำหรับ Hyperparameter ที่เหลือให้ใช้ค่าคงเดิม\n",
        "   * วาดกราฟของค่า loss และ accuracy ด้วยทั้งชุดข้อมูล train และ test (ดังตัวอย่างในรูปนี้)\n",
        "  <img src=\"https://drive.google.com/uc?id=1GuN0KQf64rGMa4oCY2upnbOTMzWaXmbT\" style=\"height:360px\">\n",
        "2. (50 คะแนน) เพิ่มอีกเซลโค้ด เพื่อสร้างโมเดลที่มีการปรับโครงสร้างที่เหมาะสมขึ้น รวมถึงการปรับค่า Hyperparameter ต่าง ๆ เพื่อให้โมเดลใหม่ได้ผลลัพธ์ที่ดีขึ้น (โดยพิจารณาจากค่า accuracy) และในการเทรนโมเดลใหม่นี้ ห้ามมีการใช้ Early Stopping\n",
        "   * ให้วาดกราฟของค่า loss และ accuracy ของโมเดลใหม่นี้ด้วย\n",
        "   * อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itoIvUsoh1qX"
      },
      "source": [
        "ข้อ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "kagzZns5jFmJ",
        "outputId": "eba085fd-3da6-47ac-fb90-38025460e1fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(576, 8)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yGLKGsGIh1CF",
        "outputId": "14542370-9c23-42f7-9dd0-7931c529cbaa"
      },
      "outputs": [],
      "source": [
        "model_1n = Sequential([\n",
        "    Dense(6, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "B8gnOFsEjnUp",
        "outputId": "a1280974-4410-40aa-a378-9013046766bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1n.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "r9aHCvg0jwQQ",
        "outputId": "07a03196-ea78-43dd-dfcf-3cefbe6b2bd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        }
      ],
      "source": [
        "# compile new_model_1\n",
        "model_1n.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDSACFWkOMu",
        "outputId": "f474008c-4511-4456-fd90-5dacc06b552a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-20 20:53:01.729863: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.6979 - val_loss: 0.6129 - val_accuracy: 0.7083\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.6944 - val_loss: 0.6100 - val_accuracy: 0.7135\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6011 - accuracy: 0.6962 - val_loss: 0.6072 - val_accuracy: 0.7240\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.6979 - val_loss: 0.6045 - val_accuracy: 0.7240\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.6979 - val_loss: 0.6020 - val_accuracy: 0.7240\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5918 - accuracy: 0.7049 - val_loss: 0.5995 - val_accuracy: 0.7240\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5890 - accuracy: 0.7118 - val_loss: 0.5972 - val_accuracy: 0.7240\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.7101 - val_loss: 0.5949 - val_accuracy: 0.7240\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.7118 - val_loss: 0.5928 - val_accuracy: 0.7344\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5810 - accuracy: 0.7135 - val_loss: 0.5907 - val_accuracy: 0.7292\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.7135 - val_loss: 0.5887 - val_accuracy: 0.7240\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7170 - val_loss: 0.5867 - val_accuracy: 0.7188\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5739 - accuracy: 0.7240 - val_loss: 0.5849 - val_accuracy: 0.7188\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.7240 - val_loss: 0.5830 - val_accuracy: 0.7188\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7257 - val_loss: 0.5813 - val_accuracy: 0.7188\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5675 - accuracy: 0.7257 - val_loss: 0.5796 - val_accuracy: 0.7188\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5654 - accuracy: 0.7292 - val_loss: 0.5780 - val_accuracy: 0.7135\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5635 - accuracy: 0.7274 - val_loss: 0.5764 - val_accuracy: 0.7188\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7257 - val_loss: 0.5749 - val_accuracy: 0.7240\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7205 - val_loss: 0.5735 - val_accuracy: 0.7240\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7205 - val_loss: 0.5721 - val_accuracy: 0.7240\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5563 - accuracy: 0.7205 - val_loss: 0.5707 - val_accuracy: 0.7240\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7205 - val_loss: 0.5694 - val_accuracy: 0.7188\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7222 - val_loss: 0.5681 - val_accuracy: 0.7135\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7222 - val_loss: 0.5669 - val_accuracy: 0.7135\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7222 - val_loss: 0.5657 - val_accuracy: 0.7135\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7240 - val_loss: 0.5645 - val_accuracy: 0.7135\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7274 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7292 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7274 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7257 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7257 - val_loss: 0.5593 - val_accuracy: 0.7188\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7292 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7274 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7309 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7326 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7326 - val_loss: 0.5547 - val_accuracy: 0.7135\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7378 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7413 - val_loss: 0.5531 - val_accuracy: 0.7083\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7431 - val_loss: 0.5523 - val_accuracy: 0.7083\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7448 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7448 - val_loss: 0.5509 - val_accuracy: 0.7031\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7448 - val_loss: 0.5501 - val_accuracy: 0.7031\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7448 - val_loss: 0.5494 - val_accuracy: 0.6979\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7465 - val_loss: 0.5488 - val_accuracy: 0.6979\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7465 - val_loss: 0.5481 - val_accuracy: 0.6979\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7465 - val_loss: 0.5475 - val_accuracy: 0.7031\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7483 - val_loss: 0.5468 - val_accuracy: 0.7031\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7517 - val_loss: 0.5462 - val_accuracy: 0.7031\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7517 - val_loss: 0.5456 - val_accuracy: 0.6979\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7535 - val_loss: 0.5451 - val_accuracy: 0.6979\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7535 - val_loss: 0.5445 - val_accuracy: 0.6979\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.7517 - val_loss: 0.5439 - val_accuracy: 0.6979\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7031\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7517 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.5423 - val_accuracy: 0.7135\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7483 - val_loss: 0.5418 - val_accuracy: 0.7135\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7483 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5409 - val_accuracy: 0.7188\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7483 - val_loss: 0.5404 - val_accuracy: 0.7188\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7483 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7500 - val_loss: 0.5395 - val_accuracy: 0.7188\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7535 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7517 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7517 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7535 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7535 - val_loss: 0.5370 - val_accuracy: 0.7240\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7535 - val_loss: 0.5366 - val_accuracy: 0.7240\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7535 - val_loss: 0.5362 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7535 - val_loss: 0.5359 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7552 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7569 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7569 - val_loss: 0.5348 - val_accuracy: 0.7344\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7552 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7587 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7587 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7622 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7604 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7639 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7639 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7656 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7691 - val_loss: 0.5311 - val_accuracy: 0.7396\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7674 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7674 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7674 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7691 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7708 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7708 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7674 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7674 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7656 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7674 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7674 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7639 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7674 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7674 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7674 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7691 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7674 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7674 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7674 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7674 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7691 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7691 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7708 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7708 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7708 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7708 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7708 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.5235 - val_accuracy: 0.7292\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7708 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5232 - val_accuracy: 0.7292\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7708 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5227 - val_accuracy: 0.7292\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7292\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7292\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5220 - val_accuracy: 0.7292\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7726 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7743 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7743 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7743 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7292\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7292\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7292\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7292\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7778 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7778 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7778 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4837 - accuracy: 0.7778 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4835 - accuracy: 0.7778 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4834 - accuracy: 0.7778 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4829 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7240\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7240\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7795 - val_loss: 0.5182 - val_accuracy: 0.7240\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7795 - val_loss: 0.5181 - val_accuracy: 0.7240\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7795 - val_loss: 0.5180 - val_accuracy: 0.7240\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7795 - val_loss: 0.5179 - val_accuracy: 0.7240\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4813 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7240\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7240\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7240\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7240\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7778 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7240\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7240\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7240\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7812 - val_loss: 0.5167 - val_accuracy: 0.7240\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7812 - val_loss: 0.5166 - val_accuracy: 0.7240\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7812 - val_loss: 0.5165 - val_accuracy: 0.7240\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7847 - val_loss: 0.5164 - val_accuracy: 0.7240\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4798 - accuracy: 0.7847 - val_loss: 0.5163 - val_accuracy: 0.7240\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7847 - val_loss: 0.5162 - val_accuracy: 0.7292\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7292\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7847 - val_loss: 0.5161 - val_accuracy: 0.7292\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7292\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7292\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7812 - val_loss: 0.5158 - val_accuracy: 0.7292\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7292\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7812 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7292\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.5138 - val_accuracy: 0.7292\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.5138 - val_accuracy: 0.7292\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7865 - val_loss: 0.5137 - val_accuracy: 0.7292\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7865 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7865 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7865 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7865 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7865 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7865 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7865 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7865 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.7865 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4734 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7882 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4726 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7917 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7934 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4715 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4713 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7934 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7934 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7934 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7934 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7951 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.7934 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4706 - accuracy: 0.7934 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7951 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7934 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7934 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7934 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7934 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.7934 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7951 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7934 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7934 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7951 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.7917 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7951 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7934 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7448\n"
          ]
        }
      ],
      "source": [
        "run_hist_model_1n = model_1n.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrmb-lSdtDfN",
        "outputId": "a0853348-d865-47b2-a124-248659e11d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1n = model_1n.predict(X_test_norm)\n",
        "y_pred_class_model_1n = (y_pred_prob_model_1n >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkQq0uEPuJfr",
        "outputId": "91ba7405-d4dc-4a4d-d2e2-5cbaaac0a2eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5020608 ],\n",
              "       [0.5332957 ],\n",
              "       [0.818219  ],\n",
              "       [0.11957027],\n",
              "       [0.40156677],\n",
              "       [0.82637817],\n",
              "       [0.678211  ],\n",
              "       [0.1170831 ],\n",
              "       [0.09943931],\n",
              "       [0.98141956]], dtype=float32)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtinq5fstmj4",
        "outputId": "4e74c068-8e56-4e36-b49e-05222c1ad9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_class_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "30JuS6TgutWr",
        "outputId": "953a6911-afa7-4361-8e93-d31211130947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.745\n",
            "roc-auc is 0.801\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1n)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1n)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1n, 'new mode 1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhvgY9a6zG32",
        "outputId": "caa438ce-a8a9-40e6-c95e-c359032a0aed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_model_1n.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "hkBOaxXizL-5",
        "outputId": "bb7b7b85-c96d-4981-ead7-d4fca0b81da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x318238ca0>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1n.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1n.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1n.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1n.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlDTP-7r03st"
      },
      "source": [
        "ข้อ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKa3-6vo1NY5",
        "outputId": "53937cc9-375b-455d-b969-ddc0dc89421f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        }
      ],
      "source": [
        "model_1nc = Sequential([\n",
        "    Dense(6, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_1nc.summary()\n",
        "# compile new_model_1\n",
        "model_1nc.compile(optimizer=SGD(learning_rate=0.005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIz6BYz91WIx",
        "outputId": "5a3688ad-86e3-49b3-cdeb-901a2bc434a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-20 20:55:49.846691: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 0.8244 - accuracy: 0.3872 - val_loss: 0.7535 - val_accuracy: 0.4427\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8002 - accuracy: 0.4080 - val_loss: 0.7348 - val_accuracy: 0.4583\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7793 - accuracy: 0.4201 - val_loss: 0.7182 - val_accuracy: 0.4948\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7596 - accuracy: 0.4358 - val_loss: 0.7034 - val_accuracy: 0.5208\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7426 - accuracy: 0.4583 - val_loss: 0.6904 - val_accuracy: 0.5469\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7272 - accuracy: 0.4861 - val_loss: 0.6788 - val_accuracy: 0.5625\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7132 - accuracy: 0.5156 - val_loss: 0.6683 - val_accuracy: 0.5677\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.5312 - val_loss: 0.6588 - val_accuracy: 0.5990\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5642 - val_loss: 0.6505 - val_accuracy: 0.5990\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5851 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.5990 - val_loss: 0.6362 - val_accuracy: 0.6667\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.6163 - val_loss: 0.6301 - val_accuracy: 0.6719\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6250 - val_loss: 0.6246 - val_accuracy: 0.6771\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.6424 - val_loss: 0.6197 - val_accuracy: 0.6719\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6376 - accuracy: 0.6580 - val_loss: 0.6152 - val_accuracy: 0.6667\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6314 - accuracy: 0.6719 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6256 - accuracy: 0.6840 - val_loss: 0.6077 - val_accuracy: 0.6719\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6892 - val_loss: 0.6044 - val_accuracy: 0.6719\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.6927 - val_loss: 0.6015 - val_accuracy: 0.6719\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6110 - accuracy: 0.6997 - val_loss: 0.5989 - val_accuracy: 0.6823\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.7031 - val_loss: 0.5965 - val_accuracy: 0.6875\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6028 - accuracy: 0.7066 - val_loss: 0.5943 - val_accuracy: 0.6823\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7066 - val_loss: 0.5923 - val_accuracy: 0.6875\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.7135 - val_loss: 0.5904 - val_accuracy: 0.6875\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7170 - val_loss: 0.5888 - val_accuracy: 0.7135\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.7222 - val_loss: 0.5873 - val_accuracy: 0.7135\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.7257 - val_loss: 0.5859 - val_accuracy: 0.7188\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.7153 - val_loss: 0.5846 - val_accuracy: 0.7240\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.7135 - val_loss: 0.5835 - val_accuracy: 0.7240\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7188 - val_loss: 0.5824 - val_accuracy: 0.7188\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7170 - val_loss: 0.5815 - val_accuracy: 0.7188\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5744 - accuracy: 0.7188 - val_loss: 0.5806 - val_accuracy: 0.7188\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5723 - accuracy: 0.7170 - val_loss: 0.5798 - val_accuracy: 0.7188\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.7170 - val_loss: 0.5791 - val_accuracy: 0.7188\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7188 - val_loss: 0.5784 - val_accuracy: 0.7135\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.7170 - val_loss: 0.5778 - val_accuracy: 0.7135\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7205 - val_loss: 0.5772 - val_accuracy: 0.7188\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7205 - val_loss: 0.5767 - val_accuracy: 0.7188\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.7222 - val_loss: 0.5762 - val_accuracy: 0.7188\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7240 - val_loss: 0.5758 - val_accuracy: 0.7188\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7257 - val_loss: 0.5754 - val_accuracy: 0.7135\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7257 - val_loss: 0.5750 - val_accuracy: 0.7083\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7257 - val_loss: 0.5746 - val_accuracy: 0.7083\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7274 - val_loss: 0.5742 - val_accuracy: 0.7135\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7257 - val_loss: 0.5739 - val_accuracy: 0.7135\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7274 - val_loss: 0.5735 - val_accuracy: 0.7135\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5520 - accuracy: 0.7257 - val_loss: 0.5732 - val_accuracy: 0.7135\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7240 - val_loss: 0.5729 - val_accuracy: 0.7135\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.7257 - val_loss: 0.5726 - val_accuracy: 0.7135\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.7257 - val_loss: 0.5723 - val_accuracy: 0.7083\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7292 - val_loss: 0.5720 - val_accuracy: 0.7083\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7292 - val_loss: 0.5717 - val_accuracy: 0.7083\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7309 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5451 - accuracy: 0.7309 - val_loss: 0.5712 - val_accuracy: 0.7083\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7292 - val_loss: 0.5709 - val_accuracy: 0.7083\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7326 - val_loss: 0.5706 - val_accuracy: 0.7083\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7326 - val_loss: 0.5704 - val_accuracy: 0.7083\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7326 - val_loss: 0.5701 - val_accuracy: 0.7083\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.7326 - val_loss: 0.5698 - val_accuracy: 0.7083\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7344 - val_loss: 0.5695 - val_accuracy: 0.7083\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7344 - val_loss: 0.5693 - val_accuracy: 0.7083\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7344 - val_loss: 0.5690 - val_accuracy: 0.7083\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7326 - val_loss: 0.5687 - val_accuracy: 0.7083\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7326 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7326 - val_loss: 0.5681 - val_accuracy: 0.7083\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5356 - accuracy: 0.7344 - val_loss: 0.5679 - val_accuracy: 0.7083\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7344 - val_loss: 0.5676 - val_accuracy: 0.7083\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7361 - val_loss: 0.5673 - val_accuracy: 0.7083\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7361 - val_loss: 0.5669 - val_accuracy: 0.7083\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7361 - val_loss: 0.5666 - val_accuracy: 0.7083\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7361 - val_loss: 0.5663 - val_accuracy: 0.7083\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7361 - val_loss: 0.5660 - val_accuracy: 0.7083\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7361 - val_loss: 0.5657 - val_accuracy: 0.7083\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7361 - val_loss: 0.5654 - val_accuracy: 0.7083\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7361 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7361 - val_loss: 0.5647 - val_accuracy: 0.7083\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7361 - val_loss: 0.5643 - val_accuracy: 0.7083\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7378 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7378 - val_loss: 0.5636 - val_accuracy: 0.7083\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7378 - val_loss: 0.5633 - val_accuracy: 0.7083\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7378 - val_loss: 0.5629 - val_accuracy: 0.7083\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7378 - val_loss: 0.5626 - val_accuracy: 0.7083\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7378 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7378 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7378 - val_loss: 0.5615 - val_accuracy: 0.7083\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7396 - val_loss: 0.5611 - val_accuracy: 0.7083\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7396 - val_loss: 0.5608 - val_accuracy: 0.7031\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7361 - val_loss: 0.5604 - val_accuracy: 0.7031\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.7396 - val_loss: 0.5600 - val_accuracy: 0.7031\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7378 - val_loss: 0.5597 - val_accuracy: 0.7031\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7378 - val_loss: 0.5593 - val_accuracy: 0.7031\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7378 - val_loss: 0.5589 - val_accuracy: 0.7031\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7378 - val_loss: 0.5585 - val_accuracy: 0.7083\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7378 - val_loss: 0.5581 - val_accuracy: 0.7083\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7378 - val_loss: 0.5577 - val_accuracy: 0.7083\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7378 - val_loss: 0.5573 - val_accuracy: 0.7083\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7378 - val_loss: 0.5569 - val_accuracy: 0.7083\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7378 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7378 - val_loss: 0.5561 - val_accuracy: 0.7083\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7378 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7378 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7378 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7396 - val_loss: 0.5545 - val_accuracy: 0.7083\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7396 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7396 - val_loss: 0.5537 - val_accuracy: 0.7083\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7413 - val_loss: 0.5533 - val_accuracy: 0.7083\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7413 - val_loss: 0.5529 - val_accuracy: 0.7083\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7431 - val_loss: 0.5525 - val_accuracy: 0.7083\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7431 - val_loss: 0.5521 - val_accuracy: 0.7135\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7431 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7448 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7448 - val_loss: 0.5510 - val_accuracy: 0.7135\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.7448 - val_loss: 0.5506 - val_accuracy: 0.7083\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7448 - val_loss: 0.5502 - val_accuracy: 0.7135\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7448 - val_loss: 0.5498 - val_accuracy: 0.7135\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7465 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7500 - val_loss: 0.5490 - val_accuracy: 0.7135\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7535 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7535 - val_loss: 0.5483 - val_accuracy: 0.7135\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7535 - val_loss: 0.5480 - val_accuracy: 0.7135\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7535 - val_loss: 0.5476 - val_accuracy: 0.7135\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7552 - val_loss: 0.5473 - val_accuracy: 0.7135\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7552 - val_loss: 0.5469 - val_accuracy: 0.7135\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5466 - val_accuracy: 0.7135\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7552 - val_loss: 0.5463 - val_accuracy: 0.7135\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5460 - val_accuracy: 0.7135\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7552 - val_loss: 0.5457 - val_accuracy: 0.7135\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7552 - val_loss: 0.5454 - val_accuracy: 0.7135\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7552 - val_loss: 0.5451 - val_accuracy: 0.7188\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7569 - val_loss: 0.5448 - val_accuracy: 0.7188\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7552 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7535 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7552 - val_loss: 0.5438 - val_accuracy: 0.7135\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7552 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.7569 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7569 - val_loss: 0.5426 - val_accuracy: 0.7135\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7552 - val_loss: 0.5423 - val_accuracy: 0.7135\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7552 - val_loss: 0.5421 - val_accuracy: 0.7083\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7552 - val_loss: 0.5418 - val_accuracy: 0.7083\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7552 - val_loss: 0.5415 - val_accuracy: 0.7083\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7587 - val_loss: 0.5412 - val_accuracy: 0.7083\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7587 - val_loss: 0.5409 - val_accuracy: 0.7135\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7587 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7587 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5400 - val_accuracy: 0.7135\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7604 - val_loss: 0.5397 - val_accuracy: 0.7135\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7604 - val_loss: 0.5394 - val_accuracy: 0.7135\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7622 - val_loss: 0.5391 - val_accuracy: 0.7135\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7622 - val_loss: 0.5388 - val_accuracy: 0.7135\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7622 - val_loss: 0.5385 - val_accuracy: 0.7135\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5382 - val_accuracy: 0.7135\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7622 - val_loss: 0.5379 - val_accuracy: 0.7135\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5376 - val_accuracy: 0.7135\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7656 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5370 - val_accuracy: 0.7135\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7674 - val_loss: 0.5367 - val_accuracy: 0.7135\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5364 - val_accuracy: 0.7135\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7656 - val_loss: 0.5358 - val_accuracy: 0.7135\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7674 - val_loss: 0.5355 - val_accuracy: 0.7135\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7656 - val_loss: 0.5352 - val_accuracy: 0.7135\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7674 - val_loss: 0.5350 - val_accuracy: 0.7135\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7674 - val_loss: 0.5347 - val_accuracy: 0.7135\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7691 - val_loss: 0.5344 - val_accuracy: 0.7135\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7691 - val_loss: 0.5342 - val_accuracy: 0.7135\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7708 - val_loss: 0.5339 - val_accuracy: 0.7135\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7691 - val_loss: 0.5337 - val_accuracy: 0.7135\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7708 - val_loss: 0.5334 - val_accuracy: 0.7135\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7708 - val_loss: 0.5331 - val_accuracy: 0.7135\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7708 - val_loss: 0.5329 - val_accuracy: 0.7135\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7691 - val_loss: 0.5326 - val_accuracy: 0.7135\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7708 - val_loss: 0.5323 - val_accuracy: 0.7135\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7708 - val_loss: 0.5320 - val_accuracy: 0.7188\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7708 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5315 - val_accuracy: 0.7188\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7674 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7656 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5300 - val_accuracy: 0.7240\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5297 - val_accuracy: 0.7240\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7674 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.5281 - val_accuracy: 0.7240\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7674 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7240\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7708 - val_loss: 0.5259 - val_accuracy: 0.7240\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7708 - val_loss: 0.5258 - val_accuracy: 0.7240\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7708 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7708 - val_loss: 0.5252 - val_accuracy: 0.7240\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7674 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.5235 - val_accuracy: 0.7292\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7674 - val_loss: 0.5233 - val_accuracy: 0.7292\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.5232 - val_accuracy: 0.7292\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7656 - val_loss: 0.5229 - val_accuracy: 0.7292\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.5228 - val_accuracy: 0.7292\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5221 - val_accuracy: 0.7292\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7674 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5200 - val_accuracy: 0.7292\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7292\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7292\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.5186 - val_accuracy: 0.7292\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7656 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.7656 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.7656 - val_loss: 0.5173 - val_accuracy: 0.7240\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.5170 - val_accuracy: 0.7240\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7240\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7656 - val_loss: 0.5166 - val_accuracy: 0.7240\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.5165 - val_accuracy: 0.7240\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.5163 - val_accuracy: 0.7240\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7240\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.5158 - val_accuracy: 0.7240\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5156 - val_accuracy: 0.7240\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.5155 - val_accuracy: 0.7240\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.5154 - val_accuracy: 0.7240\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7726 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7292\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.5138 - val_accuracy: 0.7292\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7708 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7760 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7760 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7830 - val_loss: 0.5116 - val_accuracy: 0.7292\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7830 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7830 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7847 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7847 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7830 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7396\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7396\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7396\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7396\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7899 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7951 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7917 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7934 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7951 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7951 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7917 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7934 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7934 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7934 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7917 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7917 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7917 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7917 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.8003 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7865 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7951 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7344\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7344\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7830 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7986 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7934 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7847 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7934 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7934 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7899 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7865 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7934 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7969 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7969 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7830 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7934 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7934 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7882 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7899 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7934 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7882 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7934 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7795 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7865 - val_loss: 0.5384 - val_accuracy: 0.7656\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7899 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7899 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7917 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7812 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7865 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7951 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7882 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7795 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7812 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7951 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7500\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7882 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7847 - val_loss: 0.5422 - val_accuracy: 0.7708\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7448\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7812 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7865 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7812 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7899 - val_loss: 0.5331 - val_accuracy: 0.7292\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7674 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7812 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7847 - val_loss: 0.5829 - val_accuracy: 0.7396\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7760 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7726 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7778 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7951 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7899 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7778 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7760 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7847 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7604 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7726 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7917 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7899 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7951 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7674 - val_loss: 0.5076 - val_accuracy: 0.7396\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7969 - val_loss: 0.5369 - val_accuracy: 0.7240\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7899 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7917 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7708 - val_loss: 0.5406 - val_accuracy: 0.7292\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7865 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7951 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7743 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7656 - val_loss: 0.6222 - val_accuracy: 0.7292\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7743 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7639 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.5648 - val_accuracy: 0.7240\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7743 - val_loss: 0.5393 - val_accuracy: 0.7656\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7622 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7830 - val_loss: 0.5797 - val_accuracy: 0.7344\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7656 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7760 - val_loss: 0.5951 - val_accuracy: 0.7292\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7778 - val_loss: 0.6464 - val_accuracy: 0.6875\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7726 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7569 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7795 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7639 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7708 - val_loss: 0.5641 - val_accuracy: 0.7292\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7535 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7674 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7726 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7812 - val_loss: 0.5488 - val_accuracy: 0.7604\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7604 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7691 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7743 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7517 - val_loss: 0.5527 - val_accuracy: 0.7604\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7656 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7743 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7604 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7674 - val_loss: 0.5511 - val_accuracy: 0.7188\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7500 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7778 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7986 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7604 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7726 - val_loss: 0.6138 - val_accuracy: 0.7344\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5662 - accuracy: 0.7413 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7674 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7691 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7413 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7691 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7396 - val_loss: 0.5735 - val_accuracy: 0.7448\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7483 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7847 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7656 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7830 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7726 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7795 - val_loss: 0.6010 - val_accuracy: 0.7292\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7483 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5253 - accuracy: 0.7830 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7500 - val_loss: 0.5799 - val_accuracy: 0.7396\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.7240 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7604 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7587 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.7170 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7847 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5701 - accuracy: 0.7674 - val_loss: 0.6921 - val_accuracy: 0.7240\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7778 - val_loss: 1.1557 - val_accuracy: 0.7344\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7448 - val_loss: 0.5624 - val_accuracy: 0.7604\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7639 - val_loss: 0.5417 - val_accuracy: 0.7604\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7795 - val_loss: 0.5656 - val_accuracy: 0.7240\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7778 - val_loss: 0.7294 - val_accuracy: 0.6250\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.7535 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7760 - val_loss: 0.5639 - val_accuracy: 0.7240\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7604 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7639 - val_loss: 0.6325 - val_accuracy: 0.7083\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7413 - val_loss: 0.5609 - val_accuracy: 0.7240\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5725 - accuracy: 0.7309 - val_loss: 0.6242 - val_accuracy: 0.7292\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6504 - accuracy: 0.7257 - val_loss: 0.6482 - val_accuracy: 0.7083\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7708 - val_loss: 0.6001 - val_accuracy: 0.7240\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7448 - val_loss: 0.6752 - val_accuracy: 0.6719\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7465 - val_loss: 0.7882 - val_accuracy: 0.6094\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7431 - val_loss: 0.8791 - val_accuracy: 0.7344\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7656 - val_loss: 0.6524 - val_accuracy: 0.7292\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.7517 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5721 - accuracy: 0.7552 - val_loss: 0.6613 - val_accuracy: 0.7292\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7726 - val_loss: 0.8218 - val_accuracy: 0.5885\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.7674 - val_loss: 0.6948 - val_accuracy: 0.7240\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.7465 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5523 - accuracy: 0.7604 - val_loss: 0.7111 - val_accuracy: 0.7292\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.7413 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7962 - accuracy: 0.7014 - val_loss: 0.6116 - val_accuracy: 0.7188\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5937 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.7326 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5978 - accuracy: 0.7170 - val_loss: 1.5035 - val_accuracy: 0.7135\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7298 - accuracy: 0.7222 - val_loss: 0.5855 - val_accuracy: 0.7448\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.7344 - val_loss: 0.5242 - val_accuracy: 0.7448\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5892 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5534 - accuracy: 0.7378 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6306 - accuracy: 0.7292 - val_loss: 0.6653 - val_accuracy: 0.7292\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7708 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.7656 - val_loss: 0.5938 - val_accuracy: 0.7292\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6087 - accuracy: 0.7569 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7517 - val_loss: 1.0120 - val_accuracy: 0.7344\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6094 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.7257 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.7309 - val_loss: 0.6864 - val_accuracy: 0.6562\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.7431 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6014 - accuracy: 0.7674 - val_loss: 0.5372 - val_accuracy: 0.7344\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.7257 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.7361 - val_loss: 1.7826 - val_accuracy: 0.7135\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8170 - accuracy: 0.7257 - val_loss: 0.5535 - val_accuracy: 0.7604\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.7378 - val_loss: 1.3405 - val_accuracy: 0.7292\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.7309 - val_loss: 1.6595 - val_accuracy: 0.7135\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8279 - accuracy: 0.7135 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7639 - val_loss: 0.6993 - val_accuracy: 0.7240\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.7535 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.7396 - val_loss: 0.6384 - val_accuracy: 0.7188\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7220 - accuracy: 0.7431 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8876 - accuracy: 0.6962 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.7500 - val_loss: 0.7146 - val_accuracy: 0.6562\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7160 - accuracy: 0.7431 - val_loss: 0.6144 - val_accuracy: 0.7292\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7284 - accuracy: 0.7465 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6680 - accuracy: 0.7378 - val_loss: 1.1421 - val_accuracy: 0.4688\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9027 - accuracy: 0.7135 - val_loss: 0.9283 - val_accuracy: 0.5312\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7853 - accuracy: 0.7326 - val_loss: 0.7148 - val_accuracy: 0.7240\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.7587 - val_loss: 0.6182 - val_accuracy: 0.7240\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6683 - accuracy: 0.7604 - val_loss: 0.6650 - val_accuracy: 0.7240\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8943 - accuracy: 0.7031 - val_loss: 0.6979 - val_accuracy: 0.7292\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5544 - accuracy: 0.7760 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8420 - accuracy: 0.7205 - val_loss: 1.0443 - val_accuracy: 0.7292\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7924 - accuracy: 0.7170 - val_loss: 0.6256 - val_accuracy: 0.7188\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.7378 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7274 - accuracy: 0.7431 - val_loss: 0.9791 - val_accuracy: 0.7344\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7120 - accuracy: 0.7431 - val_loss: 0.6395 - val_accuracy: 0.7188\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.7431 - val_loss: 0.6587 - val_accuracy: 0.7240\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.7361 - val_loss: 0.6484 - val_accuracy: 0.7240\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8375 - accuracy: 0.7083 - val_loss: 0.9384 - val_accuracy: 0.5469\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9894 - accuracy: 0.7049 - val_loss: 0.7030 - val_accuracy: 0.7240\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7285 - accuracy: 0.7361 - val_loss: 0.5909 - val_accuracy: 0.7448\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0104 - accuracy: 0.6997 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9563 - accuracy: 0.6910 - val_loss: 0.9284 - val_accuracy: 0.7292\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1395 - accuracy: 0.6910 - val_loss: 0.7321 - val_accuracy: 0.7240\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7674 - val_loss: 0.5542 - val_accuracy: 0.7344\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6448 - accuracy: 0.7552 - val_loss: 0.5857 - val_accuracy: 0.7448\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7445 - accuracy: 0.7483 - val_loss: 0.8830 - val_accuracy: 0.7344\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.7378 - val_loss: 0.6479 - val_accuracy: 0.7188\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1503 - accuracy: 0.6667 - val_loss: 0.5644 - val_accuracy: 0.7708\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9970 - accuracy: 0.7031 - val_loss: 2.7314 - val_accuracy: 0.6979\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.2037 - accuracy: 0.6927 - val_loss: 0.9416 - val_accuracy: 0.7292\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8029 - accuracy: 0.7309 - val_loss: 0.7411 - val_accuracy: 0.7240\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7808 - accuracy: 0.7344 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8404 - accuracy: 0.7378 - val_loss: 0.8647 - val_accuracy: 0.6146\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9355 - accuracy: 0.7170 - val_loss: 0.5668 - val_accuracy: 0.7396\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8242 - accuracy: 0.7396 - val_loss: 0.6409 - val_accuracy: 0.7292\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9223 - accuracy: 0.7170 - val_loss: 0.7008 - val_accuracy: 0.7083\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8472 - accuracy: 0.7344 - val_loss: 1.5963 - val_accuracy: 0.7240\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0029 - accuracy: 0.7101 - val_loss: 0.5931 - val_accuracy: 0.7292\n"
          ]
        }
      ],
      "source": [
        "run_hist_model_1nc = model_1nc.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcufQ9u1Zn1",
        "outputId": "ff864c2c-7be9-4dc3-83d3-e6c2799d6489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1nc= model_1nc.predict(X_test_norm)\n",
        "y_pred_class_model_1nc = (y_pred_prob_model_1nc >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0yhnpS_B1e7F",
        "outputId": "a1d80c05-2a15-42c1-f2f5-d1b765686bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.729\n",
            "roc-auc is 0.804\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1nc)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1nc)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1nc, 'new mode 1nCustom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "anGBXOJd1g-7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_model_1nc.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jUfvnSU-1iS9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x32113c9d0>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1nc.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1nc.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1nc.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1nc.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkYhvnPLUAIM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
