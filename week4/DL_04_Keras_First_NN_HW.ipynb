{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLogkosUAH-"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Uqx7woUAIF"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## Pima Diabetes Dataset\n",
        "\n",
        "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvQhWj5UAIF"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xv268rbuUAIG"
      },
      "outputs": [],
      "source": [
        "#Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B8p6y-7qUAIH"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "C39rLYeaUAIH",
        "outputId": "dc600f54-5d03-47d5-ec98-cfd65f6e544d"
      },
      "outputs": [],
      "source": [
        "## Load in the data set (Internet Access needed)\n",
        "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
        "\n",
        "seed_value = 11111\n",
        "url = \"https://raw.githubusercontent.com/punsnx/cs_datasets/main/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(url, names=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QCr0krluUAIH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ]
        }
      ],
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "# diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N9gywmErXEpJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "0               6                     148              72              35   \n",
              "1               1                      85              66              29   \n",
              "2               8                     183              64               0   \n",
              "3               1                      89              66              23   \n",
              "4               0                     137              40              35   \n",
              "\n",
              "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "0        0  33.6              0.627   50             1  \n",
              "1        0  26.6              0.351   31             0  \n",
              "2        0  23.3              0.672   32             1  \n",
              "3       94  28.1              0.167   21             0  \n",
              "4      168  43.1              2.288   33             1  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TBnwBgsWUAIH"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values #train features\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AUeCzRaPV4d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rEa33td5UAII"
      },
      "outputs": [],
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "# stratify คือ การกำหนดการกระจายของข้อมูลที่ split ให้มีการกระจายเหมือน original dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OAcXPGFWUAII"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSIknieUAII"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1Q2BRmB1UAII"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=11111)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=seed_value)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uxEybpR4UAII"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.795\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1YR5seGYUAIJ"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MMLGxSUAIJ"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 8 nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uviwG3g_UAIJ"
      },
      "outputs": [],
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qW2ikMYhaZYm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.17553013, -0.88319193, -0.4797748 , ..., -0.41547152,\n",
              "         0.23300528, -0.95829939],\n",
              "       [-1.17553013, -1.35145275,  0.9447112 , ...,  0.60441055,\n",
              "        -0.07457346, -1.04227634],\n",
              "       [-0.58157806, -0.50858328, -0.5815238 , ...,  0.35565882,\n",
              "        -0.73053221, -0.70636856],\n",
              "       ...,\n",
              "       [ 0.60632606, -0.1964094 , -0.4797748 , ...,  0.20640779,\n",
              "        -0.66776104,  0.55328559],\n",
              "       [-0.87855409,  0.86498179, -0.0727788 , ..., -0.340846  ,\n",
              "        -0.34135094,  0.72123948],\n",
              "       [ 1.49725416,  0.95863395,  0.4359662 , ...,  0.26859572,\n",
              "         1.36602495, -0.03455301]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zzAKCitoajRT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.012374  ,  1.02106873,  0.1307192 , ..., -0.09209428,\n",
              "        -0.37587509,  0.30135476],\n",
              "       [ 1.79423019,  0.36550358, -0.0727788 , ..., -0.62691048,\n",
              "        -0.66776104,  0.21737782],\n",
              "       [-0.58157806,  1.64541648,  0.9447112 , ...,  1.54966709,\n",
              "         0.59080097, -0.79034551],\n",
              "       ...,\n",
              "       [ 0.012374  , -0.78953977, -0.6832728 , ..., -1.39804083,\n",
              "        -0.36959797, -0.62239162],\n",
              "       [-0.87855409, -0.29006156,  0.1307192 , ...,  0.29347089,\n",
              "         0.22045105, -0.70636856],\n",
              "       [ 0.9033021 , -0.47736589, -0.4797748 , ..., -0.68909841,\n",
              "        -0.50769455, -0.37046079]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3nIrw2ZEUAIJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-24 19:36:01.692523: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
            "2023-12-24 19:36:01.692556: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
            "2023-12-24 19:36:01.692562: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
            "2023-12-24 19:36:01.692608: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-12-24 19:36:01.692626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "# Define the Model\n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 8 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "import os, random, numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ha9-w35OUAIJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81 (324.00 Byte)\n",
            "Trainable params: 81 (324.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHF08OSCUAIK"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 81 parameters?  Does that make sense?\n",
        "\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iQ4Tj8EiUAIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 10ms/step - loss: 0.7662 - accuracy: 0.4688 - val_loss: 0.7449 - val_accuracy: 0.5104\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.4774 - val_loss: 0.7373 - val_accuracy: 0.5156\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.4861 - val_loss: 0.7302 - val_accuracy: 0.5312\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.5035 - val_loss: 0.7234 - val_accuracy: 0.5625\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7391 - accuracy: 0.5191 - val_loss: 0.7171 - val_accuracy: 0.5677\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.5295 - val_loss: 0.7113 - val_accuracy: 0.5781\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.5434 - val_loss: 0.7057 - val_accuracy: 0.6042\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7226 - accuracy: 0.5538 - val_loss: 0.7004 - val_accuracy: 0.6146\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.5642 - val_loss: 0.6955 - val_accuracy: 0.6146\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7130 - accuracy: 0.5712 - val_loss: 0.6909 - val_accuracy: 0.6302\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.5764 - val_loss: 0.6864 - val_accuracy: 0.6406\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5938 - val_loss: 0.6822 - val_accuracy: 0.6354\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.5972 - val_loss: 0.6782 - val_accuracy: 0.6458\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.6094 - val_loss: 0.6744 - val_accuracy: 0.6615\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.6146 - val_loss: 0.6707 - val_accuracy: 0.6562\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.6198 - val_loss: 0.6672 - val_accuracy: 0.6406\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.6267 - val_loss: 0.6638 - val_accuracy: 0.6458\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6302 - val_loss: 0.6606 - val_accuracy: 0.6510\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6302 - val_loss: 0.6575 - val_accuracy: 0.6510\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.6354 - val_loss: 0.6544 - val_accuracy: 0.6510\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6441 - val_loss: 0.6515 - val_accuracy: 0.6458\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6562\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6528 - val_loss: 0.6459 - val_accuracy: 0.6615\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6562 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6597 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6615 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6615 - val_loss: 0.6358 - val_accuracy: 0.6667\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6649 - val_loss: 0.6335 - val_accuracy: 0.6667\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6649 - val_loss: 0.6312 - val_accuracy: 0.6615\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6701 - val_loss: 0.6290 - val_accuracy: 0.6562\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6719 - val_loss: 0.6269 - val_accuracy: 0.6562\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6701 - val_loss: 0.6248 - val_accuracy: 0.6510\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6701 - val_loss: 0.6228 - val_accuracy: 0.6510\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6736 - val_loss: 0.6208 - val_accuracy: 0.6510\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6753 - val_loss: 0.6189 - val_accuracy: 0.6510\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6788 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6806 - val_loss: 0.6153 - val_accuracy: 0.6458\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6823 - val_loss: 0.6135 - val_accuracy: 0.6458\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6840 - val_loss: 0.6117 - val_accuracy: 0.6510\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6840 - val_loss: 0.6100 - val_accuracy: 0.6510\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6840 - val_loss: 0.6083 - val_accuracy: 0.6510\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6858 - val_loss: 0.6067 - val_accuracy: 0.6510\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6858 - val_loss: 0.6050 - val_accuracy: 0.6510\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6858 - val_loss: 0.6035 - val_accuracy: 0.6562\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6858 - val_loss: 0.6019 - val_accuracy: 0.6615\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6875 - val_loss: 0.6004 - val_accuracy: 0.6615\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6875 - val_loss: 0.5989 - val_accuracy: 0.6615\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6910 - val_loss: 0.5974 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6927 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6944 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6615\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6944 - val_loss: 0.5917 - val_accuracy: 0.6615\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6944 - val_loss: 0.5903 - val_accuracy: 0.6615\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6979 - val_loss: 0.5889 - val_accuracy: 0.6771\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7014 - val_loss: 0.5875 - val_accuracy: 0.6771\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7066 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7049 - val_loss: 0.5848 - val_accuracy: 0.6823\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.6823\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7083 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7101 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7101 - val_loss: 0.5797 - val_accuracy: 0.6875\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7083 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7083 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7118 - val_loss: 0.5760 - val_accuracy: 0.6927\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7118 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7101 - val_loss: 0.5737 - val_accuracy: 0.6979\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7118 - val_loss: 0.5725 - val_accuracy: 0.6979\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7118 - val_loss: 0.5714 - val_accuracy: 0.6927\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7135 - val_loss: 0.5703 - val_accuracy: 0.6927\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7135 - val_loss: 0.5692 - val_accuracy: 0.6979\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.6979\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7135 - val_loss: 0.5671 - val_accuracy: 0.6979\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7153 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7170 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7170 - val_loss: 0.5640 - val_accuracy: 0.6979\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7188 - val_loss: 0.5629 - val_accuracy: 0.6979\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7205 - val_loss: 0.5619 - val_accuracy: 0.6979\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7205 - val_loss: 0.5609 - val_accuracy: 0.6979\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7205 - val_loss: 0.5599 - val_accuracy: 0.6979\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7205 - val_loss: 0.5589 - val_accuracy: 0.6979\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7257 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7274 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7309 - val_loss: 0.5560 - val_accuracy: 0.7031\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7326 - val_loss: 0.5550 - val_accuracy: 0.7031\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7326 - val_loss: 0.5541 - val_accuracy: 0.7031\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7344 - val_loss: 0.5531 - val_accuracy: 0.6979\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7344 - val_loss: 0.5522 - val_accuracy: 0.6979\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7361 - val_loss: 0.5513 - val_accuracy: 0.6927\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7361 - val_loss: 0.5504 - val_accuracy: 0.6927\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7378 - val_loss: 0.5495 - val_accuracy: 0.6927\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7378 - val_loss: 0.5487 - val_accuracy: 0.6927\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7396 - val_loss: 0.5478 - val_accuracy: 0.6927\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7396 - val_loss: 0.5470 - val_accuracy: 0.6979\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7396 - val_loss: 0.5461 - val_accuracy: 0.6979\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7413 - val_loss: 0.5453 - val_accuracy: 0.6979\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7431 - val_loss: 0.5445 - val_accuracy: 0.6927\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7431 - val_loss: 0.5437 - val_accuracy: 0.6927\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7431 - val_loss: 0.5429 - val_accuracy: 0.6875\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7448 - val_loss: 0.5422 - val_accuracy: 0.6927\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7483 - val_loss: 0.5414 - val_accuracy: 0.6927\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7500 - val_loss: 0.5406 - val_accuracy: 0.6979\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7517 - val_loss: 0.5399 - val_accuracy: 0.6979\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7517 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7500 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7500 - val_loss: 0.5378 - val_accuracy: 0.7031\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7517 - val_loss: 0.5371 - val_accuracy: 0.7031\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7517 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7517 - val_loss: 0.5357 - val_accuracy: 0.7031\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7552 - val_loss: 0.5350 - val_accuracy: 0.7031\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7031\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7031\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7569 - val_loss: 0.5331 - val_accuracy: 0.7031\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7587 - val_loss: 0.5324 - val_accuracy: 0.7031\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7031\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7587 - val_loss: 0.5311 - val_accuracy: 0.7031\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7604 - val_loss: 0.5305 - val_accuracy: 0.7031\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7031\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7639 - val_loss: 0.5287 - val_accuracy: 0.7031\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7639 - val_loss: 0.5281 - val_accuracy: 0.7031\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7031\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7031\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7031\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7031\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7135\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7656 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7656 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7674 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7691 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7639 - val_loss: 0.5218 - val_accuracy: 0.7135\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7639 - val_loss: 0.5213 - val_accuracy: 0.7135\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7639 - val_loss: 0.5208 - val_accuracy: 0.7135\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7135\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7639 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5182 - val_accuracy: 0.7240\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7622 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7622 - val_loss: 0.5167 - val_accuracy: 0.7240\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5163 - val_accuracy: 0.7292\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7622 - val_loss: 0.5160 - val_accuracy: 0.7292\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7639 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7674 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5109 - val_accuracy: 0.7292\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7292\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7674 - val_loss: 0.5104 - val_accuracy: 0.7292\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7292\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5099 - val_accuracy: 0.7292\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7292\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7292\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5089 - val_accuracy: 0.7292\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5087 - val_accuracy: 0.7292\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.7292\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.5082 - val_accuracy: 0.7292\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5080 - val_accuracy: 0.7292\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5077 - val_accuracy: 0.7292\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7708 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7708 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7708 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7344\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7344\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7292\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7292\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7292\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7292\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7292\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7292\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7292\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7292\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7292\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7292\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7292\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7292\n"
          ]
        }
      ],
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, batch_size=32)\n",
        "# the fit function returns the run history.\n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WJMeGW7MUAIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 800us/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SsYmQ73OUAIK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bhKNo_5BUAIK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.58112663],\n",
              "       [0.32257375],\n",
              "       [0.61203736],\n",
              "       [0.13304551],\n",
              "       [0.49373564],\n",
              "       [0.709026  ],\n",
              "       [0.5599951 ],\n",
              "       [0.15182672],\n",
              "       [0.1791873 ],\n",
              "       [0.9180581 ]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n_vOd-upUAIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.729\n",
            "roc-auc is 0.815\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SLVuVLnUAIK"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXfBqaFsUAIL"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xbW5F77kUAIL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11UgwSDSUAIL"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CstB8zXcUAIL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x21083f3a380>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG5HzDNFUAIL"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "slHFioCFUAIL",
        "outputId": "6a709f3d-230e-4c21-c90a-045dee77cddc",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7292\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7240\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7240\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7240\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7240\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7240\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7240\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7240\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7240\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7240\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7240\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7847 - val_loss: 0.5021 - val_accuracy: 0.7240\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7240\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7240\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7240\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7240\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7240\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7240\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7240\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7240\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7240\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7240\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7240\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7240\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7240\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7240\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7240\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7292\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7917 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7917 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7899 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7917 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7917 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7917 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7917 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7899 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n"
          ]
        }
      ],
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jBy7i6XSUAIL",
        "outputId": "b49a7eac-d8bc-4ff0-d632-3494f7f132e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x210879a3eb0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history\n",
        " [\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x696YhRJUAIM"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720x50Nrg7oG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6K5p_8gw0i"
      },
      "source": [
        "**Student Answer:**\n",
        "\n",
        "---\n",
        "จากกราฟ n epoh ที่เหมาะสม คือ 200 เพราะมากกว่านี้  validation loss ก็ไม่ขยับลงแล้ว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CylpfYBYUAIM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp9yOAXQUAIM"
      },
      "source": [
        "# <span style=\"color:blue\">แบบฝึกปฏิบัติ</span>\n",
        "\n",
        "(รวม 100 คะแนน) ให้นิสิตใช้พื้นที่ต่อไปนี้ ในการเพิ่มโค้ดให้เป็นไปตามข้อกำหนดต่อไปนี้\n",
        "1. (50 คะแนน) เพิ่มเซลโค้ด เพื่อ\n",
        "   * สร้างโมเดลที่มีเลเยอร์ hidden 2 ชั้น แต่ละชั้นมี 6 โหนด\n",
        "   * ปรับโค้ดให้สามารถรับอินพุตที่มีจำนวน feature ตามข้อมูลเทรนที่จะถูกส่งเข้ามา (ปราศจากการใช้ค่าคงที่ 8 ที่ถูกระบุอยู่ในโค้ด ณ ตอนนี้)\n",
        "   * สำหรับเลเยอร์ hidden ให้ใช้ activation function เป็น \"relu\" และเลเยอร์ output เป็น \"sigmoid\"\n",
        "   * ใช้ learning rate เท่ากับ 0.003 และเทรนด้วยจำนวน 1500 epochs ส่วนสำหรับ Hyperparameter ที่เหลือให้ใช้ค่าคงเดิม\n",
        "   * วาดกราฟของค่า loss และ accuracy ด้วยทั้งชุดข้อมูล train และ test (ดังตัวอย่างในรูปนี้)\n",
        "  <img src=\"https://drive.google.com/uc?id=1GuN0KQf64rGMa4oCY2upnbOTMzWaXmbT\" style=\"height:360px\">\n",
        "2. (50 คะแนน) เพิ่มอีกเซลโค้ด เพื่อสร้างโมเดลที่มีการปรับโครงสร้างที่เหมาะสมขึ้น รวมถึงการปรับค่า Hyperparameter ต่าง ๆ เพื่อให้โมเดลใหม่ได้ผลลัพธ์ที่ดีขึ้น (โดยพิจารณาจากค่า accuracy) และในการเทรนโมเดลใหม่นี้ ห้ามมีการใช้ Early Stopping\n",
        "   * ให้วาดกราฟของค่า loss และ accuracy ของโมเดลใหม่นี้ด้วย\n",
        "   * อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itoIvUsoh1qX"
      },
      "source": [
        "ข้อ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "kagzZns5jFmJ",
        "outputId": "eba085fd-3da6-47ac-fb90-38025460e1fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(576, 8)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "yGLKGsGIh1CF",
        "outputId": "14542370-9c23-42f7-9dd0-7931c529cbaa"
      },
      "outputs": [],
      "source": [
        "model_1n = Sequential([\n",
        "    Dense(6, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "B8gnOFsEjnUp",
        "outputId": "a1280974-4410-40aa-a378-9013046766bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103\n",
            "Trainable params: 103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1n.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "r9aHCvg0jwQQ",
        "outputId": "07a03196-ea78-43dd-dfcf-3cefbe6b2bd1"
      },
      "outputs": [],
      "source": [
        "# compile new_model_1\n",
        "model_1n.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDSACFWkOMu",
        "outputId": "f474008c-4511-4456-fd90-5dacc06b552a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.6562 - val_loss: 0.6374 - val_accuracy: 0.6927\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6580 - val_loss: 0.6355 - val_accuracy: 0.6771\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6632 - val_loss: 0.6337 - val_accuracy: 0.6771\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6615 - val_loss: 0.6320 - val_accuracy: 0.6771\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6615 - val_loss: 0.6303 - val_accuracy: 0.6615\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6632 - val_loss: 0.6287 - val_accuracy: 0.6562\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6597 - val_loss: 0.6271 - val_accuracy: 0.6615\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6597 - val_loss: 0.6257 - val_accuracy: 0.6667\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6580 - val_loss: 0.6242 - val_accuracy: 0.6615\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6545 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6528 - val_loss: 0.6215 - val_accuracy: 0.6667\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6562 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6562 - val_loss: 0.6189 - val_accuracy: 0.6615\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6545 - val_loss: 0.6177 - val_accuracy: 0.6510\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.6562 - val_loss: 0.6166 - val_accuracy: 0.6458\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6562 - val_loss: 0.6154 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6615 - val_loss: 0.6143 - val_accuracy: 0.6458\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6580 - val_loss: 0.6132 - val_accuracy: 0.6406\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6562 - val_loss: 0.6122 - val_accuracy: 0.6406\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.6545 - val_loss: 0.6112 - val_accuracy: 0.6406\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6545 - val_loss: 0.6102 - val_accuracy: 0.6406\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6545 - val_loss: 0.6092 - val_accuracy: 0.6354\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6562 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6545 - val_loss: 0.6074 - val_accuracy: 0.6458\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6615 - val_loss: 0.6065 - val_accuracy: 0.6510\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6615 - val_loss: 0.6057 - val_accuracy: 0.6510\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6615 - val_loss: 0.6048 - val_accuracy: 0.6458\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6632 - val_loss: 0.6040 - val_accuracy: 0.6510\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6632 - val_loss: 0.6032 - val_accuracy: 0.6510\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6649 - val_loss: 0.6024 - val_accuracy: 0.6562\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6649 - val_loss: 0.6016 - val_accuracy: 0.6562\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6649 - val_loss: 0.6008 - val_accuracy: 0.6562\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6649 - val_loss: 0.6001 - val_accuracy: 0.6562\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.6667 - val_loss: 0.5994 - val_accuracy: 0.6562\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6684 - val_loss: 0.5986 - val_accuracy: 0.6562\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6684 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6684 - val_loss: 0.5972 - val_accuracy: 0.6562\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6684 - val_loss: 0.5965 - val_accuracy: 0.6562\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6701 - val_loss: 0.5958 - val_accuracy: 0.6562\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6701 - val_loss: 0.5951 - val_accuracy: 0.6562\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6701 - val_loss: 0.5945 - val_accuracy: 0.6562\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6736 - val_loss: 0.5938 - val_accuracy: 0.6562\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6736 - val_loss: 0.5931 - val_accuracy: 0.6562\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6753 - val_loss: 0.5925 - val_accuracy: 0.6562\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6753 - val_loss: 0.5918 - val_accuracy: 0.6562\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.6753 - val_loss: 0.5912 - val_accuracy: 0.6615\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6753 - val_loss: 0.5906 - val_accuracy: 0.6615\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6753 - val_loss: 0.5899 - val_accuracy: 0.6615\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6736 - val_loss: 0.5893 - val_accuracy: 0.6615\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.6736 - val_loss: 0.5887 - val_accuracy: 0.6615\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.6736 - val_loss: 0.5881 - val_accuracy: 0.6615\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6736 - val_loss: 0.5875 - val_accuracy: 0.6615\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6736 - val_loss: 0.5869 - val_accuracy: 0.6615\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6736 - val_loss: 0.5863 - val_accuracy: 0.6615\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6736 - val_loss: 0.5857 - val_accuracy: 0.6615\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.6736 - val_loss: 0.5852 - val_accuracy: 0.6615\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.6736 - val_loss: 0.5846 - val_accuracy: 0.6615\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.6736 - val_loss: 0.5841 - val_accuracy: 0.6615\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.6736 - val_loss: 0.5835 - val_accuracy: 0.6615\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6771 - val_loss: 0.5830 - val_accuracy: 0.6615\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.6771 - val_loss: 0.5824 - val_accuracy: 0.6615\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6771 - val_loss: 0.5819 - val_accuracy: 0.6615\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6753 - val_loss: 0.5814 - val_accuracy: 0.6615\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6788 - val_loss: 0.5808 - val_accuracy: 0.6615\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6771 - val_loss: 0.5803 - val_accuracy: 0.6615\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.6771 - val_loss: 0.5798 - val_accuracy: 0.6615\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.6771 - val_loss: 0.5793 - val_accuracy: 0.6615\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.6788 - val_loss: 0.5788 - val_accuracy: 0.6615\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6788 - val_loss: 0.5783 - val_accuracy: 0.6615\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6788 - val_loss: 0.5778 - val_accuracy: 0.6615\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.6788 - val_loss: 0.5773 - val_accuracy: 0.6562\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.6788 - val_loss: 0.5768 - val_accuracy: 0.6562\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.6806 - val_loss: 0.5763 - val_accuracy: 0.6562\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6788 - val_loss: 0.5758 - val_accuracy: 0.6562\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.6788 - val_loss: 0.5754 - val_accuracy: 0.6562\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.6823 - val_loss: 0.5749 - val_accuracy: 0.6562\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.6823 - val_loss: 0.5744 - val_accuracy: 0.6562\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.6823 - val_loss: 0.5739 - val_accuracy: 0.6562\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.6823 - val_loss: 0.5734 - val_accuracy: 0.6562\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.6823 - val_loss: 0.5730 - val_accuracy: 0.6562\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.6823 - val_loss: 0.5725 - val_accuracy: 0.6562\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.6840 - val_loss: 0.5720 - val_accuracy: 0.6562\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.6858 - val_loss: 0.5715 - val_accuracy: 0.6562\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.6858 - val_loss: 0.5711 - val_accuracy: 0.6615\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.6858 - val_loss: 0.5706 - val_accuracy: 0.6615\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.6875 - val_loss: 0.5701 - val_accuracy: 0.6615\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.6875 - val_loss: 0.5696 - val_accuracy: 0.6615\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.6910 - val_loss: 0.5692 - val_accuracy: 0.6615\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.6910 - val_loss: 0.5687 - val_accuracy: 0.6615\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.6910 - val_loss: 0.5683 - val_accuracy: 0.6615\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.6910 - val_loss: 0.5678 - val_accuracy: 0.6615\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.6892 - val_loss: 0.5674 - val_accuracy: 0.6615\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.6892 - val_loss: 0.5669 - val_accuracy: 0.6615\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.6892 - val_loss: 0.5665 - val_accuracy: 0.6615\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.6910 - val_loss: 0.5661 - val_accuracy: 0.6615\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.6892 - val_loss: 0.5657 - val_accuracy: 0.6615\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.6910 - val_loss: 0.5653 - val_accuracy: 0.6615\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.6927 - val_loss: 0.5649 - val_accuracy: 0.6667\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.6944 - val_loss: 0.5645 - val_accuracy: 0.6719\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.6944 - val_loss: 0.5640 - val_accuracy: 0.6719\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.6979 - val_loss: 0.5636 - val_accuracy: 0.6719\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.6979 - val_loss: 0.5632 - val_accuracy: 0.6719\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.6997 - val_loss: 0.5628 - val_accuracy: 0.6719\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7049 - val_loss: 0.5625 - val_accuracy: 0.6719\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7031 - val_loss: 0.5621 - val_accuracy: 0.6719\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7049 - val_loss: 0.5617 - val_accuracy: 0.6719\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7049 - val_loss: 0.5613 - val_accuracy: 0.6719\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7066 - val_loss: 0.5609 - val_accuracy: 0.6719\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7066 - val_loss: 0.5605 - val_accuracy: 0.6771\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7101 - val_loss: 0.5601 - val_accuracy: 0.6771\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7135 - val_loss: 0.5597 - val_accuracy: 0.6771\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7153 - val_loss: 0.5594 - val_accuracy: 0.6771\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7170 - val_loss: 0.5590 - val_accuracy: 0.6771\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7170 - val_loss: 0.5586 - val_accuracy: 0.6771\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7170 - val_loss: 0.5583 - val_accuracy: 0.6823\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7170 - val_loss: 0.5579 - val_accuracy: 0.6823\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7135 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7153 - val_loss: 0.5572 - val_accuracy: 0.6823\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7118 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7118 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7135 - val_loss: 0.5562 - val_accuracy: 0.6875\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7135 - val_loss: 0.5559 - val_accuracy: 0.6875\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7135 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7135 - val_loss: 0.5552 - val_accuracy: 0.6875\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7135 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7153 - val_loss: 0.5546 - val_accuracy: 0.6823\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7153 - val_loss: 0.5542 - val_accuracy: 0.6823\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7153 - val_loss: 0.5539 - val_accuracy: 0.6823\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7153 - val_loss: 0.5536 - val_accuracy: 0.6823\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7135 - val_loss: 0.5533 - val_accuracy: 0.6823\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7101 - val_loss: 0.5530 - val_accuracy: 0.6823\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7135 - val_loss: 0.5526 - val_accuracy: 0.6875\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7118 - val_loss: 0.5523 - val_accuracy: 0.6875\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7118 - val_loss: 0.5520 - val_accuracy: 0.6875\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7118 - val_loss: 0.5516 - val_accuracy: 0.6875\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7118 - val_loss: 0.5513 - val_accuracy: 0.6875\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7118 - val_loss: 0.5510 - val_accuracy: 0.6875\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7135 - val_loss: 0.5506 - val_accuracy: 0.6823\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7135 - val_loss: 0.5503 - val_accuracy: 0.6823\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7135 - val_loss: 0.5500 - val_accuracy: 0.6823\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7153 - val_loss: 0.5497 - val_accuracy: 0.6823\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7153 - val_loss: 0.5493 - val_accuracy: 0.6823\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7153 - val_loss: 0.5490 - val_accuracy: 0.6823\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7153 - val_loss: 0.5487 - val_accuracy: 0.6823\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7153 - val_loss: 0.5484 - val_accuracy: 0.6823\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7153 - val_loss: 0.5481 - val_accuracy: 0.6823\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7153 - val_loss: 0.5478 - val_accuracy: 0.6771\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7188 - val_loss: 0.5475 - val_accuracy: 0.6771\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7205 - val_loss: 0.5472 - val_accuracy: 0.6771\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7205 - val_loss: 0.5469 - val_accuracy: 0.6771\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7240 - val_loss: 0.5466 - val_accuracy: 0.6771\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7205 - val_loss: 0.5463 - val_accuracy: 0.6771\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7240 - val_loss: 0.5460 - val_accuracy: 0.6771\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7240 - val_loss: 0.5457 - val_accuracy: 0.6771\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7257 - val_loss: 0.5454 - val_accuracy: 0.6771\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7274 - val_loss: 0.5451 - val_accuracy: 0.6771\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7274 - val_loss: 0.5448 - val_accuracy: 0.6823\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7274 - val_loss: 0.5445 - val_accuracy: 0.6823\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7274 - val_loss: 0.5442 - val_accuracy: 0.6823\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7274 - val_loss: 0.5439 - val_accuracy: 0.6823\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7257 - val_loss: 0.5436 - val_accuracy: 0.6823\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7292 - val_loss: 0.5433 - val_accuracy: 0.6823\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7309 - val_loss: 0.5430 - val_accuracy: 0.6823\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7309 - val_loss: 0.5427 - val_accuracy: 0.6823\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7326 - val_loss: 0.5424 - val_accuracy: 0.6823\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7326 - val_loss: 0.5421 - val_accuracy: 0.6823\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7326 - val_loss: 0.5418 - val_accuracy: 0.6823\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7344 - val_loss: 0.5415 - val_accuracy: 0.6771\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7344 - val_loss: 0.5412 - val_accuracy: 0.6771\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7344 - val_loss: 0.5409 - val_accuracy: 0.6771\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7344 - val_loss: 0.5406 - val_accuracy: 0.6771\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7344 - val_loss: 0.5403 - val_accuracy: 0.6771\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7344 - val_loss: 0.5401 - val_accuracy: 0.6771\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7344 - val_loss: 0.5398 - val_accuracy: 0.6771\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7344 - val_loss: 0.5395 - val_accuracy: 0.6771\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7344 - val_loss: 0.5392 - val_accuracy: 0.6771\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7344 - val_loss: 0.5389 - val_accuracy: 0.6771\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7344 - val_loss: 0.5387 - val_accuracy: 0.6771\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7344 - val_loss: 0.5384 - val_accuracy: 0.6771\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7344 - val_loss: 0.5381 - val_accuracy: 0.6771\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7344 - val_loss: 0.5379 - val_accuracy: 0.6771\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7344 - val_loss: 0.5376 - val_accuracy: 0.6771\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7344 - val_loss: 0.5373 - val_accuracy: 0.6823\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7326 - val_loss: 0.5371 - val_accuracy: 0.6823\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7361 - val_loss: 0.5368 - val_accuracy: 0.6823\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7378 - val_loss: 0.5366 - val_accuracy: 0.6875\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7326 - val_loss: 0.5363 - val_accuracy: 0.6875\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7344 - val_loss: 0.5361 - val_accuracy: 0.6875\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7361 - val_loss: 0.5358 - val_accuracy: 0.6927\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7361 - val_loss: 0.5356 - val_accuracy: 0.6927\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7396 - val_loss: 0.5353 - val_accuracy: 0.6927\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7361 - val_loss: 0.5351 - val_accuracy: 0.6927\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7378 - val_loss: 0.5348 - val_accuracy: 0.6927\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7378 - val_loss: 0.5346 - val_accuracy: 0.6927\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7396 - val_loss: 0.5344 - val_accuracy: 0.6927\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7378 - val_loss: 0.5341 - val_accuracy: 0.6927\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7448 - val_loss: 0.5339 - val_accuracy: 0.6927\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7448 - val_loss: 0.5337 - val_accuracy: 0.6927\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7448 - val_loss: 0.5335 - val_accuracy: 0.6927\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7448 - val_loss: 0.5332 - val_accuracy: 0.6979\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7465 - val_loss: 0.5330 - val_accuracy: 0.6979\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7465 - val_loss: 0.5328 - val_accuracy: 0.6979\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7465 - val_loss: 0.5326 - val_accuracy: 0.6979\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7483 - val_loss: 0.5323 - val_accuracy: 0.6979\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7483 - val_loss: 0.5321 - val_accuracy: 0.6979\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7500 - val_loss: 0.5319 - val_accuracy: 0.6979\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7500 - val_loss: 0.5317 - val_accuracy: 0.6979\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.5315 - val_accuracy: 0.6979\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.6979\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7483 - val_loss: 0.5310 - val_accuracy: 0.6979\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7483 - val_loss: 0.5308 - val_accuracy: 0.6979\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7483 - val_loss: 0.5306 - val_accuracy: 0.6979\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7483 - val_loss: 0.5303 - val_accuracy: 0.6979\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7483 - val_loss: 0.5301 - val_accuracy: 0.6979\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7483 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7483 - val_loss: 0.5297 - val_accuracy: 0.6979\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7483 - val_loss: 0.5295 - val_accuracy: 0.6979\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7483 - val_loss: 0.5292 - val_accuracy: 0.6979\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7483 - val_loss: 0.5290 - val_accuracy: 0.6979\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7500 - val_loss: 0.5288 - val_accuracy: 0.6979\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7517 - val_loss: 0.5286 - val_accuracy: 0.6979\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7517 - val_loss: 0.5284 - val_accuracy: 0.6979\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7517 - val_loss: 0.5282 - val_accuracy: 0.6979\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7517 - val_loss: 0.5279 - val_accuracy: 0.6979\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7517 - val_loss: 0.5277 - val_accuracy: 0.6979\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7535 - val_loss: 0.5275 - val_accuracy: 0.6979\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7535 - val_loss: 0.5273 - val_accuracy: 0.6979\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7535 - val_loss: 0.5271 - val_accuracy: 0.6979\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7535 - val_loss: 0.5269 - val_accuracy: 0.6979\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7535 - val_loss: 0.5267 - val_accuracy: 0.6979\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7552 - val_loss: 0.5265 - val_accuracy: 0.6979\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7569 - val_loss: 0.5263 - val_accuracy: 0.6979\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5261 - val_accuracy: 0.6979\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7569 - val_loss: 0.5260 - val_accuracy: 0.6979\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7569 - val_loss: 0.5258 - val_accuracy: 0.6979\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7569 - val_loss: 0.5256 - val_accuracy: 0.6979\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7569 - val_loss: 0.5254 - val_accuracy: 0.6979\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7587 - val_loss: 0.5252 - val_accuracy: 0.6979\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7587 - val_loss: 0.5250 - val_accuracy: 0.7031\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7587 - val_loss: 0.5248 - val_accuracy: 0.7031\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7587 - val_loss: 0.5246 - val_accuracy: 0.7031\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7587 - val_loss: 0.5244 - val_accuracy: 0.7031\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7031\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7031\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7031\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7031\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.5235 - val_accuracy: 0.7031\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5233 - val_accuracy: 0.7031\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7031\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7135\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.5228 - val_accuracy: 0.7083\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7083\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7135\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5220 - val_accuracy: 0.7135\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7188\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7188\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7188\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7188\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7188\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7188\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7188\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7188\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7188\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.5183 - val_accuracy: 0.7188\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.5181 - val_accuracy: 0.7240\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7240\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7240\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7240\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7778 - val_loss: 0.5173 - val_accuracy: 0.7240\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7240\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7778 - val_loss: 0.5170 - val_accuracy: 0.7240\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7240\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7778 - val_loss: 0.5168 - val_accuracy: 0.7240\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7240\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.5165 - val_accuracy: 0.7240\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7795 - val_loss: 0.5164 - val_accuracy: 0.7240\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7240\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7240\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7795 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7795 - val_loss: 0.5159 - val_accuracy: 0.7240\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7240\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7240\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.5155 - val_accuracy: 0.7240\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7795 - val_loss: 0.5154 - val_accuracy: 0.7240\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7240\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.5150 - val_accuracy: 0.7240\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7240\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7240\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7240\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7292\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7292\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7812 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7292\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7292\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7292\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7292\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.5113 - val_accuracy: 0.7292\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7292\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7344\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7344\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7344\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7344\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7396\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7934 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7934 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7951 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7396\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7396\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7396\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7396\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7396\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7396\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7396\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7396\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7396\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7396\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7396\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7396\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "run_hist_model_1n = model_1n.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrmb-lSdtDfN",
        "outputId": "a0853348-d865-47b2-a124-248659e11d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1n = model_1n.predict(X_test_norm)\n",
        "y_pred_class_model_1n = (y_pred_prob_model_1n >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkQq0uEPuJfr",
        "outputId": "91ba7405-d4dc-4a4d-d2e2-5cbaaac0a2eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.72667974],\n",
              "       [0.5687562 ],\n",
              "       [0.8360721 ],\n",
              "       [0.05596207],\n",
              "       [0.54750067],\n",
              "       [0.8061042 ],\n",
              "       [0.64465576],\n",
              "       [0.08659498],\n",
              "       [0.07597728],\n",
              "       [0.90766674]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtinq5fstmj4",
        "outputId": "4e74c068-8e56-4e36-b49e-05222c1ad9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_class_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "30JuS6TgutWr",
        "outputId": "953a6911-afa7-4361-8e93-d31211130947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.750\n",
            "roc-auc is 0.811\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1n)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1n)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1n, 'new mode 1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhvgY9a6zG32",
        "outputId": "caa438ce-a8a9-40e6-c95e-c359032a0aed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_model_1n.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "hkBOaxXizL-5",
        "outputId": "bb7b7b85-c96d-4981-ead7-d4fca0b81da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x21088da32b0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1n.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1n.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1n.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1n.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlDTP-7r03st"
      },
      "source": [
        "ข้อ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKa3-6vo1NY5",
        "outputId": "53937cc9-375b-455d-b969-ddc0dc89421f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
          ]
        }
      ],
      "source": [
        "model_1nc = Sequential([\n",
        "    Dense(6, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_1nc.summary()\n",
        "# compile new_model_1\n",
        "model_1nc.compile(optimizer=SGD(learning_rate=0.0002), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIz6BYz91WIx",
        "outputId": "5a3688ad-86e3-49b3-cdeb-901a2bc434a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-24 19:49:37.516078: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36/36 [==============================] - 1s 9ms/step - loss: 0.6835 - accuracy: 0.5955 - val_loss: 0.6762 - val_accuracy: 0.6198\n",
            "Epoch 2/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5972 - val_loss: 0.6741 - val_accuracy: 0.6198\n",
            "Epoch 3/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.5990 - val_loss: 0.6721 - val_accuracy: 0.6198\n",
            "Epoch 4/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.6024 - val_loss: 0.6701 - val_accuracy: 0.6198\n",
            "Epoch 5/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6752 - accuracy: 0.6042 - val_loss: 0.6682 - val_accuracy: 0.6198\n",
            "Epoch 6/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6731 - accuracy: 0.6076 - val_loss: 0.6663 - val_accuracy: 0.6198\n",
            "Epoch 7/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.6111 - val_loss: 0.6644 - val_accuracy: 0.6250\n",
            "Epoch 8/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.6163 - val_loss: 0.6626 - val_accuracy: 0.6302\n",
            "Epoch 9/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6674 - accuracy: 0.6163 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 10/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.6181 - val_loss: 0.6589 - val_accuracy: 0.6302\n",
            "Epoch 11/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.6181 - val_loss: 0.6571 - val_accuracy: 0.6302\n",
            "Epoch 12/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6618 - accuracy: 0.6198 - val_loss: 0.6554 - val_accuracy: 0.6302\n",
            "Epoch 13/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6599 - accuracy: 0.6233 - val_loss: 0.6537 - val_accuracy: 0.6302\n",
            "Epoch 14/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.6250 - val_loss: 0.6520 - val_accuracy: 0.6250\n",
            "Epoch 15/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6564 - accuracy: 0.6267 - val_loss: 0.6503 - val_accuracy: 0.6250\n",
            "Epoch 16/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6546 - accuracy: 0.6285 - val_loss: 0.6486 - val_accuracy: 0.6250\n",
            "Epoch 17/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.6285 - val_loss: 0.6470 - val_accuracy: 0.6250\n",
            "Epoch 18/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6513 - accuracy: 0.6302 - val_loss: 0.6454 - val_accuracy: 0.6302\n",
            "Epoch 19/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.6337 - val_loss: 0.6438 - val_accuracy: 0.6302\n",
            "Epoch 20/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6479 - accuracy: 0.6337 - val_loss: 0.6423 - val_accuracy: 0.6302\n",
            "Epoch 21/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6463 - accuracy: 0.6354 - val_loss: 0.6407 - val_accuracy: 0.6302\n",
            "Epoch 22/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.6406 - val_loss: 0.6392 - val_accuracy: 0.6354\n",
            "Epoch 23/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.6406 - val_loss: 0.6377 - val_accuracy: 0.6354\n",
            "Epoch 24/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6416 - accuracy: 0.6441 - val_loss: 0.6362 - val_accuracy: 0.6406\n",
            "Epoch 25/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6400 - accuracy: 0.6476 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
            "Epoch 26/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6493 - val_loss: 0.6334 - val_accuracy: 0.6406\n",
            "Epoch 27/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.6370 - accuracy: 0.6493 - val_loss: 0.6320 - val_accuracy: 0.6458\n",
            "Epoch 28/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6356 - accuracy: 0.6545 - val_loss: 0.6306 - val_accuracy: 0.6510\n",
            "Epoch 29/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6545 - val_loss: 0.6292 - val_accuracy: 0.6510\n",
            "Epoch 30/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6580 - val_loss: 0.6279 - val_accuracy: 0.6562\n",
            "Epoch 31/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6615 - val_loss: 0.6266 - val_accuracy: 0.6562\n",
            "Epoch 32/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.6632 - val_loss: 0.6253 - val_accuracy: 0.6562\n",
            "Epoch 33/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.6632 - val_loss: 0.6240 - val_accuracy: 0.6562\n",
            "Epoch 34/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6632 - val_loss: 0.6227 - val_accuracy: 0.6562\n",
            "Epoch 35/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.6632 - val_loss: 0.6214 - val_accuracy: 0.6562\n",
            "Epoch 36/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6244 - accuracy: 0.6667 - val_loss: 0.6202 - val_accuracy: 0.6562\n",
            "Epoch 37/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6667 - val_loss: 0.6190 - val_accuracy: 0.6562\n",
            "Epoch 38/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6684 - val_loss: 0.6178 - val_accuracy: 0.6615\n",
            "Epoch 39/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.6719 - val_loss: 0.6166 - val_accuracy: 0.6667\n",
            "Epoch 40/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6719 - val_loss: 0.6154 - val_accuracy: 0.6667\n",
            "Epoch 41/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.6753 - val_loss: 0.6143 - val_accuracy: 0.6667\n",
            "Epoch 42/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6788 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
            "Epoch 43/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6156 - accuracy: 0.6806 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
            "Epoch 44/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6144 - accuracy: 0.6840 - val_loss: 0.6109 - val_accuracy: 0.6667\n",
            "Epoch 45/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.6823 - val_loss: 0.6098 - val_accuracy: 0.6719\n",
            "Epoch 46/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.6823 - val_loss: 0.6087 - val_accuracy: 0.6719\n",
            "Epoch 47/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.6840 - val_loss: 0.6077 - val_accuracy: 0.6719\n",
            "Epoch 48/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.6858 - val_loss: 0.6066 - val_accuracy: 0.6719\n",
            "Epoch 49/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6840 - val_loss: 0.6056 - val_accuracy: 0.6719\n",
            "Epoch 50/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6076 - accuracy: 0.6858 - val_loss: 0.6046 - val_accuracy: 0.6719\n",
            "Epoch 51/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.6892 - val_loss: 0.6036 - val_accuracy: 0.6667\n",
            "Epoch 52/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.6910 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
            "Epoch 53/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.6892 - val_loss: 0.6016 - val_accuracy: 0.6667\n",
            "Epoch 54/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.6927 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
            "Epoch 55/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.6944 - val_loss: 0.5997 - val_accuracy: 0.6667\n",
            "Epoch 56/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6962 - val_loss: 0.5987 - val_accuracy: 0.6667\n",
            "Epoch 57/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.6962 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
            "Epoch 58/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5992 - accuracy: 0.6944 - val_loss: 0.5969 - val_accuracy: 0.6667\n",
            "Epoch 59/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.6962 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 60/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.6979 - val_loss: 0.5951 - val_accuracy: 0.6667\n",
            "Epoch 61/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5962 - accuracy: 0.6997 - val_loss: 0.5942 - val_accuracy: 0.6615\n",
            "Epoch 62/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.7031 - val_loss: 0.5933 - val_accuracy: 0.6615\n",
            "Epoch 63/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5943 - accuracy: 0.7014 - val_loss: 0.5925 - val_accuracy: 0.6615\n",
            "Epoch 64/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.7031 - val_loss: 0.5916 - val_accuracy: 0.6615\n",
            "Epoch 65/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7031 - val_loss: 0.5908 - val_accuracy: 0.6615\n",
            "Epoch 66/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.7049 - val_loss: 0.5900 - val_accuracy: 0.6615\n",
            "Epoch 67/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7049 - val_loss: 0.5892 - val_accuracy: 0.6667\n",
            "Epoch 68/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5897 - accuracy: 0.7083 - val_loss: 0.5884 - val_accuracy: 0.6667\n",
            "Epoch 69/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.7118 - val_loss: 0.5876 - val_accuracy: 0.6719\n",
            "Epoch 70/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7118 - val_loss: 0.5868 - val_accuracy: 0.6719\n",
            "Epoch 71/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5872 - accuracy: 0.7135 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
            "Epoch 72/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7135 - val_loss: 0.5853 - val_accuracy: 0.6823\n",
            "Epoch 73/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7118 - val_loss: 0.5845 - val_accuracy: 0.6823\n",
            "Epoch 74/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5846 - accuracy: 0.7135 - val_loss: 0.5838 - val_accuracy: 0.6771\n",
            "Epoch 75/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7135 - val_loss: 0.5830 - val_accuracy: 0.6771\n",
            "Epoch 76/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7153 - val_loss: 0.5823 - val_accuracy: 0.6771\n",
            "Epoch 77/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.7170 - val_loss: 0.5816 - val_accuracy: 0.6771\n",
            "Epoch 78/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7170 - val_loss: 0.5809 - val_accuracy: 0.6771\n",
            "Epoch 79/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.7153 - val_loss: 0.5802 - val_accuracy: 0.6771\n",
            "Epoch 80/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.7153 - val_loss: 0.5795 - val_accuracy: 0.6823\n",
            "Epoch 81/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.7153 - val_loss: 0.5788 - val_accuracy: 0.6823\n",
            "Epoch 82/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5784 - accuracy: 0.7153 - val_loss: 0.5782 - val_accuracy: 0.6823\n",
            "Epoch 83/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5776 - accuracy: 0.7135 - val_loss: 0.5775 - val_accuracy: 0.6823\n",
            "Epoch 84/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5768 - accuracy: 0.7118 - val_loss: 0.5768 - val_accuracy: 0.6823\n",
            "Epoch 85/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5761 - accuracy: 0.7153 - val_loss: 0.5762 - val_accuracy: 0.6823\n",
            "Epoch 86/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.7153 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
            "Epoch 87/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7153 - val_loss: 0.5749 - val_accuracy: 0.6875\n",
            "Epoch 88/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.7153 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
            "Epoch 89/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.7135 - val_loss: 0.5737 - val_accuracy: 0.6927\n",
            "Epoch 90/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5726 - accuracy: 0.7135 - val_loss: 0.5731 - val_accuracy: 0.6927\n",
            "Epoch 91/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.7135 - val_loss: 0.5725 - val_accuracy: 0.6927\n",
            "Epoch 92/1500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.7135 - val_loss: 0.5719 - val_accuracy: 0.6979\n",
            "Epoch 93/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.7135 - val_loss: 0.5713 - val_accuracy: 0.6979\n",
            "Epoch 94/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5699 - accuracy: 0.7153 - val_loss: 0.5708 - val_accuracy: 0.6979\n",
            "Epoch 95/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7153 - val_loss: 0.5702 - val_accuracy: 0.6979\n",
            "Epoch 96/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.7153 - val_loss: 0.5696 - val_accuracy: 0.6979\n",
            "Epoch 97/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.7170 - val_loss: 0.5691 - val_accuracy: 0.6979\n",
            "Epoch 98/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5674 - accuracy: 0.7188 - val_loss: 0.5685 - val_accuracy: 0.6927\n",
            "Epoch 99/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5668 - accuracy: 0.7205 - val_loss: 0.5680 - val_accuracy: 0.7031\n",
            "Epoch 100/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7205 - val_loss: 0.5674 - val_accuracy: 0.7031\n",
            "Epoch 101/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.7205 - val_loss: 0.5669 - val_accuracy: 0.7083\n",
            "Epoch 102/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7188 - val_loss: 0.5664 - val_accuracy: 0.7083\n",
            "Epoch 103/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5644 - accuracy: 0.7188 - val_loss: 0.5659 - val_accuracy: 0.7135\n",
            "Epoch 104/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7188 - val_loss: 0.5653 - val_accuracy: 0.7188\n",
            "Epoch 105/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5632 - accuracy: 0.7188 - val_loss: 0.5648 - val_accuracy: 0.7188\n",
            "Epoch 106/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7188 - val_loss: 0.5643 - val_accuracy: 0.7188\n",
            "Epoch 107/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.7188 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
            "Epoch 108/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5615 - accuracy: 0.7205 - val_loss: 0.5633 - val_accuracy: 0.7188\n",
            "Epoch 109/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5609 - accuracy: 0.7205 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
            "Epoch 110/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.7205 - val_loss: 0.5624 - val_accuracy: 0.7188\n",
            "Epoch 111/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7222 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 112/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7222 - val_loss: 0.5614 - val_accuracy: 0.7188\n",
            "Epoch 113/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7240 - val_loss: 0.5610 - val_accuracy: 0.7188\n",
            "Epoch 114/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7257 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 115/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7274 - val_loss: 0.5600 - val_accuracy: 0.7240\n",
            "Epoch 116/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7292 - val_loss: 0.5596 - val_accuracy: 0.7240\n",
            "Epoch 117/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7292 - val_loss: 0.5591 - val_accuracy: 0.7240\n",
            "Epoch 118/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7309 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
            "Epoch 119/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5556 - accuracy: 0.7344 - val_loss: 0.5583 - val_accuracy: 0.7292\n",
            "Epoch 120/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7344 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
            "Epoch 121/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7361 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
            "Epoch 122/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7361 - val_loss: 0.5570 - val_accuracy: 0.7240\n",
            "Epoch 123/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.7361 - val_loss: 0.5566 - val_accuracy: 0.7240\n",
            "Epoch 124/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7361 - val_loss: 0.5562 - val_accuracy: 0.7240\n",
            "Epoch 125/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7361 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
            "Epoch 126/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7396 - val_loss: 0.5553 - val_accuracy: 0.7240\n",
            "Epoch 127/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7396 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
            "Epoch 128/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7396 - val_loss: 0.5546 - val_accuracy: 0.7240\n",
            "Epoch 129/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
            "Epoch 130/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5503 - accuracy: 0.7396 - val_loss: 0.5538 - val_accuracy: 0.7240\n",
            "Epoch 131/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.7378 - val_loss: 0.5534 - val_accuracy: 0.7240\n",
            "Epoch 132/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7396 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
            "Epoch 133/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7396 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 134/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.7413 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 135/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7413 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
            "Epoch 136/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7448 - val_loss: 0.5515 - val_accuracy: 0.7240\n",
            "Epoch 137/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7431 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 138/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7431 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 139/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7448 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
            "Epoch 140/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7448 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 141/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7448 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
            "Epoch 142/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7448 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
            "Epoch 143/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7448 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 144/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7448 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 145/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7448 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 146/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7431 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 147/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7431 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
            "Epoch 148/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7413 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 149/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7431 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 150/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7413 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 151/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7413 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 152/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7431 - val_loss: 0.5462 - val_accuracy: 0.7188\n",
            "Epoch 153/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7431 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
            "Epoch 154/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7413 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
            "Epoch 155/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7431 - val_loss: 0.5453 - val_accuracy: 0.7188\n",
            "Epoch 156/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7431 - val_loss: 0.5450 - val_accuracy: 0.7188\n",
            "Epoch 157/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7448 - val_loss: 0.5447 - val_accuracy: 0.7188\n",
            "Epoch 158/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7448 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
            "Epoch 159/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7465 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
            "Epoch 160/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7465 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
            "Epoch 161/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7483 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
            "Epoch 162/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7483 - val_loss: 0.5432 - val_accuracy: 0.7188\n",
            "Epoch 163/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5430 - val_accuracy: 0.7188\n",
            "Epoch 164/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.7517 - val_loss: 0.5427 - val_accuracy: 0.7188\n",
            "Epoch 165/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7552 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
            "Epoch 166/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7535 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
            "Epoch 167/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7552 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
            "Epoch 168/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7569 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
            "Epoch 169/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7569 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
            "Epoch 170/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7569 - val_loss: 0.5411 - val_accuracy: 0.7188\n",
            "Epoch 171/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7569 - val_loss: 0.5408 - val_accuracy: 0.7188\n",
            "Epoch 172/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7552 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
            "Epoch 173/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7552 - val_loss: 0.5403 - val_accuracy: 0.7188\n",
            "Epoch 174/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7552 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
            "Epoch 175/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7552 - val_loss: 0.5398 - val_accuracy: 0.7240\n",
            "Epoch 176/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7569 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
            "Epoch 177/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7569 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
            "Epoch 178/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7569 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
            "Epoch 179/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7569 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
            "Epoch 180/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7569 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
            "Epoch 181/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7569 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
            "Epoch 182/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7569 - val_loss: 0.5381 - val_accuracy: 0.7240\n",
            "Epoch 183/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7569 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
            "Epoch 184/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7587 - val_loss: 0.5376 - val_accuracy: 0.7240\n",
            "Epoch 185/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7587 - val_loss: 0.5374 - val_accuracy: 0.7240\n",
            "Epoch 186/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7587 - val_loss: 0.5372 - val_accuracy: 0.7240\n",
            "Epoch 187/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7569 - val_loss: 0.5370 - val_accuracy: 0.7240\n",
            "Epoch 188/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7604 - val_loss: 0.5367 - val_accuracy: 0.7240\n",
            "Epoch 189/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7604 - val_loss: 0.5365 - val_accuracy: 0.7240\n",
            "Epoch 190/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7604 - val_loss: 0.5363 - val_accuracy: 0.7240\n",
            "Epoch 191/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7604 - val_loss: 0.5361 - val_accuracy: 0.7240\n",
            "Epoch 192/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7604 - val_loss: 0.5358 - val_accuracy: 0.7240\n",
            "Epoch 193/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.7604 - val_loss: 0.5356 - val_accuracy: 0.7240\n",
            "Epoch 194/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7587 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
            "Epoch 195/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7587 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
            "Epoch 196/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7604 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
            "Epoch 197/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7604 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
            "Epoch 198/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7587 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
            "Epoch 199/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7587 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
            "Epoch 200/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7587 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
            "Epoch 201/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7587 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
            "Epoch 202/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7587 - val_loss: 0.5338 - val_accuracy: 0.7292\n",
            "Epoch 203/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7587 - val_loss: 0.5336 - val_accuracy: 0.7292\n",
            "Epoch 204/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7587 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
            "Epoch 205/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7587 - val_loss: 0.5332 - val_accuracy: 0.7292\n",
            "Epoch 206/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5250 - accuracy: 0.7587 - val_loss: 0.5330 - val_accuracy: 0.7292\n",
            "Epoch 207/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7587 - val_loss: 0.5328 - val_accuracy: 0.7292\n",
            "Epoch 208/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7587 - val_loss: 0.5326 - val_accuracy: 0.7292\n",
            "Epoch 209/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7604 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 210/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7604 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
            "Epoch 211/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7604 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
            "Epoch 212/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7604 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
            "Epoch 213/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.7604 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
            "Epoch 214/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5232 - accuracy: 0.7604 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
            "Epoch 215/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7604 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
            "Epoch 216/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7604 - val_loss: 0.5311 - val_accuracy: 0.7240\n",
            "Epoch 217/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7604 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
            "Epoch 218/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7622 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
            "Epoch 219/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7622 - val_loss: 0.5306 - val_accuracy: 0.7292\n",
            "Epoch 220/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7622 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
            "Epoch 221/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7622 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
            "Epoch 222/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
            "Epoch 223/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
            "Epoch 224/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7622 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
            "Epoch 225/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7622 - val_loss: 0.5296 - val_accuracy: 0.7344\n",
            "Epoch 226/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7604 - val_loss: 0.5294 - val_accuracy: 0.7344\n",
            "Epoch 227/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7604 - val_loss: 0.5293 - val_accuracy: 0.7344\n",
            "Epoch 228/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7604 - val_loss: 0.5291 - val_accuracy: 0.7292\n",
            "Epoch 229/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7604 - val_loss: 0.5289 - val_accuracy: 0.7292\n",
            "Epoch 230/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7622 - val_loss: 0.5288 - val_accuracy: 0.7292\n",
            "Epoch 231/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7604 - val_loss: 0.5286 - val_accuracy: 0.7292\n",
            "Epoch 232/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.7622 - val_loss: 0.5285 - val_accuracy: 0.7292\n",
            "Epoch 233/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7622 - val_loss: 0.5283 - val_accuracy: 0.7292\n",
            "Epoch 234/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7622 - val_loss: 0.5282 - val_accuracy: 0.7292\n",
            "Epoch 235/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7622 - val_loss: 0.5280 - val_accuracy: 0.7292\n",
            "Epoch 236/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5185 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
            "Epoch 237/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7622 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
            "Epoch 238/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7622 - val_loss: 0.5276 - val_accuracy: 0.7292\n",
            "Epoch 239/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7622 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
            "Epoch 240/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7622 - val_loss: 0.5273 - val_accuracy: 0.7292\n",
            "Epoch 241/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
            "Epoch 242/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
            "Epoch 243/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7622 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
            "Epoch 244/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7622 - val_loss: 0.5267 - val_accuracy: 0.7292\n",
            "Epoch 245/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7622 - val_loss: 0.5265 - val_accuracy: 0.7292\n",
            "Epoch 246/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7292\n",
            "Epoch 247/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7622 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
            "Epoch 248/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7292\n",
            "Epoch 249/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7292\n",
            "Epoch 250/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7622 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
            "Epoch 251/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
            "Epoch 252/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7639 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
            "Epoch 253/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7622 - val_loss: 0.5254 - val_accuracy: 0.7292\n",
            "Epoch 254/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7622 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
            "Epoch 255/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
            "Epoch 256/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7622 - val_loss: 0.5250 - val_accuracy: 0.7292\n",
            "Epoch 257/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7639 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
            "Epoch 258/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7639 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
            "Epoch 259/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7639 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 260/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 261/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 262/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7639 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 263/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 264/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7656 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
            "Epoch 265/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7656 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 266/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7674 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
            "Epoch 267/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7674 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
            "Epoch 268/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7674 - val_loss: 0.5235 - val_accuracy: 0.7344\n",
            "Epoch 269/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7691 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
            "Epoch 270/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7691 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 271/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7691 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
            "Epoch 272/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7691 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 273/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.7691 - val_loss: 0.5229 - val_accuracy: 0.7344\n",
            "Epoch 274/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7691 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
            "Epoch 275/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7691 - val_loss: 0.5227 - val_accuracy: 0.7292\n",
            "Epoch 276/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
            "Epoch 277/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7691 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
            "Epoch 278/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7292\n",
            "Epoch 279/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
            "Epoch 280/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
            "Epoch 281/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
            "Epoch 282/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
            "Epoch 283/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
            "Epoch 284/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
            "Epoch 285/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
            "Epoch 286/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7708 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
            "Epoch 287/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
            "Epoch 288/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7708 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
            "Epoch 289/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
            "Epoch 290/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
            "Epoch 291/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
            "Epoch 292/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
            "Epoch 293/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7292\n",
            "Epoch 294/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
            "Epoch 295/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7292\n",
            "Epoch 296/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
            "Epoch 297/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7292\n",
            "Epoch 298/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
            "Epoch 299/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7292\n",
            "Epoch 300/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7708 - val_loss: 0.5200 - val_accuracy: 0.7292\n",
            "Epoch 301/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7292\n",
            "Epoch 302/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7292\n",
            "Epoch 303/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7292\n",
            "Epoch 304/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7708 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
            "Epoch 305/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
            "Epoch 306/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7691 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
            "Epoch 307/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7691 - val_loss: 0.5193 - val_accuracy: 0.7292\n",
            "Epoch 308/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7691 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
            "Epoch 309/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7691 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
            "Epoch 310/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
            "Epoch 311/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7726 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
            "Epoch 312/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
            "Epoch 313/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
            "Epoch 314/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
            "Epoch 315/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
            "Epoch 316/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.7708 - val_loss: 0.5184 - val_accuracy: 0.7188\n",
            "Epoch 317/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7188\n",
            "Epoch 318/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7188\n",
            "Epoch 319/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7188\n",
            "Epoch 320/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7708 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
            "Epoch 321/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
            "Epoch 322/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
            "Epoch 323/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
            "Epoch 324/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7726 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
            "Epoch 325/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7188\n",
            "Epoch 326/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7726 - val_loss: 0.5175 - val_accuracy: 0.7188\n",
            "Epoch 327/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7188\n",
            "Epoch 328/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.7726 - val_loss: 0.5173 - val_accuracy: 0.7188\n",
            "Epoch 329/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7708 - val_loss: 0.5172 - val_accuracy: 0.7188\n",
            "Epoch 330/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7708 - val_loss: 0.5171 - val_accuracy: 0.7188\n",
            "Epoch 331/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7708 - val_loss: 0.5171 - val_accuracy: 0.7188\n",
            "Epoch 332/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7708 - val_loss: 0.5170 - val_accuracy: 0.7188\n",
            "Epoch 333/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7708 - val_loss: 0.5169 - val_accuracy: 0.7188\n",
            "Epoch 334/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7708 - val_loss: 0.5168 - val_accuracy: 0.7188\n",
            "Epoch 335/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7708 - val_loss: 0.5167 - val_accuracy: 0.7188\n",
            "Epoch 336/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7188\n",
            "Epoch 337/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7188\n",
            "Epoch 338/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7188\n",
            "Epoch 339/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7188\n",
            "Epoch 340/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7726 - val_loss: 0.5163 - val_accuracy: 0.7188\n",
            "Epoch 341/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7726 - val_loss: 0.5162 - val_accuracy: 0.7135\n",
            "Epoch 342/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7135\n",
            "Epoch 343/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7135\n",
            "Epoch 344/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7135\n",
            "Epoch 345/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7135\n",
            "Epoch 346/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7726 - val_loss: 0.5158 - val_accuracy: 0.7135\n",
            "Epoch 347/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7135\n",
            "Epoch 348/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7135\n",
            "Epoch 349/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7135\n",
            "Epoch 350/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7726 - val_loss: 0.5155 - val_accuracy: 0.7135\n",
            "Epoch 351/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7135\n",
            "Epoch 352/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7726 - val_loss: 0.5153 - val_accuracy: 0.7135\n",
            "Epoch 353/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7726 - val_loss: 0.5152 - val_accuracy: 0.7135\n",
            "Epoch 354/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7726 - val_loss: 0.5152 - val_accuracy: 0.7135\n",
            "Epoch 355/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7726 - val_loss: 0.5151 - val_accuracy: 0.7135\n",
            "Epoch 356/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.7726 - val_loss: 0.5150 - val_accuracy: 0.7135\n",
            "Epoch 357/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7135\n",
            "Epoch 358/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7135\n",
            "Epoch 359/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7135\n",
            "Epoch 360/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7135\n",
            "Epoch 361/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7135\n",
            "Epoch 362/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7135\n",
            "Epoch 363/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7135\n",
            "Epoch 364/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7135\n",
            "Epoch 365/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7083\n",
            "Epoch 366/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7726 - val_loss: 0.5142 - val_accuracy: 0.7083\n",
            "Epoch 367/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7083\n",
            "Epoch 368/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7083\n",
            "Epoch 369/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7083\n",
            "Epoch 370/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7743 - val_loss: 0.5140 - val_accuracy: 0.7083\n",
            "Epoch 371/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7726 - val_loss: 0.5139 - val_accuracy: 0.7083\n",
            "Epoch 372/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7708 - val_loss: 0.5138 - val_accuracy: 0.7083\n",
            "Epoch 373/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7726 - val_loss: 0.5137 - val_accuracy: 0.7083\n",
            "Epoch 374/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7726 - val_loss: 0.5137 - val_accuracy: 0.7083\n",
            "Epoch 375/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7726 - val_loss: 0.5136 - val_accuracy: 0.7135\n",
            "Epoch 376/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7135\n",
            "Epoch 377/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7135\n",
            "Epoch 378/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7743 - val_loss: 0.5134 - val_accuracy: 0.7135\n",
            "Epoch 379/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7726 - val_loss: 0.5133 - val_accuracy: 0.7135\n",
            "Epoch 380/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7726 - val_loss: 0.5132 - val_accuracy: 0.7135\n",
            "Epoch 381/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7743 - val_loss: 0.5132 - val_accuracy: 0.7135\n",
            "Epoch 382/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7135\n",
            "Epoch 383/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7743 - val_loss: 0.5130 - val_accuracy: 0.7135\n",
            "Epoch 384/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7743 - val_loss: 0.5130 - val_accuracy: 0.7135\n",
            "Epoch 385/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7135\n",
            "Epoch 386/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7135\n",
            "Epoch 387/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7743 - val_loss: 0.5128 - val_accuracy: 0.7135\n",
            "Epoch 388/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7743 - val_loss: 0.5127 - val_accuracy: 0.7135\n",
            "Epoch 389/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7135\n",
            "Epoch 390/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7743 - val_loss: 0.5126 - val_accuracy: 0.7135\n",
            "Epoch 391/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7135\n",
            "Epoch 392/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7135\n",
            "Epoch 393/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7135\n",
            "Epoch 394/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7760 - val_loss: 0.5123 - val_accuracy: 0.7135\n",
            "Epoch 395/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7743 - val_loss: 0.5122 - val_accuracy: 0.7135\n",
            "Epoch 396/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7135\n",
            "Epoch 397/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7135\n",
            "Epoch 398/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7760 - val_loss: 0.5120 - val_accuracy: 0.7135\n",
            "Epoch 399/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.7760 - val_loss: 0.5120 - val_accuracy: 0.7135\n",
            "Epoch 400/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7135\n",
            "Epoch 401/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7135\n",
            "Epoch 402/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7135\n",
            "Epoch 403/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7135\n",
            "Epoch 404/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7135\n",
            "Epoch 405/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7135\n",
            "Epoch 406/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7135\n",
            "Epoch 407/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7135\n",
            "Epoch 408/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7135\n",
            "Epoch 409/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7083\n",
            "Epoch 410/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7083\n",
            "Epoch 411/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7083\n",
            "Epoch 412/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7083\n",
            "Epoch 413/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4958 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7083\n",
            "Epoch 414/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7083\n",
            "Epoch 415/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7083\n",
            "Epoch 416/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7083\n",
            "Epoch 417/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7083\n",
            "Epoch 418/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7083\n",
            "Epoch 419/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7083\n",
            "Epoch 420/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7083\n",
            "Epoch 421/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7083\n",
            "Epoch 422/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7083\n",
            "Epoch 423/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7083\n",
            "Epoch 424/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7083\n",
            "Epoch 425/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7083\n",
            "Epoch 426/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7083\n",
            "Epoch 427/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7083\n",
            "Epoch 428/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7743 - val_loss: 0.5103 - val_accuracy: 0.7083\n",
            "Epoch 429/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7083\n",
            "Epoch 430/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7083\n",
            "Epoch 431/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7083\n",
            "Epoch 432/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7743 - val_loss: 0.5101 - val_accuracy: 0.7083\n",
            "Epoch 433/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7083\n",
            "Epoch 434/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7083\n",
            "Epoch 435/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7083\n",
            "Epoch 436/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7083\n",
            "Epoch 437/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7083\n",
            "Epoch 438/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7760 - val_loss: 0.5098 - val_accuracy: 0.7083\n",
            "Epoch 439/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7083\n",
            "Epoch 440/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7083\n",
            "Epoch 441/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7083\n",
            "Epoch 442/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7083\n",
            "Epoch 443/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7083\n",
            "Epoch 444/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7083\n",
            "Epoch 445/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7083\n",
            "Epoch 446/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7083\n",
            "Epoch 447/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7083\n",
            "Epoch 448/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7083\n",
            "Epoch 449/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7083\n",
            "Epoch 450/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7083\n",
            "Epoch 451/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7083\n",
            "Epoch 452/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7812 - val_loss: 0.5091 - val_accuracy: 0.7083\n",
            "Epoch 453/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7812 - val_loss: 0.5090 - val_accuracy: 0.7083\n",
            "Epoch 454/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7083\n",
            "Epoch 455/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7083\n",
            "Epoch 456/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7083\n",
            "Epoch 457/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7083\n",
            "Epoch 458/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7083\n",
            "Epoch 459/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7083\n",
            "Epoch 460/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7830 - val_loss: 0.5087 - val_accuracy: 0.7083\n",
            "Epoch 461/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7083\n",
            "Epoch 462/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7083\n",
            "Epoch 463/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7083\n",
            "Epoch 464/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7083\n",
            "Epoch 465/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7083\n",
            "Epoch 466/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7083\n",
            "Epoch 467/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7083\n",
            "Epoch 468/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7083\n",
            "Epoch 469/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7083\n",
            "Epoch 470/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7083\n",
            "Epoch 471/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7083\n",
            "Epoch 472/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7083\n",
            "Epoch 473/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7083\n",
            "Epoch 474/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7083\n",
            "Epoch 475/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7083\n",
            "Epoch 476/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7083\n",
            "Epoch 477/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7083\n",
            "Epoch 478/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7083\n",
            "Epoch 479/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7083\n",
            "Epoch 480/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7083\n",
            "Epoch 481/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7083\n",
            "Epoch 482/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7083\n",
            "Epoch 483/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7083\n",
            "Epoch 484/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7083\n",
            "Epoch 485/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7083\n",
            "Epoch 486/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7083\n",
            "Epoch 487/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7083\n",
            "Epoch 488/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7083\n",
            "Epoch 489/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7083\n",
            "Epoch 490/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7083\n",
            "Epoch 491/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7083\n",
            "Epoch 492/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7083\n",
            "Epoch 493/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7083\n",
            "Epoch 494/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7083\n",
            "Epoch 495/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7083\n",
            "Epoch 496/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7083\n",
            "Epoch 497/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7083\n",
            "Epoch 498/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7083\n",
            "Epoch 499/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7083\n",
            "Epoch 500/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7083\n",
            "Epoch 501/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7083\n",
            "Epoch 502/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7847 - val_loss: 0.5069 - val_accuracy: 0.7083\n",
            "Epoch 503/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7083\n",
            "Epoch 504/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7847 - val_loss: 0.5068 - val_accuracy: 0.7083\n",
            "Epoch 505/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7083\n",
            "Epoch 506/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7083\n",
            "Epoch 507/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7847 - val_loss: 0.5067 - val_accuracy: 0.7083\n",
            "Epoch 508/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7083\n",
            "Epoch 509/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7083\n",
            "Epoch 510/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7083\n",
            "Epoch 511/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7083\n",
            "Epoch 512/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7083\n",
            "Epoch 513/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7847 - val_loss: 0.5065 - val_accuracy: 0.7083\n",
            "Epoch 514/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7083\n",
            "Epoch 515/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7083\n",
            "Epoch 516/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7847 - val_loss: 0.5064 - val_accuracy: 0.7083\n",
            "Epoch 517/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7083\n",
            "Epoch 518/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7083\n",
            "Epoch 519/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7083\n",
            "Epoch 520/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7830 - val_loss: 0.5062 - val_accuracy: 0.7083\n",
            "Epoch 521/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7830 - val_loss: 0.5062 - val_accuracy: 0.7083\n",
            "Epoch 522/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7083\n",
            "Epoch 523/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7083\n",
            "Epoch 524/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7083\n",
            "Epoch 525/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7830 - val_loss: 0.5060 - val_accuracy: 0.7083\n",
            "Epoch 526/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7830 - val_loss: 0.5060 - val_accuracy: 0.7083\n",
            "Epoch 527/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7830 - val_loss: 0.5060 - val_accuracy: 0.7083\n",
            "Epoch 528/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7830 - val_loss: 0.5059 - val_accuracy: 0.7083\n",
            "Epoch 529/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7083\n",
            "Epoch 530/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7847 - val_loss: 0.5059 - val_accuracy: 0.7083\n",
            "Epoch 531/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7083\n",
            "Epoch 532/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7083\n",
            "Epoch 533/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7847 - val_loss: 0.5058 - val_accuracy: 0.7083\n",
            "Epoch 534/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7083\n",
            "Epoch 535/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7083\n",
            "Epoch 536/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7847 - val_loss: 0.5057 - val_accuracy: 0.7083\n",
            "Epoch 537/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7847 - val_loss: 0.5056 - val_accuracy: 0.7083\n",
            "Epoch 538/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7847 - val_loss: 0.5056 - val_accuracy: 0.7083\n",
            "Epoch 539/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7847 - val_loss: 0.5056 - val_accuracy: 0.7135\n",
            "Epoch 540/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7135\n",
            "Epoch 541/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7135\n",
            "Epoch 542/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7847 - val_loss: 0.5055 - val_accuracy: 0.7135\n",
            "Epoch 543/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7135\n",
            "Epoch 544/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7135\n",
            "Epoch 545/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7135\n",
            "Epoch 546/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.7847 - val_loss: 0.5053 - val_accuracy: 0.7135\n",
            "Epoch 547/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7847 - val_loss: 0.5053 - val_accuracy: 0.7135\n",
            "Epoch 548/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7847 - val_loss: 0.5053 - val_accuracy: 0.7135\n",
            "Epoch 549/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7135\n",
            "Epoch 550/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7135\n",
            "Epoch 551/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7135\n",
            "Epoch 552/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7135\n",
            "Epoch 553/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7135\n",
            "Epoch 554/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7135\n",
            "Epoch 555/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7135\n",
            "Epoch 556/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7135\n",
            "Epoch 557/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7135\n",
            "Epoch 558/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7135\n",
            "Epoch 559/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7135\n",
            "Epoch 560/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7135\n",
            "Epoch 561/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7135\n",
            "Epoch 562/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7135\n",
            "Epoch 563/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7135\n",
            "Epoch 564/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7135\n",
            "Epoch 565/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7188\n",
            "Epoch 566/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7188\n",
            "Epoch 567/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7188\n",
            "Epoch 568/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7188\n",
            "Epoch 569/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7188\n",
            "Epoch 570/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7188\n",
            "Epoch 571/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7188\n",
            "Epoch 572/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7188\n",
            "Epoch 573/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7188\n",
            "Epoch 574/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7188\n",
            "Epoch 575/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7188\n",
            "Epoch 576/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7188\n",
            "Epoch 577/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7188\n",
            "Epoch 578/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7188\n",
            "Epoch 579/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7188\n",
            "Epoch 580/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7188\n",
            "Epoch 581/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7188\n",
            "Epoch 582/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7188\n",
            "Epoch 583/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7188\n",
            "Epoch 584/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7188\n",
            "Epoch 585/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7188\n",
            "Epoch 586/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7188\n",
            "Epoch 587/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7188\n",
            "Epoch 588/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7188\n",
            "Epoch 589/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7188\n",
            "Epoch 590/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7188\n",
            "Epoch 591/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7188\n",
            "Epoch 592/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7188\n",
            "Epoch 593/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7188\n",
            "Epoch 594/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7188\n",
            "Epoch 595/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7240\n",
            "Epoch 596/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7240\n",
            "Epoch 597/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7240\n",
            "Epoch 598/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7240\n",
            "Epoch 599/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7240\n",
            "Epoch 600/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7240\n",
            "Epoch 601/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7240\n",
            "Epoch 602/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7240\n",
            "Epoch 603/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7240\n",
            "Epoch 604/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7240\n",
            "Epoch 605/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7240\n",
            "Epoch 606/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7240\n",
            "Epoch 607/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7240\n",
            "Epoch 608/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7240\n",
            "Epoch 609/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7240\n",
            "Epoch 610/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7240\n",
            "Epoch 611/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7240\n",
            "Epoch 612/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7240\n",
            "Epoch 613/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7240\n",
            "Epoch 614/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7240\n",
            "Epoch 615/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7240\n",
            "Epoch 616/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7292\n",
            "Epoch 617/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7292\n",
            "Epoch 618/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7292\n",
            "Epoch 619/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7240\n",
            "Epoch 620/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7240\n",
            "Epoch 621/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7240\n",
            "Epoch 622/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 623/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 624/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 625/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 626/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 627/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7240\n",
            "Epoch 628/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7240\n",
            "Epoch 629/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7292\n",
            "Epoch 630/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7292\n",
            "Epoch 631/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
            "Epoch 632/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
            "Epoch 633/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
            "Epoch 634/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7865 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
            "Epoch 635/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7292\n",
            "Epoch 636/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7292\n",
            "Epoch 637/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7292\n",
            "Epoch 638/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7292\n",
            "Epoch 639/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7292\n",
            "Epoch 640/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7292\n",
            "Epoch 641/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7865 - val_loss: 0.5029 - val_accuracy: 0.7292\n",
            "Epoch 642/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7292\n",
            "Epoch 643/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7292\n",
            "Epoch 644/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7292\n",
            "Epoch 645/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7865 - val_loss: 0.5028 - val_accuracy: 0.7292\n",
            "Epoch 646/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
            "Epoch 647/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 648/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 649/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 650/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 651/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 652/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 653/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 654/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 655/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 656/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 657/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 658/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
            "Epoch 659/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
            "Epoch 660/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
            "Epoch 661/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7344\n",
            "Epoch 662/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
            "Epoch 663/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
            "Epoch 664/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
            "Epoch 665/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7344\n",
            "Epoch 666/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
            "Epoch 667/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
            "Epoch 668/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
            "Epoch 669/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7344\n",
            "Epoch 670/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
            "Epoch 671/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
            "Epoch 672/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
            "Epoch 673/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
            "Epoch 674/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7344\n",
            "Epoch 675/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
            "Epoch 676/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
            "Epoch 677/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
            "Epoch 678/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7344\n",
            "Epoch 679/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
            "Epoch 680/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
            "Epoch 681/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
            "Epoch 682/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7344\n",
            "Epoch 683/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
            "Epoch 684/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
            "Epoch 685/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
            "Epoch 686/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
            "Epoch 687/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7344\n",
            "Epoch 688/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 689/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 690/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 691/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 692/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 693/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7344\n",
            "Epoch 694/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
            "Epoch 695/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
            "Epoch 696/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
            "Epoch 697/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
            "Epoch 698/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7344\n",
            "Epoch 699/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 700/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 701/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 702/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 703/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 704/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7865 - val_loss: 0.5016 - val_accuracy: 0.7344\n",
            "Epoch 705/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
            "Epoch 706/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
            "Epoch 707/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
            "Epoch 708/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
            "Epoch 709/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7344\n",
            "Epoch 710/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 711/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 712/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 713/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 714/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 715/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
            "Epoch 716/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
            "Epoch 717/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
            "Epoch 718/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
            "Epoch 719/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
            "Epoch 720/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7344\n",
            "Epoch 721/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 722/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 723/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 724/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 725/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 726/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
            "Epoch 727/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 728/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 729/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 730/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 731/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 732/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 733/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
            "Epoch 734/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 735/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 736/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 737/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 738/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 739/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 740/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
            "Epoch 741/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 742/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 743/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 744/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 745/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 746/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 747/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7812 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
            "Epoch 748/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 749/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 750/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 751/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 752/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7830 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 753/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 754/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 755/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
            "Epoch 756/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 757/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 758/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 759/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 760/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 761/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 762/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 763/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
            "Epoch 764/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 765/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 766/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 767/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 768/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 769/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 770/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 771/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7344\n",
            "Epoch 772/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 773/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 774/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 775/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 776/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 777/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 778/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 779/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 780/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 781/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 782/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 783/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 784/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 785/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 786/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 787/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 788/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 789/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 790/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 791/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 792/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 793/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 794/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 795/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 796/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 797/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 798/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 799/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 800/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 801/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 802/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 803/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 804/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 805/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 806/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 807/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 808/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 809/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 810/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 811/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 812/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
            "Epoch 813/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
            "Epoch 814/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 815/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 816/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 817/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 818/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 819/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 820/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 821/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 822/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 823/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 824/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 825/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 826/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 827/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 828/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 829/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 830/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 831/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 832/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 833/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 834/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 835/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 836/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 837/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 838/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 839/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 840/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 841/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 842/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 843/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 844/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 845/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 846/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 847/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 848/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 849/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 850/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 851/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 852/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 853/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7812 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 854/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 855/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7812 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 856/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7812 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 857/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 858/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 859/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 860/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 861/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 862/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7830 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 863/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 864/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 865/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 866/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 867/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 868/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 869/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 870/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 871/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 872/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 873/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 874/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 875/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
            "Epoch 876/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 877/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 878/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 879/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 880/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 881/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 882/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 885/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 887/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 888/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 889/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 891/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 893/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 894/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 895/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 896/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 897/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 898/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 899/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 900/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 901/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 902/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 903/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 904/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 905/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 906/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 907/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 908/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 909/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 910/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 911/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7448\n",
            "Epoch 912/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 913/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 914/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 915/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 916/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 917/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 918/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 919/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 920/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 921/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 922/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 923/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 924/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 925/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 926/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 927/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 928/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 929/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 930/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7448\n",
            "Epoch 931/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 932/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 933/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 934/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 935/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 936/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 937/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 938/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 939/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 940/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 941/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 942/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 943/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 944/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 945/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 946/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 947/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 948/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 949/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 950/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 951/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 952/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 953/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 954/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 955/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 956/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 957/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 958/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 959/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 960/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 961/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 962/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 963/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 964/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 965/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 966/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 967/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 968/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 969/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 970/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 971/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 972/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 973/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 974/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 975/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 976/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 977/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 978/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 979/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
            "Epoch 980/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 981/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 982/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 983/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 984/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 985/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 986/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 987/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 988/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 989/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 990/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 991/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 992/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 993/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 994/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 995/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 996/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 997/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 998/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 999/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1000/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1001/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1002/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1003/1500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1004/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1005/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1006/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1007/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7812 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1008/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1010/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1011/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 1012/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1013/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1014/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1015/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1016/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1018/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1019/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1024/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1027/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1028/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1029/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1030/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1031/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 1032/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1033/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1034/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1035/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1036/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1037/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1038/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1039/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1040/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1041/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1042/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1043/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1044/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1045/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1046/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1047/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1048/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 1049/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1050/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1051/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1052/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1053/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1054/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1055/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1056/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1057/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1058/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1059/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1060/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1061/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1062/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 1063/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1064/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1065/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1066/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1067/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1068/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1069/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1070/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1071/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1072/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1073/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1074/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1075/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 1076/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1077/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1078/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1079/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1080/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1081/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1082/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1083/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1084/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1085/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1086/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1087/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1088/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1089/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1090/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1091/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1092/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1093/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 1094/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1095/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1096/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1097/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1098/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1099/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1100/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1101/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1102/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1103/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1104/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1105/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1106/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1107/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1108/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1109/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1110/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1111/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1112/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1113/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1114/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1115/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1116/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1117/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1118/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1119/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1120/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1121/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1122/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1123/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1124/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1125/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1126/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1127/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1128/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1129/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1130/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1131/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1132/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1133/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1134/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1135/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1136/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1137/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1138/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1139/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1140/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1141/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1142/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1143/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1144/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1145/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1146/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1147/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1148/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1149/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1150/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1151/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1152/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1153/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1154/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1155/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1156/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 1157/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1158/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1159/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1160/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1161/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1162/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1163/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1164/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1165/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1166/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1167/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1168/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1169/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1174/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1177/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1178/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1179/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1180/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1181/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1182/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1183/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1184/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1185/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1186/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1187/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1188/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1189/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1190/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1191/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1192/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1193/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1194/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1195/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1196/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1197/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1198/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1199/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1200/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1201/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 1202/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1203/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1204/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1205/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1206/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1207/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1208/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1209/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1210/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1211/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1212/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1213/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1214/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1215/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1216/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 1217/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1218/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1219/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1220/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1221/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1222/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1223/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1224/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1225/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1226/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1227/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1228/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1229/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1230/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1231/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1232/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1233/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1234/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1235/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1236/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1237/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1238/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1239/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1240/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1241/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1242/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1243/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1244/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1245/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1246/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1247/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1248/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1249/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1250/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1251/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1252/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1253/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1254/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1255/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1256/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1257/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1258/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1259/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1260/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1261/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1262/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1263/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1264/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1265/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1266/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1267/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1268/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1269/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1270/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1271/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1272/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1273/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1274/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1275/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1276/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1277/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1278/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1279/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1280/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1281/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1282/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1283/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1284/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1285/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 1286/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1287/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1288/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1289/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1290/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1291/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1292/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1293/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1294/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1295/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1296/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1297/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1298/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1299/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1300/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1301/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1302/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1303/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1304/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1305/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1306/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1307/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1308/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1309/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1310/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1311/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1312/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1313/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1314/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1315/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1316/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1317/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1318/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1319/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1320/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1321/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1322/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1323/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1324/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1325/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1326/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1327/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1328/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1329/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1330/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1331/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1332/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1333/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1334/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1335/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1336/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1337/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1338/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1339/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1340/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1341/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1342/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1343/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1344/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1345/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1346/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1347/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1348/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1349/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1350/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1351/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1352/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1353/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1354/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1355/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1356/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1357/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1358/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1359/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1360/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1361/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1362/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1363/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1364/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1365/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1366/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1367/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1368/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1369/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1370/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1371/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1372/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1373/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1374/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1375/1500\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1376/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1377/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1378/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1379/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1380/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1381/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1382/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1383/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1384/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1385/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1386/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1387/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1388/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1389/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1390/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1391/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1392/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1393/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1394/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1395/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1396/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1397/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1398/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1399/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1400/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1401/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1402/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1403/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1404/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1405/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1406/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1407/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1408/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1409/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1410/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1411/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1412/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1413/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1414/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1415/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1416/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1417/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1418/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1419/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1420/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1421/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1422/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1423/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1424/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1425/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1426/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1427/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1428/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1429/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1430/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1431/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1432/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1433/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1434/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1435/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1436/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1437/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1438/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1439/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1440/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1441/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1442/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1443/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1444/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1445/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1446/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1447/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1448/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1449/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1450/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1451/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1452/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1453/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1454/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1455/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1456/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1457/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1458/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
            "Epoch 1459/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1460/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1461/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1462/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1463/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1464/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1465/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1466/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1467/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1468/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1469/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1470/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1471/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1472/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1473/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1474/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1475/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1476/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1477/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1478/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1479/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1480/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1481/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1482/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1483/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1484/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1485/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1486/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1487/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1488/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1489/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1490/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1491/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1492/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1493/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1494/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1495/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1496/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1497/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1498/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1499/1500\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
            "Epoch 1500/1500\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7396\n"
          ]
        }
      ],
      "source": [
        "run_hist_model_1nc = model_1nc.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcufQ9u1Zn1",
        "outputId": "ff864c2c-7be9-4dc3-83d3-e6c2799d6489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1nc= model_1nc.predict(X_test_norm)\n",
        "y_pred_class_model_1nc = (y_pred_prob_model_1nc >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "0yhnpS_B1e7F",
        "outputId": "a1d80c05-2a15-42c1-f2f5-d1b765686bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.740\n",
            "roc-auc is 0.810\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1nc)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1nc)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1nc, 'new mode 1nCustom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "anGBXOJd1g-7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_model_1nc.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jUfvnSU-1iS9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x3122721a0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGgCAYAAABSVpb1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABv1UlEQVR4nO3deVxU5f4H8M/MyCIKuCCbgLjgkmuhEJpmSWEuN8vMXTDUMuyn0qJcK+tW6m1Rb13TVBQqS7NrpWgaoZULCWJqliKuMCa4BQgq4Mzz++PIwMAMzMBsDJ/36zUvZs55zjnPGUbm67N8H5kQQoCIiIiogZNbuwJEREREpsCghoiIiOwCgxoiIiKyCwxqiIiIyC4wqCEiIiK7wKCGiIiI7AKDGiIiIrILDGqIiIjILjCoISIiIrvAoIaIiIjsQp2CmhUrViAwMBDOzs4IDQ1FWlpajeWXL1+OLl26oGnTpvD398fcuXNx+/Zto855+/ZtxMTEoHXr1mjevDlGjx6NvLy8ulSfiIiI7JDM2LWfNm3ahClTpmDVqlUIDQ3F8uXLsXnzZmRmZsLT07Na+S+++ALPPPMM1q1bh/79++PUqVOIiorCuHHjsHTpUoPPOXPmTGzfvh0JCQlwd3fHrFmzIJfLsX//foPqrVar8ddff8HV1RUymcyYWyYiIiIrEULgxo0b8PX1hVxeS1uMMFJISIiIiYnRvFapVMLX11csXrxYZ/mYmBjx8MMPa22LjY0VAwYMMPic+fn5wsHBQWzevFlT5sSJEwKASE1NNajeOTk5AgAffPDBBx988NEAHzk5ObV+1zeBEUpLS5GRkYG4uDjNNrlcjvDwcKSmpuo8pn///vj888+RlpaGkJAQnD17Fjt27MDkyZMNPmdGRgbKysoQHh6uKdO1a1cEBAQgNTUV999/f7XrlpSUoKSkRPNa3G2QysnJgZubmzG3TURERFZSWFgIf39/uLq61lrWqKDm6tWrUKlU8PLy0tru5eWFkydP6jxmwoQJuHr1Kh544AEIIXDnzh0899xz+Oc//2nwOXNzc+Ho6IgWLVpUK5Obm6vzuosXL8abb75ZbbubmxuDGiIiogbGkKEjZp/99NNPP2HRokX4+OOPcfjwYWzZsgXbt2/HW2+9ZdbrxsXFoaCgQPPIyckx6/WIiIjIuoxqqfHw8IBCoag26ygvLw/e3t46j3nttdcwefJkTJs2DQDQs2dPFBcXY8aMGViwYIFB5/T29kZpaSny8/O1Wmtquq6TkxOcnJyMuT0iIiJqwIxqqXF0dERwcDBSUlI029RqNVJSUhAWFqbzmJs3b1YbraxQKABI41wMOWdwcDAcHBy0ymRmZiI7O1vvdYmIiKhxMaqlBgBiY2MRGRmJvn37IiQkBMuXL0dxcTGmTp0KAJgyZQratm2LxYsXAwBGjhyJpUuX4t5770VoaChOnz6N1157DSNHjtQEN7Wd093dHdHR0YiNjUWrVq3g5uaGF154AWFhYToHCRMREVHjY3RQM3bsWFy5cgWvv/46cnNz0adPH+zcuVMz0Dc7O1urZebVV1+FTCbDq6++iosXL6JNmzYYOXIk3nnnHYPPCQDLli2DXC7H6NGjUVJSgoiICHz88cf1uXciIiKyI0Yn32uoCgsL4e7ujoKCAs5+IiIiaiCM+f7m2k9ERERkFxjUEBERkV1gUENERER2gUENERER2QWjZz8RERGRiSmVwLZtQGYm4Okpvc7IALy8AD8/4Nw5wNEREAK4cgUoKQHc3YGQECAwUDpH69ZA//7S86wsIChIOrYRYVBDRERkTfHxwN2s+0b76afq22QyKfiRy4HVq4Ho6HpVryFh9xMREZG1KJV1D2j0Kc/UolYDzz4rXaORYFBDRERkLVlZ5j2/SgWsWdNoAhsGNURERNZiicz4//oXEBAgdXPZOQY1RERE1pCeDnz9tWWuJUSj6IriQGEia0hKAtavB27cAK5elWYydOwIdOsmPXdykn526QKMHGlbMxgq112hANq3B65fBy5ckPY7OEj7/P2lep84ARQUSPfk4ABcuyYNZCwvGxYGDB4szdqwpfskMpRSCRw4ID3v3x+4dEmayXT1asXnv7RUCixatQKKi6V/32Vllq2nSgU8/DDQvLn0urRUejg6Vrx2dJQe5TOrgoMb1L9Nrv1EZGkDBlT8ATSETCb1idvCDAZj624MW7pPIkPFxwPTp1cMzrVHVv63acz3N4MaIktKSpJaXowll0stIdb831Jd624MhQI4f77B/K+QGjmlUhqr0hi+Rq34b9OY7292PxFZ0o4ddTtOrQZOnzb+D4pSCXz6qdQUXlgI9OwJvPgi0K+f8XWoa92NoVIBERFAp06Ah4fUPH/+PNCjB7uoyLzS04FVq4DffgOKirS7ZJo3lx6Vu05LS6XPpzkCmoceAvr0kbqKlErg1CmgTRugZUtpf+vWUrftp58CCxaY/vq61NR15egodS8HBgKDBlm1y5wtNUSW9PDDwJ49xh9Xl5aamhJ6RUYCCQnG1eGFF4D//te4Y0yNXVRkDlFRQGKitWshMebfuq22FJn436kx39+c/URkKenpdQtoAODf/zYuoKktoVdiolQfY85niamntWkkMzjIgtLTbSegAYz7t+7nJwUP5a1HtkIIYMYMq/w7ZfcTkaXs3Vv3Y1eskNKdt24tNe1OmSL9QUtIAFaulGZTODpWNAkbMqviH/+Qzqdr9kPV5/n5UheYLVCppPE9zz1n7ZpUUCqBjz6SUtY7OkpN9G3aADk5FTO/PD2lmWITJ0rdf1VnzLBbrX7S04ENG4CzZ6X3tmoXkr7nhYXWqa8+ffsaVz46WuqyTU2V1opKSwOaNgXGjAFu35a2ZWdLa0qVz1CszM9P6tYSAvj7b+DiRdPcR127zOuJ3U9ElpKeLk2RNJU2baSF7Roiubz+QVJdutDMoS7r9vTvL30Jlf/5Zbda/dhS95E+5esx1cScg3GVSqBdO+1/d1Wvp1RKqRhMwYSTG9j9RGSLfHx0b69r03FDDWgUCmDJkvo3mRvbhWYOdV2358AB7S84dqvVna11H9VEoZB+ymTVP/9yOfDJJ+Zr2fDzk1p7y+ugUFS/np8fsHataa5nbJe5ibD7icjcymdV/PKL7v2bNkkzGZKSpKbin36Smm0bgmHDpASBbdpIM5YCA6WusGbNpHvJzZWa05s3l7YVF0vlsrJMM7jx3XeBZcukP55KpXTeCxek9zQnR39iMX1Jxwx5Xj7Tw9UVOHeu/vdQTqWSWm/GjDHdOW1R1W43QHp97ZrU/XHmjNRd8tdfFV/85UnrmjSR3qfKs5Dy8sxTz/btpeueP199X2Cg1L119arh5xMC+PLLin8rgPT7vnatYjaTuYOA8q6q06elOui6XnmZ8r9HNXVdeXjofw+M7UYzFdFIFBQUCACioKDA2lWhxiQyUgjpz5n+x3vvaR+zbVvtx9jKIy2tbu9LTo4Qcrlp6iCTSe+zqc5n7cfatfX91NmutWul35e13+PaHnK59BnV9TlVKKTtaWnGnbP8uIZI3/uQlqb792niezXm+5vdT0TmYmiz+Pz52t0OI0ZU/A/Wlslk+rvUalO1Kbw+hJDeZ1sZyFxfVpo1YnZKZcPJvFvedVJTl02/ftK4rsr699fuYpLLqx/XEOl7H/r1qz77ytzdaLXgQGEic1m6VEp0Z4g9e6TkcpUlJUkzm3JzpRkJtTWze3gA3t7SmjLOztKXh1oN9O4NzJ0rBSCffVaxJk15mcrl9T3XNytCV72NoVRKTeGVu6YuXQK2b5eavDdurPu5G7Lu3aX3vXKiN11dYg4OwKOPSjmE6pKYMStLet9PnQI6dwZu3qyYQVO+XlFdu+mqPs/PN93MGkO1by99tur7uS7/nOrqsklPB/bvl5YQKZ/VVl4WqLmrp6HR9z4olVJXGmCWbjQuk6ADgxqyOD8/w/6IGzLjwZCZU9u2Sa085mDIzAlLXJP0W7vW8NlT8fFSi5A9v7eGzL6xxueajMbZT0TWlpBgeEBjSFOtrqbuyvr3N19AAxg2c8Lc16SaGdptpVTaf0Ajk0mfndo+n9b4XJNZsaWGyBxCQ6Um/Np89ZVxs13S06XZPkePSn+A/f2BmTPNG9BUVlMzvDmvuXkzEBtr/LEuLkDHjtrdDg4OUreIId1uhnRV6DJ+vDRbZ+hQaQ2f8lkux44Bycnmm90WGCh1t5R3Sw0cCPz4I3DjhjRj68SJit+hPfDy0t0ta+y/K2t8rslg7H7SgUENWcyAARVTVmvCZm7D1TUp2Pr1UmI2U9XB0HV20tL0Lxpqq+v12KLygba6WpUUCilYvP9+dh/ZOXY/EVlLUlLNAY29zIawtLokBevY0XQBTXkdqs700JVAMDKy5lXQbXW9Hlsjl0tdQ7q6ICvPvmH3EVXClhoiU3r+eWnGki6RkcDbb7OZuz6USmkG1759UhcLICXZu3EDcHOTul4AYOpU0wY0VetQeaYHIAWzubnA8OE1BzS6zlOedE5fQBwYKN1r5S6xGzek65lby5bSrDpjuulqe+7gUJG88OpVaX0iPz9pvaKyMqBnTyA4WHsWja5ZclVn3/Dfld1i95MODGrIIrp1A06e1L3PnLOTqOEzZiaOqdcR04efWbIB7H4isoakJP0BjblnJ1HDZ8xMnNpmw5kCP7PUALGlhkgfpRL46CPghx+kZnFA9/pBrVsDI0dKAc1nn1U/z7BhUjI5IkMY05WSni4FQocPS11SxnRLBQZKA5YVCqlLqKxM+unmJgVMDGjIRhj1/V2XdRj++9//inbt2gknJycREhIiDh48qLfsgw8+KABUewwbNkxTRtd+AOLdd9/VlGnXrl21/YsXLza4zlz7iYyydq3p1pHZts3ad0ONhaHrEZWvbUTUAJh17adNmzYhNjYWCxcuxOHDh9G7d29ERETg8uXLOstv2bIFly5d0jyOHz8OhUKBMZVyCFTef+nSJaxbtw4ymQyjR4/WOte//vUvrXIvvPCCsdUnqp1SCUybZrrz9eljunMR1cSQbilDE9MRNUBNjD1g6dKlmD59OqZOnQoAWLVqFbZv345169Zh/vz51cq3atVK6/XGjRvh4uKiFdR4e3trlfnuu+/w0EMPoUOHDlrbXV1dq5UlQno6sHevlGjM0JkngBS8lM82ad8eOHdOavZPSjJt/U6f5hcIWU5CAhATIwUuZ85I64EFBEhdpZ07S91K/DySnTJqTE1paSlcXFzw9ddfY9SoUZrtkZGRyM/Px3fffVfrOXr27ImwsDCsXr1a5/68vDz4+fkhMTEREyZM0GwPDAzE7du3UVZWhoCAAEyYMAFz585Fkya647KSkhKUlJRoXhcWFsLf359jauxNVJT2StiRkdIf9drEx1tmxWAmAiMiqhezzX66evUqVCoVvLy8tLZ7eXkh14DBaWlpaTh+/Dim1dC0n5iYCFdXVzz55JNa2//v//4PGzduxJ49e/Dss89i0aJFeOWVV/SeZ/HixXB3d9c8/OuSjZRsW3q6dkADSK/T02s+Tqm0TEADAPPnM6AhIrIQo7uf6iM+Ph49e/ZESA35FdatW4eJEyfC2dlZa3tspXVfevXqBUdHRzz77LNYvHgxnJycqp0nLi5O65jylhqyE+npwKxZuvetXg388YeUBK+4WNpWPmsJAPLz6xbQeHtLCcPKE4hdvKh73ZnKPDyMvw4REdWJUUGNh4cHFAoF8qr8Ic/Ly6t1rEtxcTE2btyIf/3rX3rL7N27F5mZmdi0aVOtdQkNDcWdO3dw/vx5dOnSpdp+JycnncEO2YGqXU5VrV1rfEp9Q2zdqj1mx5AEaAMGmL4eRESkk1HdT46OjggODkZKSopmm1qtRkpKCsLK04XrsXnzZpSUlGDSpEl6y8THxyM4OBi9e/eutS5HjhyBXC6Hp6en4TdADZ+uLidL0LWeT20zTWpbA4iIiEzK6O6n2NhYREZGom/fvggJCcHy5ctRXFysmQ01ZcoUtG3bFosXL9Y6Lj4+HqNGjULr1q11nrewsBCbN2/GBx98UG1famoqDh48iIceegiurq5ITU3F3LlzMWnSJLRs2dLYWyBbl5QEfPCB1L3Tti3w4ouAlxewahXw44+WrcuwYcAbb+gPTspnmixbBhw9Kq1fc++9wIwZDGiIiCzM6KBm7NixuHLlCl5//XXk5uaiT58+2Llzp2bwcHZ2NuRy7QagzMxM7Nu3Dz/88IPe827cuBFCCIwfP77aPicnJ2zcuBFvvPEGSkpK0L59e8ydO1drzAzZiQEDtBf1y8oCfvrJOnWRyw1b8bdfP+CLLyxTJyIi0ovLJJDtSEqSlhuwBTIZsGYNEB1t7ZoQETVqxnx/W3T2E5FOSiXw6afAihXmOX/LltIsJGdnadZTSQlw546UbK+qhx4Cnn6aCcqIiBogBjVkXfHxpl2SQJdPP62+OJ9SCbRrB6jVFdsUCqksgxkiogbJ6LWfiEzG1Gss6dK/v+7Vhv38pHw2CoX0WqEwbPwMERHZLLbUkPVkZZnmPF26AHPmAMHB0uyo5GRpFtLMmboDmnLR0UBEhLQ2U6dODGiIiBo4BjVkPYcOmeY88+dLCfkAaSZSXJzhx/r5MZghIrIT7H4i61AqgRrW7gIANGtW+3k6dqwIaIiIqFFjSw1ZhyFdT0lJQFGRtIbT338D3btLSe3++AP47jvg8ccZ0BARkQbz1JB1KJVATQuMKhTA+fPsGiIiauSM+f5m9xNZx6VL+vdxJhIREdUBu5/IstLTgb17gZ9/1r0/JkYa+MuAhoiIjMSghiwnKqr2FbYjIxnQEBFRnbD7iSwjPb32gAYAfHzMXxciIrJLbKkh00hPB1atAv78U1prKTwcSEsDfv9dWhzy6lXDznP6NFtqiIioThjUUP3p6lb6/nvjzyOXS5l9iYiI6oDdT1Q/hnYrGWL1arbSEBFRnbGlhmpX3rV09izg7Q0MGgSMHCntW7iw/ufv1g344QcGNEREVC8MaqhmurqWNm4Enn/edNd45RUGNEREVG/sfiL9TNm1pA/XbiIiIhNhSw3pt3ev6c4VGAg4OABt2khdWMXFwLhxDGiIiMhkGNSQfgkJpjmPXC4FSOxiIiIiM2L3E+mWlCTlmDEFzmoiIiILYEsNVUhPBzZsAG7cAA4eNP74hx8GliwBfvwROHwYuO8+YPJkBjRERGQRDGpIYsi6TLVZsgTo1096EBERWRi7n8g0s5wiIxnMEBGRVbGlhoyf5RQWBpSUALdvA717A3PnMqAhIiKrY1BDwLVrhpdVKICvvuI4GSIisjnsfmrslEpg8WLDysrlwCefMKAhIiKbxJaaxi4rCxCi5jJ9+gD//KfU7cSAhoiIbBSDmsYuKKj2Mm+9BYwYYf66EBER1QO7nwiQyfTv69+fAQ0RETUIDGoaO33dTxERwLZtwP79lq8TERFRHbD7qbELCpJaaioHNnI5sHYtx88QEVGDUqeWmhUrViAwMBDOzs4IDQ1FWlqa3rKDBw+GTCar9hg+fLimTFRUVLX9Q4cO1TrP9evXMXHiRLi5uaFFixaIjo5GUVFRXapPtalt4DAREZENMjqo2bRpE2JjY7Fw4UIcPnwYvXv3RkREBC5fvqyz/JYtW3Dp0iXN4/jx41AoFBgzZoxWuaFDh2qV+/LLL7X2T5w4EX/88QeSk5ORlJSEX375BTNmzDC2+lSVru4nIYDTp61THyIiojoyOqhZunQppk+fjqlTp+Kee+7BqlWr4OLignXr1uks36pVK3h7e2seycnJcHFxqRbUODk5aZVr2bKlZt+JEyewc+dOrF27FqGhoXjggQfw0UcfYePGjfjrr7+MvQWq7NCh6tsUCqBTJ8vXhYiIqB6MCmpKS0uRkZGB8PDwihPI5QgPD0dqaqpB54iPj8e4cePQrFkzre0//fQTPD090aVLF8ycORPXKmW5TU1NRYsWLdC3b1/NtvDwcMjlchzUs5p0SUkJCgsLtR5UhVIJzJ9fffuSJRxPQ0REDY5RQc3Vq1ehUqng5eWltd3Lywu5ubm1Hp+Wlobjx49j2rRpWtuHDh2KTz/9FCkpKfj3v/+Nn3/+GY899hhUKhUAIDc3F56enlrHNGnSBK1atdJ73cWLF8Pd3V3z8Pf3N+ZWG4esLECtrr69UvBIRETUUFh09lN8fDx69uyJkJAQre3jxo3TPO/Zsyd69eqFjh074qeffsKQIUPqdK24uDjExsZqXhcWFjKwqUrXzCeZjF1PRETUIBnVUuPh4QGFQoG8vDyt7Xl5efD29q7x2OLiYmzcuBHR0dG1XqdDhw7w8PDA6buDVb29vasNRL5z5w6uX7+u97pOTk5wc3PTelAVly7pHiR86ZJ16kNERFQPRgU1jo6OCA4ORkpKimabWq1GSkoKwsLCajx28+bNKCkpwaRJk2q9jlKpxLVr1+Dj4wMACAsLQ35+PjIyMjRldu/eDbVajdDQUGNugSrbu1f3dibcIyKiBsjo2U+xsbFYs2YNEhMTceLECcycORPFxcWYOnUqAGDKlCmIi4urdlx8fDxGjRqF1q1ba20vKirCyy+/jF9//RXnz59HSkoKHn/8cXTq1AkREREAgG7dumHo0KGYPn060tLSsH//fsyaNQvjxo2Dr69vXe6bAKDSYGwtAwZYth5EREQmYPSYmrFjx+LKlSt4/fXXkZubiz59+mDnzp2awcPZ2dmQy7VjpczMTOzbtw8//PBDtfMpFAocO3YMiYmJyM/Ph6+vLx599FG89dZbcHJy0pTbsGEDZs2ahSFDhkAul2P06NH48MMPja0+lVMqgcWLde+720JGRETUkMiEaBzpYwsLC+Hu7o6CgoLGN75GqQQOHAB++gnIyADatwcefBB4/nnd5ffsAQYPtmQNiRoMpRL49FMgORm4cgUoLQUcHaV9dX3u6Cg9N8W5TPXcVuvk7S396eI6u42HMd/fDGrsXXw8MH264UsfKBTA+fPMU0OkQ3w8UCUjBVlJ//4c/tdYGPP9zVW67ZlSaVxAA0jJ+BjQEFWjVDKgsSUHDgBJSdauBdkaBjX2TNe6TrXx8DBPXYgauKwsa9eAqtq509o1IFvDoMaelSfXMwZnPhHpFBRk7RpQVUOHWrsGZGsY1NgzPz9Ax/R6vYYPB/r1M199iBowPz9g7Vpr14LK9e/PwcJUnUWXSSArqJIXqEaVFiolouqio4HERClvZdeuQJMmQEkJ4Ows9fTW9bmDgzTDxxTnMtVzW6zTuXNAUREwdy6wdKm1Pw1kixjU2LtK2Z9rxa4nolqVD1N76y3gqaesW5fGZtQo4LvvgC5drF0TslXsfrJn6enAjh2Gl2fSPaJa3b4t/Wza1Lr1aIzK3/Py3wFRVWypsVdKJbBwoXHHnD7N6dzU6CUlAStWADk5uhPA3V1nF0eOSMPQyHLKg5r33gPWrJGeWzshYOXntpqw0FJ1at0aGDkSmDLFel8lTL5nj+qSIUwuBy5cYFBDjVr//kBqqnHlmQDOctzdgcJCa9eCDLF2rTQGzRSYfK8xqy1DWNeu1bfJZMDq1QxoqFFLSjIuoAGYAM6SEhIY0DQkM2ZIX0eWxu4ne1NbhrAhQ6RFa5KSgFOngM6dpXmRDGiokTNm+FllO3dyarElfPONtWtAxlCrrTOigUGNvaktQ9jQodKn7LnnLFMfogZi2DBg5Urjj2MCOMt44glg61Zr14IMJZcDnTpZ4bqWvySZVW0Zwvr0sVhViBqSESOkBeyNwQRwlhMVBXTsaO1akKGsNaKBLTX2yMtLypxVVlZ9H2c4Een1/PPAyy8D3t7SMmj6ktJ5ewMzZzKgsbTTp6WxNZ98AhQX20ZCQFtPWGjJOrVpI/2bmDzZel8zDGrszYAB0uhFXRQK67QHEjUQt25JP0eOlP6nSbYnKkp6EOnC7id7kpSkP6CRy6X/3rCVhkgvJtYjatjYUmNPapq+8dprpksaUIOEBOCLL4B77wVeeEF/DKVUAp9+CmzbBly7JiVwcnUFAgOBli2BEyekL5bnn2cTf0OhK2ldQ0tGdumS9PrUKdO+N0RkGQxq7IlCoX+fBVKfduggLTgHSLPG331XdwKmmnID/vqr9uvvv2eCs4bA2KR1tm7nTqmntjx7MBE1DOx+shdKpfTfZF3GjAH69TPr5RMSKgKayqomYKotN6AuTHBm2+qStK4hOHNG+lwTUcPBoMZeZGVVLB9c1fPPm/3y+hJjlSdgKldbbkB9du6s23FkfnVNWtcQfPedtWtARMZgUGMvgoKk5Q6qstCMpyee0L29agKm2nID6sMEZ7Zr2DBr18B8Hn/c2jUgImMwqLEXfn4Vy9aWs+CMp6goaaBvVVUTMNWWG1AXJjizbSNG1D1YtWUdO3LqMFFDw1W67YkQQJMmUp/PokUWz4A0ZQrw2WfScyenmvP89ewJHD8ura+pUkkzT/74o3q5OXOAZcvMVmUykbVrgenTpYR13t4NOxlZs2bSKiIMaIhsgzHf35z9ZE8++UQKaADg1VcBT0+LTOMuV57jA5B6vWqKp1Qq6efHHwMPPSR9mSgUFcOCmjcHiop0LypOtqf8d//QQ8BXX1m3LkTUeLH7yV4olUBMTMVrtRp49lmLrv1eno21/HlNbYDlZcuTnMlk0v+Uy7VqVf2cZLvKf0+Vf4dERJbGlhp7kZUFqNVIR19swHgAwETVl/BJzUGWhx+CgozviVIqpdOWH1ueMC85GbhyRWrCb9sWePFFabmpQ4cqjhUCCA6WWlt0JUK7cEH6eeYMcP/90nMHh4ovR/ndcPvDD6VrVk6W5uoKdO8uxWxmnqlOdyUlSbOchg2TxtAkJQEffABcvCj9Ti5flsplZ1u3nkTUuHFMjb147z1EveKBREQBKJ8FVf6rlUEulwbtGtobFR8vjZEQQgowJk8GEhNNX20AiIyUftbl/JGRzCViblUT65V3DerTsSOT1hGR6Rjz/c2gxh4olUj3fwIhSENFQFOdQgGcP197i41SCbRrVzE8x9alpbHFxlySkqTFHY21fj0H2hKRaRjz/c0xNfYgKwt78QBqCmgAaXCuIf+DvtuT1WBwCQXzqWtiPSatIyJrYFBjD5o3x0DsQ0V3k26G5uELCqoY09IQDBhg7RrYr7om1mPSOiKyhjp9da1YsQKBgYFwdnZGaGgo0tLS9JYdPHgwZDJZtcfwuwsslpWVYd68eejZsyeaNWsGX19fTJkyBX/99ZfWeQIDA6udY8mSJXWpvv0pKkI/HMJIbK2yQzvIMTQPn5+flB+mnEJRMe7FHCIj637+yEh2PZnTiBHSGJnKygd768OkdURkLUaPqdm0aROmTJmCVatWITQ0FMuXL8fmzZuRmZkJT0/PauWvX7+O0tJSzetr166hd+/eWLt2LaKiolBQUICnnnoK06dPR+/evfH3339j9uzZUKlUOFRpOk1gYCCio6Mxffp0zTZXV1c0a9bMoHrb+5gaBATgoOiH+3FQs/mXr/Mw6CkvzWtjftPJycCjj0rPDx8G7r1XmqV08CBwzz1SS052NlBYCAwaBPzyi7TtySeBsDDgxAnpuBs3dCc4U6uB3r2BuXMrgpL0dODLL6XnDz8M/P67VI+CgopkaQoFcPKkVObgQSAkpD5vHBni448rsgU88YSUOPFf/wJ8faVEdUxaR0TmZNbke0uXLsX06dMxdepUAMCqVauwfft2rFu3DvPnz69WvlV5wpG7Nm7cCBcXF4wZMwYA4O7ujuTkZK0y//3vfxESEoLs7GwEBARotru6usLb29vYKjcat9BU6/U9nVV1PlflRHotW0o/y8fZLFkiDR59+WXg/fcBFxdpe+vWwObNdb4k+vXTbnUZMQKIi9Muk59fUZ8+fep+LTJc5VxBbdtWvB4/Xvr9ExHZCqOCmtLSUmRkZCCu0jeNXC5HeHg4UivP+axBfHw8xo0bV2MLS0FBAWQyGVq0aKG1fcmSJXjrrbcQEBCACRMmYO7cuWjShKl2kJUFpfDFekzR2vzIaBet1z166M/1Up6D5uRJIDAQ2Lat4rjwcOl/4+WDjI8ckYKa8sR5+/ZJP2/elM5jzpUZmlaK2wYOlAKp55/n2lCmoCsPUeUcNADw9dfS7xkAcnKsU08iIr2EES5evCgAiAMHDmhtf/nll0VISEitxx88eFAAEAcPHtRb5tatW+K+++4TEyZM0Nr+wQcfiD179oijR4+KlStXihYtWoi5c+fqPc/t27dFQUGB5pGTkyMAiIKCglrr2dCsfep7AaiE1Alg/KN//7odExCge9/atea71ylT9NeH6m7t2rp/doiIzKmgoMDg72+LBjUzZswQPXv21Lu/tLRUjBw5Utx77721Vj4+Pl40adJE3L59W+f+hQsXCkgjZbUe9hbU5KT9JYA7dQ5ozPGQy4XIyTH9vaal1XzdbdtMf83GICenfr9vvu9EZE7GBDVGzX7y8PCAQqFAXl6e1va8vLxax7oUFxdj48aNiNaT0rasrAxPP/00Lly4gOTk5FoHA4WGhuLOnTs4f/68zv1xcXEoKCjQPHLstK08a28uAIW1q6FFrTZPRtm9e2vev3On6a/ZGGRl1e94vu9EZCuMCmocHR0RHByMlJQUzTa1Wo2UlBSEhYXVeOzmzZtRUlKCSZMmVdtXHtBkZWXhxx9/ROvWrWuty5EjRyCXy3XOuAIAJycnuLm5aT3sUdBAbwC2lSlPLjcsH46xBg6sef/Qoaa/ZmMQFFS/4/m+E5GtMDpPTWxsLNasWYPExEScOHECM2fORHFxsWY21JQpU7QGEpeLj4/HqFGjqgUsZWVleOqpp3Do0CFs2LABKpUKubm5yM3N1UwFT01NxfLly3H06FGcPXsWGzZswNy5czFp0iS0LJ8K00j5QYmpSKjXOfr3r9sx+o5bvdo8g4X79dOfz6Z/fw4Wris/P2Dt2rody/ediGyJ0VOHxo4diytXruD1119Hbm4u+vTpg507d8LLS8qHkp2dDXmVdLSZmZnYt28ffvjhh2rnu3jxIrZulZLG9akyR3fPnj0YPHgwnJycsHHjRrzxxhsoKSlB+/btMXfuXMTGxhpbffuhVEpTlL75BoPgi/V4BgDghYt4EluQf284zjt3Q0lJxSHluV4cHIA//5S2/fKL1AISFgb8+mtF2ZYtga5dpbJXr0r5YRwcAG9vYObMii+ypCRg6VLg77+BiAhg1izzzn5KSJBypqxeDXz1lZQnZ+5cqQ5Ud9HRUo6glBSgSxfpd105r1CzZlKeomPHpI+ev7/0vjOgISJbwgUtG6L4eGDaNM3LBERqWmtGYBu24R81rvJYVlaRFfb6dSmAKU+sV+6xx+q+7o+ljBolrTH0ySfAjBnWrk3DFx4uBTUbNgATJli7NkREEi5oac+USq2ARi8fH727HByklhegIpFa5QRrgHY+GFtVXseqdae6KX8fG8LvnohIF2aua2iqTFVJwjC8h7ma17loIz05fbrGfiAHB2nV7hEjpG6pzEzt/adPmz+RXn05O0s/33sPWLNGel6eMA6Q7vHRR4EXXrDt+7AEfYn1gIrnZ85Ir48dk5ZDICJqaNj91NCUD2gAMAB7cQADAMgqFRDojwPYn9NO7zd5VBSQmGjY5daulcZb2CJ3d2lMjSFs+T7MrUpvpUH69wf27zdPfYiIjMHup0YgCcN0BDQAIMMB9EfSEd0BTXq64QENII1VUSrrXE2zSUgwPKABbPc+zM3Q3sqqDhyQBoETETUkDGpsXXq6NLUnPV16fbf7aQeGoXpAU06mNyFabQnsqjJXIr36+uYb48rb6n2YW30S6zGpHhE1NAxqbFlUFBASArz4ovQzKkqTKW0YdkBa+UEXoTchWm0J7KoyVyK9+jJ2zIet3oe51SexHpPqEVFDw6DGVunqJ0pMlJbIBjACO9AJuv4bLtC/v0xv/pCaEtjpYq5EevUVFQV07Gh4eVu9D3Ora2I9JtUjooaIA4Vt1dKlUgtNVb16SdNTAKzGdDyL1WiDS/BvdRPefXwxc25Tg76M0tOlL/o//gBu3JC6Z3r3Bvr2lU7fpQswebLtBwIJCVKemuJiKUlcecK4mzel2TzNmgEnT9r+fZjbwIHAvn1SQsUmTbQT65U/15VckYjI2oz5/uaUblt17Zru7XcDGgC4BSmhyBDZz/jy6AOAn+EJRvr105ubr0GJipIeVf35J9C9u/Rl3dgDmsrefhsYPdratSAiMg92P9kipRJYvLjWYrchJWpx7hrIb+4qynPYMDGfpPx9KH9fiIjsEVtqbFFWltQvUIs8SOttqWxrkW6bUJ4V9+ZN4L77gKIi7WRzzZtL2599Vkq+/NFHwA8/SEtIlJepmpzO0VHqnnn+edvsnklKAj74ALh4sXrdy2dBHTkCDB9utSoSEZkVx9TYojFjgK+/rrFIPJ7BdKyBgBwyCKxZK2u0yeV0mTBBWqDRXGwtOd2AAVJuGUPYWt2JiGrC5HsNWXp6rQGNEm0xA6sh7v76BGR49tnGmVxOl/R08wY0gG0lp0tKMjygAWyr7kREpsSgxtYYkB0vC0FQQ6G1TaVqnMnldDE2wWBd2Upyurqspm4rdSciMiUGNbZG36ynSoKQBTlUWtsUisaZXE4XYxMM1pWtJKcbNsz4Y2yl7kREpsSgxpYolcCiRbUW88NFrMYMyO5mFJbLpVwtnAAlMTbBYF3YUnK6ESOAtm0NL29LdSciMiXOfrIlRizUEz2vDb5Il2H3buDf/268K1Drk5AAxMRICQYPH5YSDFZONlf+Vm/bBkyfDuTmSksKVE1IV/n52bNSkr8XXwTef9+qt1fN2LFSvkY/P2nmFxPrEVFjxKDGlhi6UI9CAcyaBdxtjfD1NV+VGrKaEgy6uUmBTpcuwJ070rZvvpES9ukzfLg0fqWmMtZSnofmmWeAN9+0bl2IiKyF3U+2RN9CPf37S4EMIP2829d0+7a0qanhiYTprvL37NatioCgtvex8jG2xtB7ICKyZ2ypsTXPPANMmyY9nzYNmDFDam5QKqXpTZ06aQbPXL0qFcvOtlJdGzAHB+nnU09JXUoAcOIE0KGD/mPUd5McfvCBFHuWlupO0meN53l50vMzZ4x7H4iI7AmDGluzalXF83XrgPvvl4IaPz+tkcBRUcCpU9LzOXOA336TxpFQ7eLjpay7gPYwphEjpAHGut7H+HipewqQxtbYqrVrpXWvmFyPiBojZhS2JUol0K5dRZMAIHU3nT+vFdCkpwMhIdUPT0uzj0UqzUmpBPz9ay5T9X005Bhbs20bBwQTkX1gRuGGKitLO6ABdGbV05dcjv87r50hE8yqvo9GTEqzGUyuR0SNEYMaWxIUJCWdqUxHVj19yeUGDDBTveyIIRPMqr6Phk5KsyVMrkdEjRGDGlvi5we89FLF60oznSrr1w945BHtQyMj2fVkCH0TzMrpeh9rO8bWMLkeETVWHChsa8qToHh7A1u36o1UYmKA5GQgIEBa/5IBjeGio4GICOC//wV++EFqHLv33oqJZjUd89ln0vteUCDNOtKVpM9az/39mVyPiBo3DhS2JfHxFdO5AUAmA9as0ZkueNMmYNw4YPBgYM8ey1WRiIjIkjhQuCFSKqV8/ZUJATz7rLSvCiZbIyIi0sagxlZkZUlBTFU6Zj8BwKVL0s+rV3XGPERERI0OgxpbceiQ7u06Zj/FxwP//Kf0PD1dGlcTH2/m+hEREdk4BjW2QKkEXnlF977587VmPxnZS0VERNRoMKixBTVld/PwqFbUiF4qIiKiRqNOQc2KFSsQGBgIZ2dnhIaGIi0tTW/ZwYMHQyaTVXsMHz5cU0YIgddffx0+Pj5o2rQpwsPDkVXli/769euYOHEi3Nzc0KJFC0RHR6OoqKgu1bc9NWV3q5IJLihImhRVlY5eKiIiokbF6KBm06ZNiI2NxcKFC3H48GH07t0bERERuHz5ss7yW7ZswaVLlzSP48ePQ6FQYMyYMZoy7777Lj788EOsWrUKBw8eRLNmzRAREYHbt29rykycOBF//PEHkpOTkZSUhF9++QUzZsyowy3bKF2Rypgx1RKn+PlJs7wrk8t15ugjIiJqXISRQkJCRExMjOa1SqUSvr6+YvHixQYdv2zZMuHq6iqKioqEEEKo1Wrh7e0t3nvvPU2Z/Px84eTkJL788kshhBB//vmnACDS09M1Zb7//nshk8nExYsXDbpuQUGBACAKCgoMKm9Ru3cLIfUqaT/27NF7SGCgVORf/xIiJ8dyVSUiIrIkY76/jWqpKS0tRUZGBsLDwzXb5HI5wsPDkZqaatA54uPjMW7cODRr1gwAcO7cOeTm5mqd093dHaGhoZpzpqamokWLFujbt6+mTHh4OORyOQ4ePKjzOiUlJSgsLNR62CxdfUpyuUH9SY8+yhYaIiIiwMjup6tXr0KlUsHLy0tru5eXF3Jzc2s9Pi0tDcePH8e0Sllzy4+r6Zy5ubnw9PTU2t+kSRO0atVK73UXL14Md3d3zcPf37/2G7QltSR6vnNH+tmEC10QEREBsPDsp/j4ePTs2RMhISFmv1ZcXBwKCgo0j5ycHLNfs850TWkSQud0pvR0adWEvDzp9fXrFqgfERFRA2BUUOPh4QGFQoG88m/Uu/Ly8uDt7V3jscXFxdi4cSOiq6xjVH5cTef09vauNhD5zp07uH79ut7rOjk5wc3NTethswzsfoqKAkJCgHXrgLIyadujjzLxHhEREWBkUOPo6Ijg4GCkpKRotqnVaqSkpCAsLKzGYzdv3oySkhJMmjRJa3v79u3h7e2tdc7CwkIcPHhQc86wsDDk5+cjIyNDU2b37t1Qq9UIDQ015hZsl66WmkrS04HERN2HzpjBxHtERERGdz/FxsZizZo1SExMxIkTJzBz5kwUFxdj6tSpAIApU6YgLi6u2nHx8fEYNWoUWrdurbVdJpNhzpw5ePvtt7F161b8/vvvmDJlCnx9fTFq1CgAQLdu3TB06FBMnz4daWlp2L9/P2bNmoVx48bB19e3DrdtYw4cqL6tSvfT3r36D1ermXiPiIjI6GGmY8eOxZUrV/D6668jNzcXffr0wc6dOzUDfbOzsyGXa8dKmZmZ2LdvH3744Qed53zllVdQXFyMGTNmID8/Hw888AB27twJZ2dnTZkNGzZg1qxZGDJkCORyOUaPHo0PP/zQ2Orbnvh4oNLAaY0q2fQGDtR/CgMnShEREdk1mRC1TLOxE4WFhXB3d0dBQYHtjK9RKgF9s7IWLADefltrU1SU7i6otWulwcNERET2xpjvb679ZE1GrPkEVM8kDABHjzKgISIiAhjUWJcRaz4BwK1b1YsFBJiwPkRERA0Ygxpb5eNTbVOlpbA0mHyPiIhIwqDGmmrqftIxnens2erFqqT3ISIiarQY1FiTvu6nKjOfAGmSlK5UQJ07M/keERERwKDGNi1ZorVKpVKpe9Y3IOWoefZZJt8jIiJiUGNN+rqfKq1GXlOxcioVk+8RERExqLGmQ4eqb9PR9VTTJCk9hxARETU6DGqsRakE5s+vvr1K1xMgvVy7VvdpFArgk0+qHUJERNTocEKwtWRlSQNiqqrS9VQuOhp46SUgPx+YORMYNgxo3lxqoWFAQ0RExKDGenT1KclkNfYjlZZKP19+GWjf3kz1IiIiaqDY/WQtly5V3yaE7u13d5VnFG7a1Iz1IiIiaqAY1FjL3r26t+/fr3Pz2bNSYAMAf/xhpjoRERE1YAxqrGXgQN3bdaz5FB+v3SsVHi6t2E1EREQVGNRYS79+1QOYyEhpeyX6Eu8lJgLp6WasHxERUQPDoMaahg6Vfvr7A9u2AQkJ1YrUlHhPT08VERFRo8Sgxlri44HXXpOe5+QA//iHzkWcakq8p6OnioiIqNFiUGMNSiUwfbr2NiF0LuKkL/Gejp4qIiKiRo1BjTVkZVVMZapMzyJO0dEVLTaTJwNpaTp7qoiIiBo1BjXWoGvNJ6DGRZxUKunnzJlsoSEiItKFQY2lKZXAK6/o3jd/vt41D8oT7zk7m6leREREDRyXSbC0mqYzeXhoniYlATt2SGs8Xb0K5OZK20+fBu6918x1JCIiaoAY1FiaAdOZBgwADhyQNq1cqV3k6aelQcIcU0NERKSN3U+WpmdtJwwfDvTrh6SkioBGHybeIyIiqo5BjaXpW/MpPByA1OVkCCbeIyIi0sagxtKuXdO9/W7X07Bhhp2GifeIiIi0MaixJKUSWLKk+vYxYzTztEeMAO65p+bTMPEeERFRdQxqLCkrC1Crq29//nmtl++/X71IYCAwfjwT7xEREenD2U+WFBQEyGTa2YTl8moJ9+7cqX7oyy9Xi32IiIioErbUWJuO5RJ0BTVMukdERFQzBjWWpGvNJyGqrfdUVlb90D//NGO9iIiI7ACDGksKCpK6myrTsd6TrpaaDz7gjCciIqKa1CmoWbFiBQIDA+Hs7IzQ0FCkpaXVWD4/Px8xMTHw8fGBk5MTOnfujB2VErIEBgZCJpNVe8TExGjKDB48uNr+5557ri7Vtx4/P+1RwAoF8Mkn1dZ70rfe5YED0vIJREREVJ3RA4U3bdqE2NhYrFq1CqGhoVi+fDkiIiKQmZkJT0/PauVLS0vxyCOPwNPTE19//TXatm2LCxcuoEWLFpoy6enpUJUvQw3g+PHjeOSRRzBmzBitc02fPh3/+te/NK9dXFyMrb71/eMfQGws4OAgZdDTMTf7t9/0H75zpzTtm4iIiLQZHdQsXboU06dPx9SpUwEAq1atwvbt27Fu3TrMnz+/Wvl169bh+vXrOHDgABwcHABILTOVtWnTRuv1kiVL0LFjRzz44INa211cXODt7W1slW3Lp59KP8vKgPvvB1avBqKjtYrccw/w00+6Dx861LzVIyIiaqiM6n4qLS1FRkYGwu+m9AcAuVyO8PBwpKam6jxm69atCAsLQ0xMDLy8vNCjRw8sWrRIq2Wm6jU+//xzPPPMM5DJZFr7NmzYAA8PD/To0QNxcXG4efOm3rqWlJSgsLBQ62F1SiXw9tsVr9Vq4Nlnpe2V6Eu+178/W2mIiIj0Maql5urVq1CpVPDy8tLa7uXlhZMnT+o85uzZs9i9ezcmTpyIHTt24PTp03j++edRVlaGhQsXViv/7bffIj8/H1FRUVrbJ0yYgHbt2sHX1xfHjh3DvHnzkJmZiS1btui87uLFi/Hmm28ac3vmpyv5nkolzX6qNK6mfPbTwIGAq6v0fOZMBjREREQ1MXvyPbVaDU9PT6xevRoKhQLBwcG4ePEi3nvvPZ1BTXx8PB577DH4+vpqbZ8xY4bmec+ePeHj44MhQ4bgzJkz6NixY7XzxMXFITY2VvO6sLAQ/v7+JryzOtCVfK+G2U/t2gGffWbB+hERETVgRnU/eXh4QKFQIC8vT2t7Xl6e3rEuPj4+6Ny5MxQKhWZbt27dkJubi9LSUq2yFy5cwI8//ohp06bVWpfQ0FAAwOkqOV7KOTk5wc3NTethdX5+wOTJFa/1zH4qD2ruDkEiIiIiAxgV1Dg6OiI4OBgpKSmabWq1GikpKQgLC9N5zIABA3D69GmoK3W7nDp1Cj4+PnB0dNQqu379enh6emL48OG11uXIkSMApKCpQWnVCgCQ3nUSop/6G499HY1Fi7SH1ZQv5H3hQrXhNkRERKSPMNLGjRuFk5OTSEhIEH/++aeYMWOGaNGihcjNzRVCCDF58mQxf/58Tfns7Gzh6uoqZs2aJTIzM0VSUpLw9PQUb7/9ttZ5VSqVCAgIEPPmzat2zdOnT4t//etf4tChQ+LcuXPiu+++Ex06dBCDBg0yuN4FBQUCgCgoKDD2lk0nMlIIQERinQDUQuqHqnisXSs9Km+TyaRtREREjZEx399GBzVCCPHRRx+JgIAA4ejoKEJCQsSvv/6q2ffggw+KyMhIrfIHDhwQoaGhwsnJSXTo0EG888474s6dO1pldu3aJQCIzMzMatfLzs4WgwYNEq1atRJOTk6iU6dO4uWXXzYqQLF6UJOWJgQg0tBXZ0BTHsDIZNW3KxRC5ORYp9pERETWZMz3t0wIHSsq2qHCwkK4u7ujoKDAOuNrli4FXnwRSzEHL2KZ0Yfv2QMMHmz6ahEREdkyY76/ufaTpQwcKP3APgC640iZTHpUpWOCFBEREVXBoMZS+vUDpkxBPxzCk9CdW2fNGulRmVyuc4IUERERVcHuJ0sqLgaaN8dxdEdPHNds7tYN+OGHisDFxQW4dQv48EPgiScY0BARUeNlzPe32ZPvUSWffAIAuIWmWpsDAysCFyGAkhLp+VNPAQ1txjoREZG1sPvJUpRK4OWXAQC34ay169atiudlZRUrKThrFyMiIqIasKXGUu6u+5SOvngHcVq7Dh8G7rsPcHfXjCcGABw/rv2aiIiI9GNQYymHDiEK65CIKADaU5wKC4HffpOe//RTxfZBg4DISCAhwUJ1JCIiasDY/WQJSiXSX/lKZ0BTm8REID3dLLUiIiKyKwxqLCErC3vxAIwNaMrt32/a6hAREdkjBjWWEBRUY9K92gwYYNrqEBER2SMGNZbg54d+a59DJBJgbGATGSnl7SMiIqKaMaixlF69kCCfBjnuAAAe6n8LixYB69cDw4YBAQHaxR9+GEhL4yBhIiIiQzGosYSoKCAkBHfUMqjhAADY7P8S4uKkXdu3A2+/rX3IoEFsoSEiIjIGgxpzS0+XpjBBO+ne9U0/aE1rqppo79w5i9SOiIjIbjCoMbe9ezVP12Ka5nlXnET8B/ma16+/rn1YYiIHCBMRERmDQY25de4MAFCiLV7EB5rNaijw7OZwKJVAUhJw8mT1Qw8ckPYRERFR7RjUmFuzZgCALARBDYXWLpVahtOngR079B++c6c5K0dERGQ/GNSYW1AQIJMhCFmQQ6W1S6EAOnWSZj/pM3SometHRERkJxjUmJufHxAdDT9cxHws1mxWKIBPPpF2jxgB9O9f/dD+/aV9REREVDsGNZbQoQMA4JEuSgBSTprz54Ho6Ioi+/cD27ZJrTbDhknPuTwCERGR4bhKt7nFxwMLFgAAbmeeBwC0bi210FQ1YgRbZoiIiOqKLTXmpFQCM2YAQloa4RaaAgCaKkqsWSsiIiK7xJYac8rKAtRqKNEWn2IiPsMkAEDuxTtQKp10ttYQERFR3bClxpyCghAvmwZ/ZGMB/o2T6AkAOHupGfz9pZ4pIiIiMg0GNWakhB+miU+g722eMUPqoSIiIqL6Y1BjRllZQE1vsVoNnD5tseoQERHZNQY1ZhQUBABqvfvlcin5HhEREdUfgxoz8ruUjrWYDn2BzerVuqd2ExERkfEY1JjT3r2IxjqMgLQqZSecwENIxqJhe5GTo518j4iIiOqHU7rNaeBAAIAcUp6aV7AU07EWeCMNYAsNERGRSbGlxpz69QMee0yTdM8Zt4HISGk7ERERmRSDGnN78UVcRhsAwMXn3wESEqxbHyIiIjtVp6BmxYoVCAwMhLOzM0JDQ5GWllZj+fz8fMTExMDHxwdOTk7o3LkzduzYodn/xhtvQCaTaT26du2qdY7bt28jJiYGrVu3RvPmzTF69Gjk5eXVpfoWFbWoM46iDwAg7uMAREVZtTpERER2y+igZtOmTYiNjcXChQtx+PBh9O7dGxEREbh8+bLO8qWlpXjkkUdw/vx5fP3118jMzMSaNWvQtm1brXLdu3fHpUuXNI99+/Zp7Z87dy62bduGzZs34+eff8Zff/2FJ5980tjqW1R6OpC42w+ATLMtMVHaTkRERKZl9EDhpUuXYvr06Zg6dSoAYNWqVdi+fTvWrVuH+fPnVyu/bt06XL9+HQcOHICDgwMAIDAwsHpFmjSBt7e3zmsWFBQgPj4eX3zxBR5++GEAwPr169GtWzf8+uuvuP/++429DYvYuxeoHNCU27+fw2qIiIhMzaiWmtLSUmRkZCA8PLziBHI5wsPDkZqaqvOYrVu3IiwsDDExMfDy8kKPHj2waNEiqFQqrXJZWVnw9fVFhw4dMHHiRGRnZ2v2ZWRkoKysTOu6Xbt2RUBAgN7rlpSUoLCwUOthaQOvfQvcnflUQWDAAItXhYiIyO4ZFdRcvXoVKpUKXl5eWtu9vLyQm5ur85izZ8/i66+/hkqlwo4dO/Daa6/hgw8+wNtvv60pExoaioSEBOzcuRMrV67EuXPnMHDgQNy4cQMAkJubC0dHR7Ro0cLg6y5evBju7u6ah7+/vzG3Wn9KJfotfhKPYUeljQKR+BT9fLjgExERkamZffaTWq2Gp6cnVq9ejeDgYIwdOxYLFizAqlWrNGUee+wxjBkzBr169UJERAR27NiB/Px8fPXVV3W+blxcHAoKCjSPnJwcU9yO4bKyACEQi2UAAC/8hTSEIAFRXPCJiIjIDIwaU+Ph4QGFQlFt1lFeXp7e8TA+Pj5wcHCAQqHQbOvWrRtyc3NRWloKR0fHase0aNECnTt3xum7X/7e3t4oLS1Ffn6+VmtNTdd1cnKCk5OTMbdnWtLCT7gNZwBAAJToh0OAQsEFn4iIiMzAqJYaR0dHBAcHIyUlRbNNrVYjJSUFYWFhOo8ZMGAATp8+DbW6Yv2jU6dOwcfHR2dAAwBFRUU4c+YMfHx8AADBwcFwcHDQum5mZiays7P1XtcmyGSaxHtNcUvatmQJF3wiIiIyA6O7n2JjY7FmzRokJibixIkTmDlzJoqLizWzoaZMmYK4uDhN+ZkzZ+L69euYPXs2Tp06he3bt2PRokWIiYnRlHnppZfw888/4/z58zhw4ACeeOIJKBQKjB8/HgDg7u6O6OhoxMbGYs+ePcjIyMDUqVMRFhZmszOfyrufyltqbsIFSrQF+va1csWIiIjsk9FTuseOHYsrV67g9ddfR25uLvr06YOdO3dqBg9nZ2dDLq+Ilfz9/bFr1y7MnTsXvXr1Qtu2bTF79mzMmzdPU0apVGL8+PG4du0a2rRpgwceeAC//vor2rRpoymzbNkyyOVyjB49GiUlJYiIiMDHH39cn3s3r6AgQC5HslqasXUI/dAOF7D6UAGiB1u3akRERPZIJoSoOufYLhUWFsLd3R0FBQVwc3OzyDWVLy5DwNLZEJUaxBQK4Px59kAREREZwpjvb679ZEZZ7R/VCmgAQKXi5CciIiJzYFBjRkFHv4YMaq1tnPxERERkHgxqzEWphF/8m4jALs0mBe7gkyXX2fVERERkBgxqzOXu7KfOOAUAmIjPcB6BiO57zMoVIyIisk8MaswlKEgrT01XZMJPkcu+JyIiIjNhUGMufn7AqFGaPDXOslLgk0847YmIiMhMjM5TQ0ZwdcVptAcAnJ7wKhBtmankREREjRFbaswlKgoDPp2OVDwAAPhkgysGDLBynYiIiOwYgxpzSE9HUuIVHMAAALK7G2U4cEAgKcmaFSMiIrJfDGrMYe9e7MAwVAQ05WTYudMaFSIiIrJ/DGrMYeBADMMOAFVXoBAYOtQaFSIiIrJ/DGrMoV8/jJjYEoE4V2mjQP/+MowYYbVaERER2TUGNebyn/9gBtYAALoG3MS2bTLs32/lOhEREdkxBjXmcuuWJvHewyNc2EJDRERkZgxqzOX2bU3ivaZNrVwXIiKiRoBBjbncuoXzCAAAXM8psnJliIiI7B+DGjOJmliGzRgLAFj/VTNEDThl5RoRERHZNwY1ZpCelIfE3+9F5cR7iQeCkJ6UZ81qERER2TUGNWawd0chdCXe27/zhjWqQ0RE1CgwqDGDgSfXQlfivQFDXa1RHSIiokaBQY2ppaej3553MRGfV9ooENnzN/Qb4WW1ahEREdk7BjWmtncvAGA55mo2pSIUCc/8Yq0aERERNQoMakxt4EAA0OSocUAp7kc6MGCANWtFRERk9xjUmFq/fsCUKZpswk1xC4iMlLYTERGR2TSxdgXsSVISsGIFIFOvhR9WAwDuODaF8u0E+Fm5bkRERPaOQY2JDBgAHDhQ/soBwPMAgJuljvD3F1i7VoboaGvVjoiIyP6x+8kEkpIqBzTlZFrPZ8wQUCotWCkiIqJGhkGNCezYUXsZtVqG06fNXxciIqLGikGNCQwbVnsZuVygUyfz14WIiKixYlBjAiNGAPfcU1MJgdX//ht+HC1MRERkNgxqTOS996pva4GrWIT5yIE/ovses3yliIiIGhHOfjKRW7eqb7sHmYjDvwGFAux7IiIiMq86tdSsWLECgYGBcHZ2RmhoKNLS0mosn5+fj5iYGPj4+MDJyQmdO3fGjkqjaxcvXox+/frB1dUVnp6eGDVqFDIzM7XOMXjwYMhkMq3Hc889V5fqm8Xt29W3OePuxiVLwL4nIiIi8zI6qNm0aRNiY2OxcOFCHD58GL1790ZERAQuX76ss3xpaSkeeeQRnD9/Hl9//TUyMzOxZs0atG3bVlPm559/RkxMDH799VckJyejrKwMjz76KIqLi7XONX36dFy6dEnzePfdd42tvtnoaqlRwhdKtAX69rV8hYiIiBoZo7ufli5diunTp2Pq1KkAgFWrVmH79u1Yt24d5s+fX638unXrcP36dRw4cAAODg4AgMDAQK0yO3fu1HqdkJAAT09PZGRkYNCgQZrtLi4u8Pb2NrbKFrF7d/Vtp9AN/sjB2kN/I3qwxatERETUqBjVUlNaWoqMjAyEh4dXnEAuR3h4OFJTU3Ues3XrVoSFhSEmJgZeXl7o0aMHFi1aBJVKpfc6BQUFAIBWrVppbd+wYQM8PDzQo0cPxMXF4ebNm3rPUVJSgsLCQq2HuSiVwMaN+vbKMGNeSybeIyIiMjOjWmquXr0KlUoFLy8vre1eXl44efKkzmPOnj2L3bt3Y+LEidixYwdOnz6N559/HmVlZVi4cGG18mq1GnPmzMGAAQPQo0cPzfYJEyagXbt28PX1xbFjxzBv3jxkZmZiy5YtOq+7ePFivPnmm8bcXp1lZQFC6N9fnniPw2qIiIjMx+yzn9RqNTw9PbF69WooFAoEBwfj4sWLeO+993QGNTExMTh+/Dj27duntX3GjBma5z179oSPjw+GDBmCM2fOoGPHjtXOExcXh9jYWM3rwsJC+Pv7m/DOKgQFATKZ/sBGSrwn072TiIiITMKo7icPDw8oFArk5eVpbc/Ly9M71sXHxwedO3eGQqHQbOvWrRtyc3NRWlqqVXbWrFlISkrCnj174FdLs0ZoaCgA4LSetQecnJzg5uam9TAXPz9gyIDK05+E1vPVq2VspSEiIjIzo4IaR0dHBAcHIyUlRbNNrVYjJSUFYWFhOo8ZMGAATp8+DbVardl26tQp+Pj4wNHREQAghMCsWbPwzTffYPfu3Wjfvn2tdTly5AgAKWiyBR1bXgMARGEd1iMSkVgvJd776leuzk1ERGQBRk/pjo2NxZo1a5CYmIgTJ05g5syZKC4u1syGmjJlCuLi4jTlZ86cievXr2P27Nk4deoUtm/fjkWLFiEmJkZTJiYmBp9//jm++OILuLq6Ijc3F7m5ubh1d570mTNn8NZbbyEjIwPnz5/H1q1bMWXKFAwaNAi9evWq73tgEredWgAAuuEkovAZEvAM4hTvwy/MPF1eREREpM3oMTVjx47FlStX8PrrryM3Nxd9+vTBzp07NYOHs7OzIZdXxEr+/v7YtWsX5s6di169eqFt27aYPXs25s2bpymzcuVKAFKCvcrWr1+PqKgoODo64scff8Ty5ctRXFwMf39/jB49Gq+++mpd7tksbsmbAQCa4m7CGrkc+OQTjg4mIiKyEJkQNc3bsR+FhYVwd3dHQUGBycfXJCUBzzwDXLkCxDSLx3+Lp0kBTaXBzURERGQ8Y76/ufZTPd1/P3DwYMXrFcXP4Dd0wf6ZD0prPnFADRERkUVwle56SErSDmgkMhzAACSphwLPPgtm3SMiIrIMBjX1UGlNzipk2InHAJUK0DPlnIiIiEyLQU09DBumb4/AUHwvDRbu1MmSVSIiImq0GNTUw4gRQP/+QNVke/2xHyOwo+a1E4iIiMikGNTU0/79wLZ3jmEYtmIYtmEbRmA/Bko7hWD3ExERkYVw9pMJjJjSGiMW9Km+Q6Fg9xMRmYRara62tAyRPXBwcNBaSqk+GNSYwqVLurfPn8/ke0RUb6WlpTh37pzWcjNE9qRFixbw9vaGTFa/xZ8Z1JjC3r26t3t4WLYeRGR3hBC4dOkSFAoF/P39tTK2EzV0QgjcvHkTly9fBlD/9RwZ1JjCwIG6tw8YYNl6EJHduXPnDm7evAlfX1+4uLhYuzpEJte0aVMAwOXLl+Hp6VmvriiG/KbQrx/w6KPa2yIjpe1ERPWgUqkAAI6OjlauCZH5lAfsZWVl9ToPgxpTeeEF6ae/P5CWBiQkWLU6RGRf6jvWgMiWmerzzaDGVG7dXZ07MJAtNERERFbAoMZUbt+Wft7tGyQiItMKDAzE8uXLrV0NsmEMakylvKWmqIiLWBJRoyaTyWp8vPHGG3U6b3p6OmbMmGGSOn755ZdQKBSIiYkxyfnINjCoMZU9e6SfBw4A7doB8fHWrQ8RkZVcunRJ81i+fDnc3Ny0tr300kuaskII3Llzx6DztmnTxmQzwOLj4/HKK6/gyy+/xO3ylnYrYVJF02FQYwpKJbBpU8VrtRp49lm22BCRbVEqpf+Amflvk7e3t+bh7u4OmUymeX3y5Em4urri+++/R3BwMJycnLBv3z6cOXMGjz/+OLy8vNC8eXP069cPP/74o9Z5q3Y/yWQyrF27Fk888QRcXFwQFBSErVu31lq/c+fO4cCBA5g/fz46d+6MLVu2VCuzbt06dO/eHU5OTvDx8cGsWbM0+/Lz8/Hss8/Cy8sLzs7O6NGjB5KSkgAAb7zxBvr06aN1ruXLlyMwMFDzOioqCqNGjcI777wDX19fdOnSBQDw2WefoW/fvnB1dYW3tzcmTJigyd9S7o8//sCIESPg5uYGV1dXDBw4EGfOnMEvv/wCBwcH5ObmapWfM2cOBupLO2KHGNSYQlZW9cUrVSqu+0REpicEUFxs/OPjj6VW5Icfln5+/LHx5zDhIr3z58/HkiVLcOLECfTq1QtFRUUYNmwYUlJS8Ntvv2Ho0KEYOXIksrOzazzPm2++iaeffhrHjh3DsGHDMHHiRFy/fr3GY9avX4/hw4fD3d0dkyZNQnyVlvWVK1ciJiYGM2bMwO+//46tW7ei090lb9RqNR577DHs378fn3/+Of78808sWbLE6NwqKSkpyMzMRHJysiYgKisrw1tvvYWjR4/i22+/xfnz5xEVFaU55uLFixg0aBCcnJywe/duZGRk4JlnnsGdO3cwaNAgdOjQAZ999pmmfFlZGTZs2IBnnnnGqLo1aKKRKCgoEABEQUGB6U+ekyOETCaE9E9eeigU0nYionq4deuW+PPPP8WtW7ekDUVF2n9rLPkoKjK6/uvXrxfu7u6a13v27BEAxLffflvrsd27dxcfffSR5nW7du3EsmXLNK8BiFdffVXzuqioSAAQ33//vd5zqlQq4e/vr7n+lStXhKOjozh79qymjK+vr1iwYIHO43ft2iXkcrnIzMzUuX/hwoWid+/eWtuWLVsm2rVrp3kdGRkpvLy8RElJid56CiFEenq6ACBu3LghhBAiLi5OtG/fXpSWluos/+9//1t069ZN8/p///ufaN68uSiqw+/N0qp9zisx5vubLTWm4OennT1YoQA++YTrPhER6dG3b1+t10VFRXjppZfQrVs3tGjRAs2bN8eJEydqbanp1auX5nmzZs3g5uZWrcumsuTkZBQXF2PYsGEAAA8PDzzyyCNYt24dACmr7V9//YUhQ4boPP7IkSPw8/ND586dDbpPfXr27FktoWJGRgZGjhyJgIAAuLq64sEHHwQAzXtw5MgRDBw4EA4ODjrPGRUVhdOnT+PXX38FACQkJODpp59Gs2bN6lXXhoTLJJiKu7v0MyoKeOstBjREZB4uLtIsS2NcvAh06yaN9yunUAB//gm0bWvctU2k6hftSy+9hOTkZLz//vvo1KkTmjZtiqeeeqrWQbRVv+BlMlmNC3/Gx8fj+vXrmtT8gNSldOzYMbz55pta23Wpbb9cLoeo0k2nK0tu1fsvLi5GREQEIiIisGHDBrRp0wbZ2dmIiIjQvAe1XdvT0xMjR47E+vXr0b59e3z//ff46aefajzG3jCoMYX4eGD7dul5YiLwwANAdLR160RE9kkmA4z9n3fnzsDq1dIEBpWqojW5nq0NprR//35ERUXhiSeeACC13Jw/f96k17h27Rq+++47bNy4Ed27d9dsV6lUeOCBB/DDDz9g6NChCAwMREpKCh566KFq5+jVqxeUSiVOnTqls7WmTZs2yM3NhRBCkyX3yJEjtdbt5MmTuHbtGpYsWQJ/f38AwKFDh6pdOzExEWVlZXpba6ZNm4bx48fDz88PHTt2xIBGtgYhu5/qS6kEKudNEIIzn4jI9kRHA+fPS7Ofzp+3uf94BQUFYcuWLThy5AiOHj2KCRMm1NjiUhefffYZWrdujaeffho9evTQPHr37o1hw4ZpBgy/8cYb+OCDD/Dhhx8iKysLhw8fxkcffQQAePDBBzFo0CCMHj0aycnJOHfuHL7//nvs3LkTADB48GBcuXIF7777Ls6cOYMVK1bg+++/r7VuAQEBcHR0xEcffYSzZ89i69ateOutt7TKzJo1C4WFhRg3bhwOHTqErKwsfPbZZ8jMzNSUiYiIgJubG95++21MnTrVVG9dg8Ggpr6ysrSbdAHOfCIi2+TnBwwebJPd40uXLkXLli3Rv39/jBw5EhEREbjvvvtMeo1169bhiSee0LnO0OjRo7F161ZcvXoVkZGRWL58OT7++GN0794dI0aMQFZWlqbs//73P/Tr1w/jx4/HPffcg1deeUWz8Gi3bt3w8ccfY8WKFejduzfS0tK08vLo06ZNGyQkJGDz5s245557sGTJErz//vtaZVq3bo3du3ejqKgIDz74IIKDg7FmzRqtVhu5XI6oqCioVCpMmTKlrm9VgyUTVTv/7FRhYSHc3d1RUFAANzc3051YqZSmR1btqz5/3ib/cBBRw3L79m2cO3cO7du3h7Ozs7WrQw1AdHQ0rly5YlDOHltR0+fcmO9vttTUl5+f1FddTi7nzCciIrK4goIC7Nu3D1988QVeeOEFa1fHKhjUmEJ0NFDe/PfNNzbXV01ERPbv8ccfx6OPPornnnsOjzzyiLWrYxWc/WQKq1cD5VP2nnhCes3AhoiILKixTd/WhS019aVUAjNnVrzmuk9ERERWwaCmvjj7iYiIyCYwqKmvoCApGVZlcjlwd/EzIiIisgwGNaZQdVZ845glT0REZFPqFNSsWLECgYGBcHZ2RmhoKNLS0mosn5+fj5iYGPj4+MDJyQmdO3fGjh07jDrn7du3ERMTg9atW6N58+YYPXo08vLy6lJ906qUkElDCHY/ERERWZjRQc2mTZsQGxuLhQsX4vDhw+jduzciIiL0ropaWlqKRx55BOfPn8fXX3+NzMxMrFmzBm0rLaJmyDnnzp2Lbdu2YfPmzfj555/x119/4cknn6zDLZuYru4nhYLdT0RERJYmjBQSEiJiYmI0r1UqlfD19RWLFy/WWX7lypWiQ4cOorS0tM7nzM/PFw4ODmLz5s2aMidOnBAARGpqqkH1LigoEABEQUGBQeWNMmyYEFL7jBAKhRBr15r+GkTUKN26dUv8+eef4tatW9auisU9+OCDYvbs2ZrX7dq1E8uWLavxGADim2++qfe1TXUeMkxNn3Njvr+NaqkpLS1FRkYGwsPDNdvkcjnCw8ORmpqq85itW7ciLCwMMTEx8PLyQo8ePbBo0SLNOhmGnDMjIwNlZWVaZbp27YqAgAC91y0pKUFhYaHWw2w8PaWfTzxhkwvFERFZ0siRIzF06FCd+/bu3QuZTIZjx44Zfd709HTMqLyAsAm88cYb6NOnT7Xtly5dwmOPPWbSa+lz69YttGrVCh4eHigpKbHINe2VUUHN1atXoVKp4OXlpbXdy8sLubm5Oo85e/Ysvv76a6hUKuzYsQOvvfYaPvjgA7z99tsGnzM3NxeOjo5o0aKFwdddvHgx3N3dNY/ypdxNLj4eSEyUnn/7LbBrl3muQ0TUQERHRyM5ORlKHfm61q9fj759+6JXr15Gn7dNmzZwcXExRRVr5e3tDScnJ4tc63//+x+6d++Orl274ttvv7XINfURQuDOnTtWrUN9mH32k1qthqenJ1avXo3g4GCMHTsWCxYswKpVq8x63bi4OBQUFGgeOTk5pr+IUgnMmFEx20kIJt4jIpulVAJ79pj/T9SIESM0q05XVlRUhM2bNyM6OhrXrl3D+PHj0bZtW7i4uKBnz5748ssvazxvYGAgli9frnmdlZWFQYMGwdnZGffccw+Sk5OrHTNv3jx07twZLi4u6NChA1577TWU3c0An5CQgDfffBNHjx6FTCaDTCbT1Fkmk2kFGL///jsefvhhNG3aFK1bt8aMGTNQVFSk2R8VFYVRo0bh/fffh4+PD1q3bo2YmBjNtWoSHx+PSZMmYdKkSYiPj6+2/48//sCIESPg5uYGV1dXDBw4EGfOnNHsX7duHbp37w4nJyf4+Phg1qxZAIDz589DJpPhyJEjmrL5+fmQyWSa7MM//fQTZDIZvv/+ewQHB8PJyQn79u3DmTNn8Pjjj8PLywvNmzdHv3798OOPP2rVq6SkBPPmzYO/vz+cnJzQqVMnxMfHQwiBTp06VVtl/MiRI5DJZDhtxok0Ri2T4OHhAYVCUW3WUV5eHry9vXUe4+PjAwcHBygUCs22bt26ITc3F6WlpQad09vbG6WlpcjPz9dqranpuk5OTuaPsmtKvMcFLYnIDIQAbt40/rjEROCFF6Q/WXI58NFHQGSkcedwcak+L0KXJk2aYMqUKUhISMCCBQsgu3vQ5s2boVKpMH78eBQVFSE4OBjz5s2Dm5sbtm/fjsmTJ6Njx44ICQmp9RpqtRpPPvkkvLy8cPDgQRQUFGDOnDnVyrm6uiIhIQG+vr74/fffMX36dLi6uuKVV17B2LFjcfz4cezcuVPzhe3u7l7tHMXFxYiIiEBYWBjS09Nx+fJlTJs2DbNmzdIK3Pbs2QMfHx/s2bMHp0+fxtixY9GnTx9Mnz5d732cOXMGqamp2LJlC4QQmDt3Li5cuIB27doBAC5evIhBgwZh8ODB2L17N9zc3LB//35Na8rKlSsRGxuLJUuW4LHHHkNBQQH2799f6/tX1fz58/H++++jQ4cOaNmyJXJycjBs2DC88847cHJywqeffoqRI0ciMzMTAQEBAIApU6YgNTUVH374IXr37o1z587h6tWrkMlkeOaZZ7B+/Xq89NJLmmusX78egwYNQidzTqQxdjBPSEiImDVrlua1SqUSbdu21TtQOC4uTrRr106oVCrNtuXLlwsfHx+Dz1k+UPjrr7/WlDl58qT1Bwrn5Aghk1UMEgaEkMul7UREJlB1AGVRkfafHEs+iooMr3f5ZI49e/Zotg0cOFBMmjRJ7zHDhw8XL774ouZ1TQOFd+3aJZo0aSIuXryo2f/999/XOsD3vffeE8HBwZrXCxcuFL17965WrvJ5Vq9eLVq2bCmKKr0B27dvF3K5XOTm5gohhIiMjBTt2rUTd+7c0ZQZM2aMGDt2rN66CCHEP//5TzFq1CjN68cff1wsXLhQ8zouLk60b99e72QbX19fsWDBAp37zp07JwCI3377TbPt77//1vq97NmzRwAQ3377bY31FEKI7t27i48++kgIIURmZqYAIJKTk3WWvXjxolAoFOLgwYNCCCFKS0uFh4eHSEhI0FneKgOFASA2NhZr1qxBYmIiTpw4gZkzZ6K4uBhTp04FIEVucXFxmvIzZ87E9evXMXv2bJw6dQrbt2/HokWLEBMTY/A53d3dER0djdjYWOzZswcZGRmYOnUqwsLCcP/999ctmjMXJt4jIkLXrl3Rv39/rFu3DgBw+vRp7N27F9F3J1KoVCq89dZb6NmzJ1q1aoXmzZtj165dyM7ONuj8J06cgL+/P3x9fTXbwsLCqpXbtGkTBgwYAG9vbzRv3hyvvvqqwdeofK3evXujWbNmmm0DBgyAWq1GZmamZlv37t21eiV8fHz0pjsBpPcgMTERkyZN0mybNGkSEhISoL7bC3DkyBEMHDgQDg4O1Y6/fPky/vrrLwwZMsSo+9Glb9++Wq+Liorw0ksvoVu3bmjRogWaN2+OEydOaN67I0eOQKFQ4MEHH9R5Pl9fXwwfPlzz+9+2bRtKSkowZsyYete1Jkav0j127FhcuXIFr7/+OnJzc9GnTx/s3LlTM9A3OzsbcnlFrOTv749du3Zh7ty56NWrF9q2bYvZs2dj3rx5Bp8TAJYtWwa5XI7Ro0ejpKQEERER+Pjjj+tz7/WXlaU7mzC7n4jITFxcgEpDOQxy8SLQrZt2b7lCAfz5J1ApZZhB1zZGdHQ0XnjhBaxYsQLr169Hx44dNV+C7733Hv7zn/9g+fLl6NmzJ5o1a4Y5c+agtLTUuIvUIDU1FRMnTsSbb76JiIgIuLu7Y+PGjfjggw9Mdo3KqgYeMplME5zosmvXLly8eBFjx47V2q5SqZCSkoJHHnkETZs21Xt8TfsAaL6LRaXvKX1jfCoHbADw0ksvITk5Ge+//z46deqEpk2b4qmnntL8fmq7NgBMmzYNkydPxrJly7B+/XqMHTvW7AO9jQ5qAGDWrFmagUhV6Vr6PCwsDL/++mudzwkAzs7OWLFiBVasWGFUXc2qeXPd26t8OIiITEUmM/5PTOfOwOrV0jwGlUoKaD75RNpuTk8//TRmz56NL774Ap9++ilmzpypGV+zf/9+PP7445pWCrVajVOnTuGee+4x6NzdunVDTk4OLl26BB8fHwCo9j1z4MABtGvXDgsWLNBsu3DhglYZR0dHTYqRmq6VkJCA4uJizZf//v37IZfL0aVLF4Pqq0t8fDzGjRunVT8AeOeddxAfH49HHnkEvXr1QmJiIsrKyqoFTa6urggMDERKSgoeeuihaudv06YNAGl6+r333gsAWoOGa7J//35ERUXhiSeeACC13Jw/f16zv2fPnlCr1fj555+10q1UNmzYMDRr1gwrV67Ezp078csvvxh07frg2k/1oe+/S8XFlq0HEVEtoqOlNFp79lgunVbz5s0xduxYxMXF4dKlS4iKitLsCwoKQnJyMg4cOIATJ07g2WefNWrpm/DwcHTu3BmRkZE4evQo9u7dWy04CAoKQnZ2NjZu3IgzZ87gww8/xDfffKNVJjAwEOfOncORI0dw9epVnXliJk6cCGdnZ0RGRuL48ePYs2cPXnjhBUyePLlaOhJDXblyBdu2bUNkZCR69Oih9ZgyZQq+/fZbXL9+HbNmzUJhYSHGjRuHQ4cOISsrC5999pmm2+uNN97ABx98gA8//BBZWVk4fPgwPvroIwBSa8r999+PJUuW4MSJE/j555/x6quvGlS/oKAgbNmyBUeOHMHRo0cxYcIErVanwMBAREZG4plnnsG3336Lc+fO4aeffsJXX32lKaNQKBAVFYW4uDgEBQXp7B40NQY19REUJE0jqIxLJBCRjfLzAwYPtmzveHR0NP7++29ERERojX959dVXcd999yEiIgKDBw+Gt7c3Ro0aZfB55XI5vvnmG9y6dQshISGYNm0a3nnnHa0y//jHPzB37lzMmjULffr0wYEDB/Daa69plRk9ejSGDh2Khx56CG3atNE5rdzFxQW7du3C9evX0a9fPzz11FMYMmQI/vvf/xr3ZlTy6aefolmzZjrHwwwZMgRNmzbF559/jtatW2P37t0oKirCgw8+iODgYKxZs0bTahMZGYnly5fj448/Rvfu3TFixAhkVVqTcN26dbhz5w6Cg4MxZ84cTY642ixduhQtW7ZE//79MXLkSEREROC+++7TKrNy5Uo89dRTeP7559G1a1dMnz4dxVX+Ux8dHY3S0lLNGFlzkwnROEa2FhYWwt3dHQUFBXBzczPdiePjq7fpMqMwEZnI7du3ce7cObRv3x7Ozs7Wrg6RUfbu3YshQ4YgJyenxlatmj7nxnx/12lMDVUSHQ1EREiDgzt14gBhIiJq9EpKSnDlyhW88cYbGDNmTJ276YzF7idTsEabLhERkY368ssv0a5dO+Tn5+Pdd9+12HUZ1BAREZFJRUVFQaVSISMjA22NyRtQTwxqiIiIyC4wqCEiIiK7wKCGiKgBaCQTVamRqinzsjE4+4mIyIY5ODhAJpPhypUraNOmjSYjL5E9EEKgtLQUV65cgVwuh6OjY73Ox6CGiMiGKRQK+Pn5QalUaqWpJ7InLi4uCAgI0Fo7si4Y1BAR2bjmzZsjKChI72KERA2ZQqFAkyZNTNIKyaCGiKgBUCgUUCgU1q4GkU3jQGEiIiKyCwxqiIiIyC4wqCEiIiK70GjG1JTneCgsLLRyTYiIiMhQ5d/bhuRqajRBzY0bNwAA/v7+Vq4JERERGevGjRtwd3evsYxMNJI0lWq1Gn/99RdcXV1NnryqsLAQ/v7+yMnJgZubm0nPbYt4v/aN92v/Gts9834bNiEEbty4AV9f31rz2DSalhq5XA4/Pz+zXsPNzc0uPkCG4v3aN96v/Wts98z7bbhqa6Epx4HCREREZBcY1BAREZFdYFBjAk5OTli4cCGcnJysXRWL4P3aN96v/Wts98z7bTwazUBhIiIism9sqSEiIiK7wKCGiIiI7AKDGiIiIrILDGqIiIjILjCoqacVK1YgMDAQzs7OCA0NRVpamrWrVCeLFy9Gv3794OrqCk9PT4waNQqZmZlaZW7fvo2YmBi0bt0azZs3x+jRo5GXl6dVJjs7G8OHD4eLiws8PT3x8ssv486dO5a8lTpZsmQJZDIZ5syZo9lmb/d78eJFTJo0Ca1bt0bTpk3Rs2dPHDp0SLNfCIHXX38dPj4+aNq0KcLDw5GVlaV1juvXr2PixIlwc3NDixYtEB0djaKiIkvfSq1UKhVee+01tG/fHk2bNkXHjh3x1ltvaa0d09Dv95dffsHIkSPh6+sLmUyGb7/9Vmu/qe7v2LFjGDhwIJydneHv7493333X3LemU033W1ZWhnnz5qFnz55o1qwZfH19MWXKFPz1119a57CX+63queeeg0wmw/Lly7W2N6T7NRlBdbZx40bh6Ogo1q1bJ/744w8xffp00aJFC5GXl2ftqhktIiJCrF+/Xhw/flwcOXJEDBs2TAQEBIiioiJNmeeee074+/uLlJQUcejQIXH//feL/v37a/bfuXNH9OjRQ4SHh4vffvtN7NixQ3h4eIi4uDhr3JLB0tLSRGBgoOjVq5eYPXu2Zrs93e/169dFu3btRFRUlDh48KA4e/as2LVrlzh9+rSmzJIlS4S7u7v49ttvxdGjR8U//vEP0b59e3Hr1i1NmaFDh4revXuLX3/9Vezdu1d06tRJjB8/3hq3VKN33nlHtG7dWiQlJYlz586JzZs3i+bNm4v//Oc/mjIN/X537NghFixYILZs2SIAiG+++UZrvynur6CgQHh5eYmJEyeK48ePiy+//FI0bdpUfPLJJ5a6TY2a7jc/P1+Eh4eLTZs2iZMnT4rU1FQREhIigoODtc5hL/db2ZYtW0Tv3r2Fr6+vWLZsmda+hnS/psKgph5CQkJETEyM5rVKpRK+vr5i8eLFVqyVaVy+fFkAED///LMQQvqj4eDgIDZv3qwpc+LECQFApKamCiGkf4RyuVzk5uZqyqxcuVK4ubmJkpISy96AgW7cuCGCgoJEcnKyePDBBzVBjb3d77x588QDDzygd79arRbe3t7ivffe02zLz88XTk5O4ssvvxRCCPHnn38KACI9PV1T5vvvvxcymUxcvHjRfJWvg+HDh4tnnnlGa9uTTz4pJk6cKISwv/ut+qVnqvv7+OOPRcuWLbU+z/PmzRNdunQx8x3VrKYv+XJpaWkCgLhw4YIQwj7vV6lUirZt24rjx4+Ldu3aaQU1Dfl+64PdT3VUWlqKjIwMhIeHa7bJ5XKEh4cjNTXVijUzjYKCAgBAq1atAAAZGRkoKyvTut+uXbsiICBAc7+pqano2bMnvLy8NGUiIiJQWFiIP/74w4K1N1xMTAyGDx+udV+A/d3v1q1b0bdvX4wZMwaenp649957sWbNGs3+c+fOITc3V+t+3d3dERoaqnW/LVq0QN++fTVlwsPDIZfLcfDgQcvdjAH69++PlJQUnDp1CgBw9OhR7Nu3D4899hgA+7vfqkx1f6mpqRg0aBAcHR01ZSIiIpCZmYm///7bQndTNwUFBZDJZGjRogUA+7tftVqNyZMn4+WXX0b37t2r7be3+zUUg5o6unr1KlQqldYXGgB4eXkhNzfXSrUyDbVajTlz5mDAgAHo0aMHACA3NxeOjo6aPxDlKt9vbm6uzvejfJ+t2bhxIw4fPozFixdX22dv93v27FmsXLkSQUFB2LVrF2bOnIn/+7//Q2JiIoCK+tb0ec7NzYWnp6fW/iZNmqBVq1Y2d7/z58/HuHHj0LVrVzg4OODee+/FnDlzMHHiRAD2d79Vmer+GtJnvLLbt29j3rx5GD9+vGZBR3u733//+99o0qQJ/u///k/nfnu7X0M1mlW6yXAxMTE4fvw49u3bZ+2qmE1OTg5mz56N5ORkODs7W7s6ZqdWq9G3b18sWrQIAHDvvffi+PHjWLVqFSIjI61cO9P76quvsGHDBnzxxRfo3r07jhw5gjlz5sDX19cu75cqlJWV4emnn4YQAitXrrR2dcwiIyMD//nPf3D48GHIZDJrV8emsKWmjjw8PKBQKKrNhsnLy4O3t7eValV/s2bNQlJSEvbs2QM/Pz/Ndm9vb5SWliI/P1+rfOX79fb21vl+lO+zJRkZGbh8+TLuu+8+NGnSBE2aNMHPP/+MDz/8EE2aNIGXl5dd3a+Pjw/uuecerW3dunVDdnY2gIr61vR59vb2xuXLl7X237lzB9evX7e5+3355Zc1rTU9e/bE5MmTMXfuXE2rnL3db1Wmur+G9BkHKgKaCxcuIDk5WdNKA9jX/e7duxeXL19GQECA5u/XhQsX8OKLLyIwMBCAfd2vMRjU1JGjoyOCg4ORkpKi2aZWq5GSkoKwsDAr1qxuhBCYNWsWvvnmG+zevRvt27fX2h8cHAwHBwet+83MzER2drbmfsPCwvD7779r/UMq/8NS9QvV2oYMGYLff/8dR44c0Tz69u2LiRMnap7b0/0OGDCg2hT9U6dOoV27dgCA9u3bw9vbW+t+CwsLcfDgQa37zc/PR0ZGhqbM7t27oVarERoaaoG7MNzNmzchl2v/eVMoFFCr1QDs736rMtX9hYWF4ZdffkFZWZmmTHJyMrp06YKWLVta6G4MUx7QZGVl4ccff0Tr1q219tvT/U6ePBnHjh3T+vvl6+uLl19+Gbt27QJgX/drFGuPVG7INm7cKJycnERCQoL4888/xYwZM0SLFi20ZsM0FDNnzhTu7u7ip59+EpcuXdI8bt68qSnz3HPPiYCAALF7925x6NAhERYWJsLCwjT7y6c4P/roo+LIkSNi586dok2bNjY5xVmXyrOfhLCv+01LSxNNmjQR77zzjsjKyhIbNmwQLi4u4vPPP9eUWbJkiWjRooX47rvvxLFjx8Tjjz+ucwrwvffeKw4ePCj27dsngoKCbGaKc2WRkZGibdu2mindW7ZsER4eHuKVV17RlGno93vjxg3x22+/id9++00AEEuXLhW//fabZraPKe4vPz9feHl5icmTJ4vjx4+LjRs3ChcXF6tM+a3pfktLS8U//vEP4efnJ44cOaL1N6zyzB57uV9dqs5+EqJh3a+pMKipp48++kgEBAQIR0dHERISIn799VdrV6lOAOh8rF+/XlPm1q1b4vnnnxctW7YULi4u4oknnhCXLl3SOs/58+fFY489Jpo2bSo8PDzEiy++KMrKyix8N3VTNaixt/vdtm2b6NGjh3BychJdu3YVq1ev1tqvVqvFa6+9Jry8vISTk5MYMmSIyMzM1Cpz7do1MX78eNG8eXPh5uYmpk6dKm7cuGHJ2zBIYWGhmD17tggICBDOzs6iQ4cOYsGCBVpfcA39fvfs2aPz32xkZKQQwnT3d/ToUfHAAw8IJycn0bZtW7FkyRJL3aKWmu733Llzev+G7dmzR3MOe7lfXXQFNQ3pfk1FJkSlFJtEREREDRTH1BAREZFdYFBDREREdoFBDREREdkFBjVERERkFxjUEBERkV1gUENERER2gUENERER2QUGNURERGQXGNQQERGRXWBQQ0RERHaBQQ0RERHZBQY1REREZBf+H7x1Tp47piA1AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1nc.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1nc.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1nc.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1nc.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkYhvnPLUAIM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_env",
      "language": "python",
      "name": "dl_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
