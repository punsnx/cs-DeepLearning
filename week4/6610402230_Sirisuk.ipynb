{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLogkosUAH-"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Uqx7woUAIF"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## Pima Diabetes Dataset\n",
        "\n",
        "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvQhWj5UAIF"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xv268rbuUAIG"
      },
      "outputs": [],
      "source": [
        "#Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "B8p6y-7qUAIH"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C39rLYeaUAIH"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Load in the data set (Internet Access needed)\n",
        "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
        "\n",
        "seed_value = 11111\n",
        "url = \"https://raw.githubusercontent.com/punsnx/cs_datasets/main/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(url, names=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCr0krluUAIH",
        "outputId": "b2cd2714-31b8-4cc2-fbfe-95a6bae7b6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ]
        }
      ],
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "# diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "N9gywmErXEpJ",
        "outputId": "ac14d7bd-2206-4fc4-bf1b-b2bfb2254bc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "0               6                     148              72              35   \n",
              "1               1                      85              66              29   \n",
              "2               8                     183              64               0   \n",
              "3               1                      89              66              23   \n",
              "4               0                     137              40              35   \n",
              "\n",
              "   insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "0        0  33.6              0.627   50             1  \n",
              "1        0  26.6              0.351   31             0  \n",
              "2        0  23.3              0.672   32             1  \n",
              "3       94  28.1              0.167   21             0  \n",
              "4      168  43.1              2.288   33             1  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TBnwBgsWUAIH"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values #train features\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUeCzRaPV4d8",
        "outputId": "96bb4467-e347-4876-fe50-690922aafb08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rEa33td5UAII"
      },
      "outputs": [],
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "# stratify คือ การกำหนดการกระจายของข้อมูลที่ split ให้มีการกระจายเหมือน original dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcXPGFWUAII",
        "outputId": "3bdf9246-fbe1-45da-e369-f78932b71cd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSIknieUAII"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1Q2BRmB1UAII",
        "outputId": "10c88a2e-f211-4377-a14d-badf2ede1418"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=11111)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=seed_value)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEybpR4UAII",
        "outputId": "470ce235-319b-4290-a9f6-8df6ae5bfbb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.795\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "1YR5seGYUAIJ",
        "outputId": "32d18a68-cf19-4359-a8e7-eff2c641cb5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MMLGxSUAIJ"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 8 nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uviwG3g_UAIJ"
      },
      "outputs": [],
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW2ikMYhaZYm",
        "outputId": "6e63467c-45f0-494a-de33-0296ea7e99d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.17553013, -0.88319193, -0.4797748 , ..., -0.41547152,\n",
              "         0.23300528, -0.95829939],\n",
              "       [-1.17553013, -1.35145275,  0.9447112 , ...,  0.60441055,\n",
              "        -0.07457346, -1.04227634],\n",
              "       [-0.58157806, -0.50858328, -0.5815238 , ...,  0.35565882,\n",
              "        -0.73053221, -0.70636856],\n",
              "       ...,\n",
              "       [ 0.60632606, -0.1964094 , -0.4797748 , ...,  0.20640779,\n",
              "        -0.66776104,  0.55328559],\n",
              "       [-0.87855409,  0.86498179, -0.0727788 , ..., -0.340846  ,\n",
              "        -0.34135094,  0.72123948],\n",
              "       [ 1.49725416,  0.95863395,  0.4359662 , ...,  0.26859572,\n",
              "         1.36602495, -0.03455301]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzAKCitoajRT",
        "outputId": "2773af3d-0246-47ff-84ac-47f81f402312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.012374  ,  1.02106873,  0.1307192 , ..., -0.09209428,\n",
              "        -0.37587509,  0.30135476],\n",
              "       [ 1.79423019,  0.36550358, -0.0727788 , ..., -0.62691048,\n",
              "        -0.66776104,  0.21737782],\n",
              "       [-0.58157806,  1.64541648,  0.9447112 , ...,  1.54966709,\n",
              "         0.59080097, -0.79034551],\n",
              "       ...,\n",
              "       [ 0.012374  , -0.78953977, -0.6832728 , ..., -1.39804083,\n",
              "        -0.36959797, -0.62239162],\n",
              "       [-0.87855409, -0.29006156,  0.1307192 , ...,  0.29347089,\n",
              "         0.22045105, -0.70636856],\n",
              "       [ 0.9033021 , -0.47736589, -0.4797748 , ..., -0.68909841,\n",
              "        -0.50769455, -0.37046079]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3nIrw2ZEUAIJ"
      },
      "outputs": [],
      "source": [
        "# Define the Model\n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 8 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "import os, random, numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha9-w35OUAIJ",
        "outputId": "1e6c71f4-ed26-4e7b-e40f-4f944b473d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81\n",
            "Trainable params: 81\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHF08OSCUAIK"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 81 parameters?  Does that make sense?\n",
        "\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ4Tj8EiUAIK",
        "outputId": "c0a043f8-e6c6-436c-e2cc-1e632e4178b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.7662 - accuracy: 0.4688 - val_loss: 0.7449 - val_accuracy: 0.5104\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7588 - accuracy: 0.4774 - val_loss: 0.7373 - val_accuracy: 0.5156\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.4861 - val_loss: 0.7302 - val_accuracy: 0.5312\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7452 - accuracy: 0.5035 - val_loss: 0.7234 - val_accuracy: 0.5625\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.5191 - val_loss: 0.7171 - val_accuracy: 0.5677\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.5295 - val_loss: 0.7113 - val_accuracy: 0.5781\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7278 - accuracy: 0.5434 - val_loss: 0.7057 - val_accuracy: 0.6042\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7226 - accuracy: 0.5538 - val_loss: 0.7004 - val_accuracy: 0.6146\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.5642 - val_loss: 0.6955 - val_accuracy: 0.6146\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.5712 - val_loss: 0.6909 - val_accuracy: 0.6302\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.5764 - val_loss: 0.6864 - val_accuracy: 0.6406\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5938 - val_loss: 0.6822 - val_accuracy: 0.6354\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.5972 - val_loss: 0.6782 - val_accuracy: 0.6458\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6094 - val_loss: 0.6744 - val_accuracy: 0.6615\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.6146 - val_loss: 0.6707 - val_accuracy: 0.6562\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.6198 - val_loss: 0.6672 - val_accuracy: 0.6406\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6267 - val_loss: 0.6638 - val_accuracy: 0.6458\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6302 - val_loss: 0.6606 - val_accuracy: 0.6510\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6302 - val_loss: 0.6575 - val_accuracy: 0.6510\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6354 - val_loss: 0.6544 - val_accuracy: 0.6510\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6441 - val_loss: 0.6515 - val_accuracy: 0.6458\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6562\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6528 - val_loss: 0.6459 - val_accuracy: 0.6615\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6562 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6597 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6615 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6615 - val_loss: 0.6358 - val_accuracy: 0.6667\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6649 - val_loss: 0.6335 - val_accuracy: 0.6667\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6649 - val_loss: 0.6312 - val_accuracy: 0.6615\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6701 - val_loss: 0.6290 - val_accuracy: 0.6562\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6719 - val_loss: 0.6269 - val_accuracy: 0.6562\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6701 - val_loss: 0.6248 - val_accuracy: 0.6510\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6701 - val_loss: 0.6228 - val_accuracy: 0.6510\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6736 - val_loss: 0.6208 - val_accuracy: 0.6510\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6753 - val_loss: 0.6189 - val_accuracy: 0.6510\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6788 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6806 - val_loss: 0.6153 - val_accuracy: 0.6458\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6823 - val_loss: 0.6135 - val_accuracy: 0.6458\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6840 - val_loss: 0.6117 - val_accuracy: 0.6510\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6840 - val_loss: 0.6100 - val_accuracy: 0.6510\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6840 - val_loss: 0.6083 - val_accuracy: 0.6510\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6858 - val_loss: 0.6067 - val_accuracy: 0.6510\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6858 - val_loss: 0.6050 - val_accuracy: 0.6510\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6858 - val_loss: 0.6035 - val_accuracy: 0.6562\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6858 - val_loss: 0.6019 - val_accuracy: 0.6615\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6875 - val_loss: 0.6004 - val_accuracy: 0.6615\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6875 - val_loss: 0.5989 - val_accuracy: 0.6615\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6910 - val_loss: 0.5974 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6927 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6944 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6615\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6944 - val_loss: 0.5917 - val_accuracy: 0.6615\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6944 - val_loss: 0.5903 - val_accuracy: 0.6615\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6979 - val_loss: 0.5889 - val_accuracy: 0.6771\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7014 - val_loss: 0.5875 - val_accuracy: 0.6771\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7066 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7049 - val_loss: 0.5848 - val_accuracy: 0.6823\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.6823\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7083 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7101 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7101 - val_loss: 0.5797 - val_accuracy: 0.6875\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7083 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7083 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7118 - val_loss: 0.5760 - val_accuracy: 0.6927\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7118 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7101 - val_loss: 0.5737 - val_accuracy: 0.6979\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7118 - val_loss: 0.5725 - val_accuracy: 0.6979\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7118 - val_loss: 0.5714 - val_accuracy: 0.6927\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7135 - val_loss: 0.5703 - val_accuracy: 0.6927\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7135 - val_loss: 0.5692 - val_accuracy: 0.6979\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.6979\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7135 - val_loss: 0.5671 - val_accuracy: 0.6979\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7153 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7170 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7170 - val_loss: 0.5640 - val_accuracy: 0.6979\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7188 - val_loss: 0.5629 - val_accuracy: 0.6979\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7205 - val_loss: 0.5619 - val_accuracy: 0.6979\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7205 - val_loss: 0.5609 - val_accuracy: 0.6979\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7205 - val_loss: 0.5599 - val_accuracy: 0.6979\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7205 - val_loss: 0.5589 - val_accuracy: 0.6979\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7257 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7274 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7309 - val_loss: 0.5560 - val_accuracy: 0.7031\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7326 - val_loss: 0.5550 - val_accuracy: 0.7031\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7326 - val_loss: 0.5541 - val_accuracy: 0.7031\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7344 - val_loss: 0.5531 - val_accuracy: 0.6979\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7344 - val_loss: 0.5522 - val_accuracy: 0.6979\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7361 - val_loss: 0.5513 - val_accuracy: 0.6927\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7361 - val_loss: 0.5504 - val_accuracy: 0.6927\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7378 - val_loss: 0.5495 - val_accuracy: 0.6927\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7378 - val_loss: 0.5487 - val_accuracy: 0.6927\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7396 - val_loss: 0.5478 - val_accuracy: 0.6927\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7396 - val_loss: 0.5470 - val_accuracy: 0.6979\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7396 - val_loss: 0.5461 - val_accuracy: 0.6979\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7413 - val_loss: 0.5453 - val_accuracy: 0.6979\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7431 - val_loss: 0.5445 - val_accuracy: 0.6927\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7431 - val_loss: 0.5437 - val_accuracy: 0.6927\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7431 - val_loss: 0.5429 - val_accuracy: 0.6875\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7448 - val_loss: 0.5422 - val_accuracy: 0.6927\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7483 - val_loss: 0.5414 - val_accuracy: 0.6927\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7500 - val_loss: 0.5406 - val_accuracy: 0.6979\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7517 - val_loss: 0.5399 - val_accuracy: 0.6979\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7517 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7500 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7500 - val_loss: 0.5378 - val_accuracy: 0.7031\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7517 - val_loss: 0.5371 - val_accuracy: 0.7031\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7517 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7517 - val_loss: 0.5357 - val_accuracy: 0.7031\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7552 - val_loss: 0.5350 - val_accuracy: 0.7031\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7031\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7031\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7569 - val_loss: 0.5331 - val_accuracy: 0.7031\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7587 - val_loss: 0.5324 - val_accuracy: 0.7031\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7031\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7587 - val_loss: 0.5311 - val_accuracy: 0.7031\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7604 - val_loss: 0.5305 - val_accuracy: 0.7031\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7031\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7639 - val_loss: 0.5287 - val_accuracy: 0.7031\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7639 - val_loss: 0.5281 - val_accuracy: 0.7031\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7031\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7031\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7031\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7031\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7135\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7656 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7656 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7674 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7691 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7639 - val_loss: 0.5218 - val_accuracy: 0.7135\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7639 - val_loss: 0.5213 - val_accuracy: 0.7135\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7639 - val_loss: 0.5208 - val_accuracy: 0.7135\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7135\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7639 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5182 - val_accuracy: 0.7240\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7622 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7622 - val_loss: 0.5167 - val_accuracy: 0.7240\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5163 - val_accuracy: 0.7292\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7622 - val_loss: 0.5160 - val_accuracy: 0.7292\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7639 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7674 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5109 - val_accuracy: 0.7292\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7292\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7674 - val_loss: 0.5104 - val_accuracy: 0.7292\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7292\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5099 - val_accuracy: 0.7292\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7292\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7292\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5089 - val_accuracy: 0.7292\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5087 - val_accuracy: 0.7292\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.7292\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.5082 - val_accuracy: 0.7292\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5080 - val_accuracy: 0.7292\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5077 - val_accuracy: 0.7292\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7708 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7708 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7708 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7344\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7344\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7292\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7292\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7292\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7292\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7292\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7292\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7292\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7292\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7292\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7292\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7292\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7292\n"
          ]
        }
      ],
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, batch_size=32)\n",
        "# the fit function returns the run history.\n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJMeGW7MUAIK",
        "outputId": "3abc2ac4-e507-4e29-8acd-51800343eed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 1000us/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsYmQ73OUAIK",
        "outputId": "c9ce1178-7302-4b47-d793-f8a06df1bc28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhKNo_5BUAIK",
        "outputId": "36cf27f4-6ac6-48d5-8000-e7a5e72f74f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.58112663],\n",
              "       [0.32257375],\n",
              "       [0.6120373 ],\n",
              "       [0.13304552],\n",
              "       [0.49373564],\n",
              "       [0.709026  ],\n",
              "       [0.5599951 ],\n",
              "       [0.15182672],\n",
              "       [0.17918733],\n",
              "       [0.9180581 ]], dtype=float32)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "n_vOd-upUAIK",
        "outputId": "c8703ca4-3c9e-42ce-e66c-f2e98414233d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.729\n",
            "roc-auc is 0.815\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SLVuVLnUAIK"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXfBqaFsUAIL"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbW5F77kUAIL",
        "outputId": "cbd7c9ea-7df7-44e2-8a3c-214fa1da4905"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11UgwSDSUAIL"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "CstB8zXcUAIL",
        "outputId": "318a214b-7792-4563-c543-1c40bbfccf36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x17ba4c64610>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKm0lEQVR4nO3de1xU1fo/8M/MKCDKRUW5CKKWmBqiohJaaUqhdUzrHEV/ltrBLA+W5SX1W166HDE17WZZZmLfc455OVp9zTQjNC8opHHUNEIFgRPgpQDBFJ1Zvz+mGRmYy97D3Ofzfr32i5k9e+9Z21Hmca1nPUshhBAgIiIicmFKZzeAiIiIyBIGLEREROTyGLAQERGRy2PAQkRERC6PAQsRERG5PAYsRERE5PIYsBAREZHLY8BCRERELq+ZsxtgCxqNBr/88gsCAgKgUCic3RwiIiKSQAiBK1euICIiAkql+T4UjwhYfvnlF0RFRTm7GURERGSFkpISREZGmj3GIwKWgIAAANobDgwMdHJriIiISIrq6mpERUXpv8fN8YiARTcMFBgYyICFiIjIzUhJ52DSLREREbk8BixERETk8hiwEBERkcvziBwWIiJqGiEEbt68CbVa7eymkIdRqVRo1qxZk8uOMGAhIvJydXV1KCsrw9WrV53dFPJQ/v7+CA8Ph4+Pj9XXYMBCROTFNBoNCgsLoVKpEBERAR8fHxbgJJsRQqCurg4XL15EYWEhunbtarFAnCkMWIiIvFhdXR00Gg2ioqLg7+/v7OaQB2rRogWaN2+O8+fPo66uDn5+flZdh0m3RERk9f96iaSwxd8v/g0lIiIil8eAhYiIiFweAxZLSkuBrCztTyIi8lidOnXCm2++6exmkAkMWMxZtw6IjgaGDtX+XLfO2S0iIvJ6CoXC7LZ48WKrrpubm4upU6c2qW1DhgzBc88916RrkHGcJWRKaSkwdSqg0WifazTAU08BycmAhSWwiYi8UmkpUFAAdO1q19+TZWVl+sebNm3CwoULkZ+fr9/XqlUr/WMhBNRqNZo1s/x1165dO9s2lGyKPSymFBTcClZ01GrgzBnntIeIyFGEAGpr5W3vvWfYI/3ee/KvIYSk5oWFhem3oKAgKBQK/fOffvoJAQEB+OqrrxAfHw9fX18cOHAAZ8+exahRoxAaGopWrVqhf//++Oabbwyu23BISKFQ4KOPPsIjjzwCf39/dO3aFV988UWT/mj//e9/o2fPnvD19UWnTp3wxhtvGLz+3nvvoWvXrvDz80NoaCj+8pe/6F/bunUrYmNj0aJFC7Rt2xZJSUmora1tUnvcCXtYTOnaFVAqDYMWlQq4/XbntYmIyBGuXgXq9VLIptEAaWnaTY6aGqBlS+vft5558+ZhxYoV6NKlC1q3bo2SkhI8+OCD+Pvf/w5fX1988sknGDlyJPLz89GxY0eT13n55ZexbNkyLF++HO+88w4mTJiA8+fPo02bNrLbdPToUYwdOxaLFy9GSkoKDh06hL/97W9o27YtJk+ejO+//x7PPvss/vd//xcDBw7Er7/+iv379wPQ9iqNHz8ey5YtwyOPPIIrV65g//79EBKDPE/AgMWUyEjgww+BJ5/URv0KBfDBBxwOIiJyA6+88gruv/9+/fM2bdogLi5O//zVV1/F9u3b8cUXX2D69OkmrzN58mSMHz8eALBkyRK8/fbbyMnJwfDhw2W3aeXKlRg2bBgWLFgAAIiJicGpU6ewfPlyTJ48GcXFxWjZsiX+9Kc/ISAgANHR0ejTpw8AbcBy8+ZNPProo4iOjgYAxMbGym6DO+OQkDmpqcAnn2gfR0QAf/2rc9tDROQI/v7a3g6pW36+tke6PpVKu1/OdWxYabdfv34Gz2tqajB79mx0794dwcHBaNWqFU6fPo3i4mKz1+nVq5f+ccuWLREYGIgLFy5Y1abTp09j0KBBBvsGDRqEgoICqNVq3H///YiOjkaXLl3w+OOP45///Kd+fae4uDgMGzYMsbGxGDNmDNauXYvffvvNqna4KwYsljzyCNCsGfDf/wKFhc5uDRGR/SkU2qEZqVtMjLZHWqXSnq9SaXukY2LkXceGaxi1bDC0NHv2bGzfvh1LlizB/v37kZeXh9jYWNTV1Zm9TvPmzRv80SigaZjfaCMBAQE4duwYNm7ciPDwcCxcuBBxcXGorKyESqXCnj178NVXX6FHjx5455130K1bNxR60fcSAxZLWrYE7rpL+/jbb53bFiIiV5WaChQVaetWFRVpn7uQgwcPYvLkyXjkkUcQGxuLsLAwFBUVObQN3bt3x8GDBxu1KyYmBqo/gr1mzZohKSkJy5Ytw/Hjx1FUVIRv//juUSgUGDRoEF5++WX88MMP8PHxwfbt2x16D87EHBYphg4FDhwANm4Ehg9nHgsRkTGRkS77+7Fr167Ytm0bRo4cCYVCgQULFtitp+TixYvIy8sz2BceHo5Zs2ahf//+ePXVV5GSkoLs7Gy8++67eO+99wAAO3bswLlz53DvvfeidevW2LlzJzQaDbp164YjR44gMzMTDzzwANq3b48jR47g4sWL6N69u13uwRWxh0WK33/X/vz2WxaQIyJyQytXrkTr1q0xcOBAjBw5EsnJyejbt69d3utf//oX+vTpY7CtXbsWffv2xebNm/Hpp5/izjvvxMKFC/HKK69g8uTJAIDg4GBs27YNQ4cORffu3bFmzRps3LgRPXv2RGBgIL777js8+OCDiImJwUsvvYQ33ngDI0aMsMs9uCKF8IA5UdXV1QgKCkJVVRUCAwNte/HSUm2Q0nB6c1GRy/5PgohIqmvXrqGwsBCdO3eGn5+fs5tDHsrU3zM539/sYbGEBeSIiIicjgGLJboCcvWxgBwREZFDMWCxRFdArn7Q8u67HA4iIiJyIAYsUuim6+lKMXft6tTmEBEReRsGLFJFRQEjR2of797t3LYQERF5GQYscjzwgPbnjh3a4kilpc5tDxERkZewKmBZvXo1OnXqBD8/PyQkJCAnJ8fksUOGDIFCoWi0PfTQQ/pjJk+e3Oh1axaWsjvdQlqnT99aQp01WYiIiOxOdsCyadMmzJw5E4sWLcKxY8cQFxeH5ORkk4tBbdu2DWVlZfrt5MmTUKlUGDNmjMFxw4cPNzhu48aN1t2RPV2/bvhcowGeeoo9LURERHYmO2BZuXIlnnzySTzxxBPo0aMH1qxZA39/f3z88cdGj2/Tpg3CwsL02549e+Dv798oYPH19TU4rnXr1tbdkT0VFDTex5osRERuaciQIXjuuef0zzt16oQ333zT7DkKhQKfffZZk9/bVtfxJrIClrq6Ohw9ehRJSUm3LqBUIikpCdnZ2ZKusW7dOowbN67RSpp79+5F+/bt0a1bN0ybNg2XL1+W0zTHYE0WIiKnGzlypMm0gf3790OhUOD48eOyr5ubm4upU6c2tXkGFi9ejN69ezfaX1ZWZvey+hkZGQgODrbreziSrIDl0qVLUKvVCA0NNdgfGhqK8vJyi+fn5OTg5MmTmDJlisH+4cOH45NPPkFmZiZef/117Nu3DyNGjIBarTZ6nevXr6O6utpgc4jISOD99289Vyq1S6izJgsRkcOkpqZiz549KDUyHL9+/Xr069cPvXr1kn3ddu3awd/f3xZNtCgsLAy+vr4OeS9P4dBZQuvWrUNsbCwGDBhgsH/cuHF4+OGHERsbi9GjR2PHjh3Izc3F3r17jV4nPT0dQUFB+i0qKsoBrf/D1KnAww9rH0+b5nJLqBMROUtpqWMmUP7pT39Cu3btkJGRYbC/pqYGW7ZsQWpqKi5fvozx48ejQ4cO8Pf3R2xsrMXcyIZDQgUFBbj33nvh5+eHHj16YM+ePY3OmTt3LmJiYuDv748uXbpgwYIFuHHjBgBtD8fLL7+M//znP/oJJbo2NxwSOnHiBIYOHYoWLVqgbdu2mDp1KmpqavSvT548GaNHj8aKFSsQHh6Otm3bIi0tTf9e1iguLsaoUaPQqlUrBAYGYuzYsaioqNC//p///Af33XcfAgICEBgYiPj4eHz//fcAgPPnz2PkyJFo3bo1WrZsiZ49e2Lnzp1Wt0UKWQFLSEgIVCqVwQ0BQEVFBcLCwsyeW1tbi08//RSpEr7gu3TpgpCQEJwxkRsyf/58VFVV6beSkhLpN2ELuvybAwcc+75ERA4gBFBbK2977z3txEndBMr33pN/DalL8TZr1gwTJ05ERkYG6q/fu2XLFqjVaowfPx7Xrl1DfHw8vvzyS5w8eRJTp07F448/bnZWa30ajQaPPvoofHx8cOTIEaxZswZz585tdFxAQAAyMjJw6tQpvPXWW1i7di1WrVoFAEhJScGsWbPQs2dP/YSSlJSURteora1FcnIyWrdujdzcXGzZsgXffPMNpk+fbnBcVlYWzp49i6ysLGzYsAEZGRmNgjapNBoNRo0ahV9//RX79u3Dnj17cO7cOYP2TZgwAZGRkcjNzcXRo0cxb948NG/eHACQlpaG69ev47vvvsOJEyfw+uuvo1WrVla1RTIh04ABA8T06dP1z9VqtejQoYNIT083e9769euFr6+vuHTpksX3KCkpEQqFQnz++eeS2lRVVSUAiKqqKknHN9nFi0IoFEIAQmzaJERJiWPel4jIxn7//Xdx6tQp8fvvv+v31dRof705equpkd7u06dPCwAiKytLv++ee+4Rjz32mMlzHnroITFr1iz988GDB4sZM2bon0dHR4tVq1YJIYTYvXu3aNasmfjvf/+rf/2rr74SAMT27dtNvsfy5ctFfHy8/vmiRYtEXFxco+PqX+fDDz8UrVu3FjX1/gC+/PJLoVQqRXl5uRBCiEmTJono6Ghx8+ZN/TFjxowRKSkpJtuyfv16ERQUZPS1r7/+WqhUKlFcXKzf9+OPPwoAIicnRwghREBAgMjIyDB6fmxsrFi8eLHJ927I2N8zIeR9f8seEpo5cybWrl2LDRs24PTp05g2bRpqa2vxxBNPAAAmTpyI+fPnNzpv3bp1GD16NNq2bWuwv6amBnPmzMHhw4dRVFSEzMxMjBo1CrfffjuSk5NlB2C2ZrSLMyQE6NxZ+zglhfVYiIgc7I477sDAgQP1M1TPnDmD/fv363vx1Wo1Xn31VcTGxqJNmzZo1aoVdu/ejeLiYknXP336NKKiohAREaHfl5iY2Oi4TZs2YdCgQQgLC0OrVq3w0ksvSX6P+u8VFxdnMBll0KBB0Gg0yM/P1+/r2bMnVCqV/nl4eLjJkiJS3jMqKsogpaJHjx4IDg7G6dOnAWi/76dMmYKkpCQsXboUZ8+e1R/77LPP4rXXXsOgQYOwaNEiq5Kc5ZIdsKSkpGDFihVYuHAhevfujby8POzatUufiFtcXIyysjKDc/Lz83HgwAGjw0EqlQrHjx/Hww8/jJiYGKSmpiI+Ph779+93ekLS6tVAx45GasSVlgKFhbcOZD0WIvIg/v5ATY30LT/f+ATK/Hx515Gb75qamop///vfuHLlCtavX4/bbrsNgwcPBgAsX74cb731FubOnYusrCzk5eUhOTkZdXV1NvpTArKzszFhwgQ8+OCD2LFjB3744Qe8+OKLNn2P+nTDMToKhQIajcYu7wVoZzj9+OOPeOihh/Dtt9+iR48e2L59OwBgypQpOHfuHB5//HGcOHEC/fr1wzvvvGO3tgBAM2tOmj59eqOxNR1jibLdunUzGGesr0WLFtjtgmvzlJYCzz57a0xVF5MkJwORBQWNB1t19Vg4Y4iI3JxCATSoPGFWTIx2UfunntL+KlSptBMoY2Ls10YAGDt2LGbMmIF//etf+OSTTzBt2jQoFAoAwMGDBzFq1Cg89thjALQ5Gz///DN69Ogh6drdu3dHSUkJysrKEB4eDgA4fPiwwTGHDh1CdHQ0XnzxRf2+8+fPGxzj4+NjcsZr/ffKyMhAbW2tvpfl4MGDUCqV6Natm6T2yqW7v5KSEn0vy6lTp1BZWWnwZxQTE4OYmBg8//zzGD9+PNavX49HHnkEABAVFYWnn34aTz/9NObPn4+1a9fimWeesUt7Aa4lZFJBgTZIqU9fI471WIiIDOgWtc/K0v50xATKVq1aISUlBfPnz0dZWRkmT56sf61r167Ys2cPDh06hNOnT+Opp55qNGHEnKSkJMTExGDSpEn4z3/+g/379xsEJrr3KC4uxqeffoqzZ8/i7bff1vdA6HTq1AmFhYXIy8vDpUuXcL1hxXRok1v9/PwwadIknDx5EllZWXjmmWfw+OOPNyojIpdarUZeXp7Bdvr0aSQlJSE2NhYTJkzAsWPHkJOTg4kTJ2Lw4MHo168ffv/9d0yfPh179+7F+fPncfDgQeTm5qJ79+4AgOeeew67d+9GYWEhjh07hqysLP1r9sKAxQSzMUlkpPa/E39E8lAoWI+FiLxeZCQwZIhjfxWmpqbit99+Q3JyskG+yUsvvYS+ffsiOTkZQ4YMQVhYGEaPHi35ukqlEtu3b8fvv/+OAQMGYMqUKfj73/9ucMzDDz+M559/HtOnT0fv3r1x6NAhLFiwwOCYP//5zxg+fDjuu+8+tGvXzujUan9/f+zevRu//vor+vfvj7/85S8YNmwY3n33XXl/GEbU1NSgT58+BtvIkSOhUCjw+eefo3Xr1rj33nuRlJSELl26YNOmTQC06RqXL1/GxIkTERMTg7Fjx2LEiBF4+eWXAWgDobS0NHTv3h3Dhw9HTEwM3nvvvSa31xyFMDVW40aqq6sRFBSEqqoqBAYG2uy669Zpy67oelo++qjB/xq2bwcefRQICAAuXQJ8fGz23kREjnDt2jUUFhaic+fO8PPzc3ZzyEOZ+nsm5/ubPSxmpKYCeXm3no8c2eCAUaOAsDDgyhXgzTeZdEtERGQnDFgsiI0F4uK0jxvlEyuVgC4hau5cTm8mIiKyEwYsEgwZov2ZldXghdJSYP/+W885vZmIiMguGLBIcN992p9fftkgFjE7lYiIiIhshQGLBLpp9SUlDUZ9OL2ZiIjIIRiwWFBaCjz//K3nBqM+uunN9YOWNWs4vZmI3I4HTBglF2aLv18MWCywOOqTmgr89BOgW0agTx+Hto+IqCl05d6vXr3q5JaQJ9P9/Wq4vIAcVpXm9ya6UZ/6QUujUZ+uXbVznrduBVauBF5/nb0sROQWVCoVgoOD9Yvo+fv768vbEzWVEAJXr17FhQsXEBwcbLB4o1wMWCzQjfro1sgAgMWLjcQjrVtrf/7rX8Cnn2pPckRtaiKiJgoLCwMAq1f+JbIkODhY//fMWqx0K1FpqbZO3LFjwNtvAwbrO5WWarNxG3bDFBWxp4WI3IZarcaNGzec3QzyMM2bNzfZsyLn+5s9LBJFRgJjx2oDlj17GgQs5hJdGLAQkZtQqVRN6rInsicm3cpw//3an99+qw1a9DVZOL2ZiIjIrhiwyNC7N9CyJVBbCzzwQL2aLLpEl/r/M3nhBfauEBER2QgDFhl++UUbrOgY1GRJTdXmrCQlaV+sqnJGE4mIiDwSAxYZCgoa7zOoyRIZCcyZo338r38BX3/NdYWIiIhsgAGLDJJSVYYOBQIDgcpKIDmZKzgTERHZAAMWGXSpKjpKJfDBBw1SVcrLgStXbj3nCs5ERERNxoBFptRUYNo07eNRo4zUhisoABqWtuEKzkRERE3CgMUKKSnanwcONC6/winOREREtseAxQoDB2rTVC5e1A4JGYz26MaN6q/F0WjciIiIiORgwGKF5s1vdZj87W9G8mpTU4Hs7FvPW7ZkDgsREVETMGCxQmkp8MMPt54bzatNSAC6ddM+Hj+es4WIiIiagAGLFSTl1ZaWAj//fOs5ZwsRERFZjQGLFSTl1XK2EBERkc0wYLFCw7xahcJIXi1nCxEREdkMAxYrpaYCu3ZpH/v6atNUDOiimvpBy1tvcbYQERGRFRiwNMH992tzaa9dA1atMpKeolsQURekFBYyh4WIiMgKDFiaQKEAbrtN+/ill0xMBIqKAu66S/v4jTc4W4iIiMgKCiEaZoa6n+rqagQFBaGqqgqBgYEOe9/SUm38Ub/arUpl2Kki7SAiIiLvI+f7mz0sTVBQ0Lg0f6OJQJIOIiIiInMYsDSBpIlAnC1ERETUZAxYmsDYRKD3328w0qM7SKW6te/uux3WRiIiIk/AgKWJUlO1oz4tW2qfx8SYOKioCEhO1j7ft4/Jt0RERDIwYLGBLl2AsWO1j41Ob9bZs+fWY5bqJyIikowBi40EBWl/fv65ic4TJt8SERFZjQGLDZSWAm+/feu50c4TY8m3SiWTb4mIiCRgwGIDkjpPjCXfJiZqT+awEBERkVkMWGxA8sxlXfLtsmXa5wcPAkOHMgGXiIjIAgYsNmCs82TGDBOFbCMjgZQUw31MwCUiIjKLAYuN6DpPHnpI+/zKFTMHnz3beB8TcImIiExiwGJDkZHA889rH2/Zop3FbLTThNVviYiIZGHAYmODBwOtWgGVlcADD5hIT9GNISkUt/Y995wDW0lEROReGLDYWHk5UFt767nJ9JTUVODYsVuJL2+8weRbIiIiExiw2FhBASCE4T6T6SkhIYbzoZl8S0REZBQDFhuTlZ4iK7ohIiLyXlYFLKtXr0anTp3g5+eHhIQE5OTkmDx2yJAhUCgUjbaHdNNpAAghsHDhQoSHh6NFixZISkpCQUGBNU1zOmPpKR98YGKKM5NviYiIJJEdsGzatAkzZ87EokWLcOzYMcTFxSE5ORkXLlwwevy2bdtQVlam306ePAmVSoUxY8boj1m2bBnefvttrFmzBkeOHEHLli2RnJyMa9euWX9nTpSaCmRlaR8rFEBwsIlRHl10Uz9oSU11RBOJiIjci5BpwIABIi0tTf9crVaLiIgIkZ6eLun8VatWiYCAAFFTUyOEEEKj0YiwsDCxfPly/TGVlZXC19dXbNy4UdI1q6qqBABRVVUl407sr1MnIbRjPkIolUJ89JGJA0tKhOjYUeLBREREnkHO97esHpa6ujocPXoUSUlJ+n1KpRJJSUnIzs6WdI1169Zh3LhxaNmyJQCgsLAQ5eXlBtcMCgpCQkKC5Gu6otJS4Pz5W88t5tPWf4HJt0RERAZkBSyXLl2CWq1GaGiowf7Q0FCUl5dbPD8nJwcnT57ElClT9Pt058m55vXr11FdXW2wuRpZ+bSSVk8kIiLyXg6dJbRu3TrExsZiwIABTbpOeno6goKC9FtUVJSNWmg7svJpmXxLRERklqyAJSQkBCqVChUVFQb7KyoqEBYWZvbc2tpafPrpp0htkFSqO0/ONefPn4+qqir9VlJSIuc2HMJYPu0775hZELHh6ol9+9q9jURERO5CVsDi4+OD+Ph4ZGZm6vdpNBpkZmYiMTHR7LlbtmzB9evX8dhjjxns79y5M8LCwgyuWV1djSNHjpi8pq+vLwIDAw02V5SaCpw7B7Rvr31eWmomLUW3euKjj2qf5+ay8i0REdEfZA8JzZw5E2vXrsWGDRtw+vRpTJs2DbW1tXjiiScAABMnTsT8+fMbnbdu3TqMHj0abdu2NdivUCjw3HPP4bXXXsMXX3yBEydOYOLEiYiIiMDo0aOtuysXEh0N3HWX9vGSJRJikM8+u/WYybdEREQAgGZyT0hJScHFixexcOFClJeXo3fv3ti1a5c+aba4uBjKBvkY+fn5OHDgAL7++muj13zhhRdQW1uLqVOnorKyEnfffTd27doFPz8/K27JtZSWAjt23Hqui0GSk40MD5lLvjU6lkREROQdFEI0nMvifqqrqxEUFISqqiqXGx7KygKGDjW+f8iQBjtLS7VdMA2Dlk2bgIEDGbQQEZFHkfP9zbWE7EzWBCBjybcAkJLCfBYiIvJqDFjszFgMYqzHRU+XfLtpk+F+5rMQEZEXY8DiALoY5L77tM/37LHQYRIZCbRr13g/i8kREZGXYsDiQPv23XpsscPE2FiSUgn8saQBERGRN2HA4iCyq+8bqzyn0WjnSDOXhYiIvAwDFgexqvp+aipw+LDhPuayEBGRF2LA4iDGkm+N1mJpqKam8T7mshARkZdhwOJAuuTbxYu1z7Ozgd27LXSWcGFEIiIiBiyOFhkJvPgi0Lo18NtvwPDhEmYMNeyauf9+h7SViIjIVTBgcYLycqCy8tZzi2kpuq6Ze+7RPt+1i4XkiIjIqzBgcYKCAqDhggiS0lIOHrz1mMm3RETkRRiwOIFVaSmm5kVv2cKghYiIPB4DFicwlpYybpyFk4xFOQAwcyaHh4iIyOMxYHESXVpKjx7a5//8pxXJtzocHiIiIg/HgMXJfvrp1mPJybcrVzZ+jbVZiIjIgzFgcSLZ5foBbU/LmDFcZ4iIiLwKAxYnsnp9Q64zREREXoYBixMZS0uRHHekpgIHDhjuYy4LERF5KAYsTpaaqi3Rr1Dc2ic57rh2rfE+5rIQEZEHYsDiAmpqrCwkZ/WYEhERkXthwOICrF7fsEljSkRERO6DAYsLMBZ39O0r8eQmjSkRERG5BwYsLkJXYuXRR7XPc3NlFLC1ekyJiIjIPTBgcTGffXbrseSOEmNjSgoFc1mIiMhjMGBxIVYVkgOMjykJwVwWIiLyGAxYXIip9Q0vXJDQy8JcFiIi8mAMWFyIqfUNU1Ik5rOYymXZsoVBCxERuTUGLC5Gl3y7ebPhfkmdJaa6aGbOlJHBS0RE5HoYsLigyEggJKTxfkkLIxrrogE4PERERG6NAYuLsrqIra6LZuXKxq+p1do8FyIiIjfDgMVFNWlB5shIYMwY48ND48ZxaIiIiNwOAxYXlpoKHD5suE/yyI6xiEfWBYiIiFwHAxYXV1PTeJ/kIrapqcDGjU24ABERkWtgwOLimrwg88CBXNGZiIjcHgMWF9fkBZm5ojMREXkAhRANK425n+rqagQFBaGqqgqBgYHObo5d5OYCCQmGdeFUKu2EoMhIR1yAiIjItuR8f7OHxU00eUFmUxfgNGciInIDDFjchKkFmSWtM2TqAgCnORMRkVtgwOImTC3ILHmdIU5zJiIiN8aAxY3oitiuX2+4X3LMYW6aMxdIJCIiF8aAxc1ERmp7VBqSnM9ibJozwAUSiYjIpTFgcUNNqs3CBRKJiMgNMWBxQ01aZwjgAolEROR2GLC4qSatMwRwgUQiInIrDFjcmKl1hiR3kHDmEBERuQkGLG7MJqVVzM0c4tAQERG5CAYsbsxmHSSmZg5xaIiIiFwEAxY3Z66DRHLZfg4NERGRi7MqYFm9ejU6deoEPz8/JCQkICcnx+zxlZWVSEtLQ3h4OHx9fRETE4OdO3fqX1+8eDEUCoXBdscdd1jTNK9krINEoZA4zVmHQ0NEROTCZAcsmzZtwsyZM7Fo0SIcO3YMcXFxSE5OxoULF4weX1dXh/vvvx9FRUXYunUr8vPzsXbtWnTo0MHguJ49e6KsrEy/HThwwLo78kKmyvZLnuasw6EhIiJyUQohGi7ha15CQgL69++Pd999FwCg0WgQFRWFZ555BvPmzWt0/Jo1a7B8+XL89NNPaN68udFrLl68GJ999hny8vLk3wHkLU/tyXJzgYQEw0WZVSptyZXISIkXWbcOmDpVOxxUn+wLERERmSfn+1tWD0tdXR2OHj2KpKSkWxdQKpGUlIRsE8MGX3zxBRITE5GWlobQ0FDceeedWLJkCdRqtcFxBQUFiIiIQJcuXTBhwgQUFxfLaRpBO825Yfgpe5kgrjdEREQuSFbAcunSJajVaoSGhhrsDw0NRXl5udFzzp07h61bt0KtVmPnzp1YsGAB3njjDbz22mv6YxISEpCRkYFdu3bh/fffR2FhIe655x5cuXLF6DWvX7+O6upqg41MT3OWvUwQ1xsiIiIXY/dZQhqNBu3bt8eHH36I+Ph4pKSk4MUXX8SaNWv0x4wYMQJjxoxBr169kJycjJ07d6KyshKbN282es309HQEBQXpt6ioKHvfhluw2TJBXG+IiIhcjKyAJSQkBCqVChUVFQb7KyoqEBYWZvSc8PBwxMTEQFXvy6979+4oLy9HXV2d0XOCg4MRExODMybm5c6fPx9VVVX6raSkRM5teDSbLRPE9YaIiMiFyApYfHx8EB8fj8zMTP0+jUaDzMxMJCYmGj1n0KBBOHPmDDT1kjh//vlnhIeHw8fHx+g5NTU1OHv2LMLDw42+7uvri8DAQIONbrHZMkFcb4iIiFyE7CGhmTNnYu3atdiwYQNOnz6NadOmoba2Fk888QQAYOLEiZg/f77++GnTpuHXX3/FjBkz8PPPP+PLL7/EkiVLkJaWpj9m9uzZ2LdvH4qKinDo0CE88sgjUKlUGD9+vA1u0TvZrBYci8oREZELaCb3hJSUFFy8eBELFy5EeXk5evfujV27dukTcYuLi6Gs9+UWFRWF3bt34/nnn0evXr3QoUMHzJgxA3PnztUfU1paivHjx+Py5cto164d7r77bhw+fBjt2rWzwS16r9RUICAASEkx3K8b0RkzxtEXIiIiso7sOiyuiHVYTCst1U7saVhWRanUdpykpjr6QkRERFp2q8NC7schQ0NTpwKbN3N4iIiI7IYBixewyQKJ5i6k0WiHi1ijhYiI7IQBi5ewyQKJpi6kw0RcIiKyEwYsXsJmCySaKyoHsEYLERHZBQMWL5Kaqo0lFIpb+6xKQdEVldu8mTVaiIjIIRiweBljCyRalYKiKypnLhE3N9cmbSYiImLA4mVMLZAIWJmCYi4RV/Z4ExERkXEMWLyMXVJQTCXiMgmXiIhshAGLF7J5CoqpGi0Ak3CJiMgmGLB4KUspKFYNDR0+zCRcIiKyCwYsXs5cUTnZHSP9+7MaLhER2QUDFjKZgmJVxwir4RIRkR0wYCHbrTekw2q4RERkYwxYCICNh4ZYDZeIiGyMAQvp2XxoiNVwiYjIRhiwkJ65oSGrcmZZDZeIiGyEAQsZsEvOLKvhEhFREzFgoUbskjPLarhERNQEDFioEbvkzLIaLhERNQEDFjLKLjmzrIZLRERWYsBCJtklZ5bVcImIyAoMWMgim+fMshouERHJxICFJLF5zqylzF5OeSYionoYsJAklnJmt2yxokaLucxeTnkmIqJ6FEII4exGNFV1dTWCgoJQVVWFwMBAZzfHo+XmauMIjabxa0qlNgZJTZVxwdJS7QyhceNMX/TwYW3uCxEReRQ539/sYSFZdDmzxjpGrBrJMZfZq7soe1qIiLweAxaSTTfleeXKxq81KRHX1JRnFpcjIvJ6DFjIKrqOEVPxhU2nPAMsLkdE5OUYsJDVzCXi2qWnhcXliIi8FgMWahJLIzksLkdERLbAgIWazNxIDovLERGRLTBgIZuwS84si8sREdEfGLCQzVjKmWVxOSIishYLx5HNsbgcERFJwcJx5FQsLkdERLbGgIXswinF5TiDiIjIYzFgIbtxeHE5ziAiIvJYDFjIrhxeXE53Yc4gIiLyKAxYyO7sWlyOM4iIiLwCAxZyCLsVlysq0uat2DQaIiIiV8OAhRzGLjmznEFEROQVGLCQQ9ktZ9Yu405EROQqGLCQw9ktZ9Yu405EROQKGLCQU9gtZ5a1WoiIPBIDFnIau+XMslYLEZHHYcBCTiUlZzYhAZgzR2anCGu1EBF5FAYs5BLMxRdCACtWWNEpImXcyapoiIiIHI0BC7kMcyM5gJUpKJbGnayOhoiIyJGsClhWr16NTp06wc/PDwkJCcjJyTF7fGVlJdLS0hAeHg5fX1/ExMRg586dTbomeSYpIzmyU1AsjTvpLswhIiIilyU7YNm0aRNmzpyJRYsW4dixY4iLi0NycjIuXLhg9Pi6ujrcf//9KCoqwtatW5Gfn4+1a9eiQ4cOVl+TPJulnhbAyvhCSjTEqc9ERK5JyDRgwACRlpamf65Wq0VERIRIT083evz7778vunTpIurq6mx2zYaqqqoEAFFVVSXxLsgdlJQIMXu2ECqVENqxm8abUinERx/JvPBHH2lPNHfRTZu0DSAiIruR8/0tq4elrq4OR48eRVJSkn6fUqlEUlISsrOzjZ7zxRdfIDExEWlpaQgNDcWdd96JJUuWQK1WW33N69evo7q62mAjzxMZCSxfboepz6mpwPnzwOzZnPpMROQmZAUsly5dglqtRmhoqMH+0NBQlJeXGz3n3Llz2Lp1K9RqNXbu3IkFCxbgjTfewGuvvWb1NdPT0xEUFKTfoqKi5NwGuRm7LBeki4Y49ZmIyC3YfZaQRqNB+/bt8eGHHyI+Ph4pKSl48cUXsWbNGquvOX/+fFRVVem3kpISG7aYXJVditjareQuERHZkqyAJSQkBCqVChUVFQb7KyoqEBYWZvSc8PBwxMTEQFXvC6F79+4oLy9HXV2dVdf09fVFYGCgwUbeQUoR244dZZZWsVvJXSIishVZAYuPjw/i4+ORmZmp36fRaJCZmYnExESj5wwaNAhnzpyBRqPR7/v5558RHh4OHx8fq65J3s3SZB+rSqvYZdyJiIhsRm5G76effip8fX1FRkaGOHXqlJg6daoIDg4W5eXlQgghHn/8cTFv3jz98cXFxSIgIEBMnz5d5Ofnix07doj27duL1157TfI1LeEsIe/00UfmZxDpJvzk5Mi8cE6O6VlEVl2QiIiMkfP9LTtgEUKId955R3Ts2FH4+PiIAQMGiMOHD+tfGzx4sJg0aZLB8YcOHRIJCQnC19dXdOnSRfz9738XN2/elHxNSxiweK+SEiE2b7Y8S9mmU58VCiGWLRPi22859ZmIqAnkfH8rhBDCuX08TVddXY2goCBUVVUxn8VLrVunTTOpN/JoQKnUDiP17y/jorm52mEgUxfVXfjDD7XjVEREJIuc72+uJUQeQUpplbvu0s5kzsqSmJBrt5K7REQkF3tYyOPYvGOEPS1ERHbBHhbyajbvGLFUq0X2BYmISC4GLOSRLE19BmTOVNbVasnK0o4rceozEZFDcUiIPNq6dcBTTwF/LF1llM0TcpVKYONGYOBAbX0XIiIyikNCRH+Q2jGSkCCzOq5dSu4SEZEp7GEhr2Ipf1Z27iwTcomIrMYeFiITLCXkyl5EkQm5REQOwYCFvI6lhFzZIzqWFk/UXZQJuUREVmPAQl5JytRnWYsoWlo8EWBPCxFREzBgIa9VvzquzUZ07FJyl4iImHRLBG3ckJ0NjBtnOn9WoQBmzQJmzJA4W5kJuUREZjHplkgmKSM6soaIAK5FRERkQwxYiOqxNKIDyJxJZPOSu0RE3okBC1EDkZHaFBObzSTi1GcioiZjwEJkgk1nEtmt5C4RkXdg0i2RBaWlwFtvAatW2XBNIpuX3CUicj9MuiWyId0QkdTacJJmLNu85C4RkWdjDwuRTOvWaWMJc7OVAYmdJFKmPsueT01E5B7Yw0JkR1JmEgES82htXnKXiMgzMWAhsoKUmUSAxDxau5TcJSLyLAxYiJpAyoxlSR0kchJlOJOIiLwQc1iIbKC0FDhzBvj+e2DuXPOTfyTNJJKSKMOZRETk5uR8fzNgIbIxS3m0CgXw+utAv35A165m8mh186lXrjQfAW3cCAwcyIRcInI7TLolciJLebRCAC+8AAwdaqFSrpySu0zIJSIPx4CFyA6kziTS5beYDVy4iCIREQMWInuROpMIkJCYK2UmERNyiciDMWAhsjMpM4l0zHaUSJlJxJotROShGLAQOYCUtQ91LJb4j4wExoyRVtqfQ0RE5CE4S4jICaRMANIxW5nfZlOSiIgcj7OEiFycbnSnyYm5cqYkcZiIiNwYAxYiJ7JJYq5NFzciInJNDFiIXECTE3NturgREZHrYcBC5CJskphrs8WNiIhcC5NuiVxUkxJz5SxuxNL+ROQkXEuIyIM0eUaRpZlEJk8kIrIvzhIi8iBNTsyVUtqfw0RE5OIYsBC5iSYl5kop7W/0RCIi18CAhciNyE3MTUiol5gLCaX9dScOGMCZRETkUpjDQuTGmpTfsm6dtjfF3IlKJbB0KSvlEpFdMOmWyMtYHbhAxolKpXZMKjXVdg0nIq/GgIXIS0mZEKRj0HlSm4fIUfHSgpbDh7UJNURETcRZQkReSm5irm6ZoY4P98acpB9QqoiyfBIr5RKREzBgIfIwchJzdYQAVnzdC9GK81iXvImVconI5XBIiMjDyclvAf4Y9fm8Av1bnZZWKZdDRERkJQ4JEZGervCclDIswB+zmkeGYs6XQ1A6brb5inWN5k5zmIiI7IM9LEReRuoyQ0C9xNwLO9H1jacRKUrMX5wl/olIBs4SIiJJ5E2HFpgVvxczjk6yHLhwCjQRSWD3IaHVq1ejU6dO8PPzQ0JCAnJyckwem5GRAYVCYbD5+fkZHDN58uRGxwwfPtyaphGRDPLWKVJgxff3oaM4jzlYjlJ0MH0wS/wTkY3JDlg2bdqEmTNnYtGiRTh27Bji4uKQnJyMCxcumDwnMDAQZWVl+u38+fONjhk+fLjBMRs3bpTbNCKykpT1EXUEFFiB2eiI85iD100HLpwCTUQ2JDtgWblyJZ588kk88cQT6NGjB9asWQN/f398/PHHJs9RKBQICwvTb6GhoY2O8fX1NTimdevWcptGRE0gdX1EHQEVVuAFRCuKsRxzkIUhjYOX+lOgmZhLRE0gK2Cpq6vD0aNHkZSUdOsCSiWSkpKQnZ1t8ryamhpER0cjKioKo0aNwo8//tjomL1796J9+/bo1q0bpk2bhsuXL5u83vXr11FdXW2wEVHTRdZbH1FqHReNUOIFvI6hyDLd62JQpa4je12ISDZZAculS5egVqsb9ZCEhoaivLzc6DndunXDxx9/jM8//xz/+Mc/oNFoMHDgQJTW+2U1fPhwfPLJJ8jMzMTrr7+Offv2YcSIEVCr1UavmZ6ejqCgIP0WFWWhOicRyRIZCQwZou1t0fW6mA9cFABu9bqYHS5i4TkisoKsWUK//PILOnTogEOHDiExMVG//4UXXsC+fftw5MgRi9e4ceMGunfvjvHjx+PVV181esy5c+dw22234ZtvvsGwYcMavX79+nVcv35d/7y6uhpRUVGcJURkR3IL0AGAAmrMwhuYgbcRif82PoCF54i8mt1mCYWEhEClUqGiosJgf0VFBcLCwiRdo3nz5ujTpw/OnDlj8pguXbogJCTE5DG+vr4IDAw02IjIvuQWoAPq5bngPJZjVuM8F41Gu1oj81uIyAJZAYuPjw/i4+ORmZmp36fRaJCZmWnQ42KOWq3GiRMnEB4ebvKY0tJSXL582ewxROQcVuW5QIUXsNx4ngvzW4hIAtmzhGbOnIm1a9diw4YNOH36NKZNm4ba2lo88cQTAICJEydi/vz5+uNfeeUVfP311zh37hyOHTuGxx57DOfPn8eUKVMAaBNy58yZg8OHD6OoqAiZmZkYNWoUbr/9diQnJ9voNonI1uyS58L8FiIyQXbAkpKSghUrVmDhwoXo3bs38vLysGvXLn0ibnFxMcrKyvTH//bbb3jyySfRvXt3PPjgg6iursahQ4fQo0cPAIBKpcLx48fx8MMPIyYmBqmpqYiPj8f+/fvh6+tro9skIntqOFwkrZ6LmeEiFp4jogZYmp+IbE6XoLtqFWBisl8DAoCicZIu1yYi8mhcS4iIXIKchRbraxS46Fdh7Ad07crghchDMGAhIpdjs2nR7HUh8hgMWIjIZckfLgKUUGMp5qIfjqIValCDVuiKM4icPY6BC5EbY8BCRC5P/nCRNs+lUb6L4l1Erl2kXQyJiNyK3QrHERHZirXTohtNjxaFmDPlN5TuyLNvg4nIqdjDQkQuw5o8Fx0l1Fj64HfoNywYXe8JQ2R/Fp4kcnUcEiIit2ZNnotWveGift9hxnt3MHAhcmEMWIjII9TPc5k3Txe86HJZLNMFLmMX9UBNy1DOiCZyMQxYiMjj6IKXli2BzZuBlW8IaIS0wEUX5CiVAkuXKljOhchFMGAhIo9XWgq8NeU4Vu3uATWaQXrPyx/DRgqBWbMUnBVN5EQMWIjIa5TmluHMwQp8/00l5n55NzRoJuv8+nXoAKCggL0vRI7CgIWIvFJpbhne+ttPWPn9PVYFLoB2wWgW0yVyDNZhISKvFNk/HMtz78P5nIuY3S8LKtz84xXR4GdjQmg33eMVK4COHYE5c7TDT0TkXOxhISKPVZpbhjMrPkPLLRmoFS3wPfphLpZy2IjIRXBIiIiovnrzo0tfeBtvielYiZkcNiJyMgYsRESm5OYCd92FUk043sKzWIWZUKMZFNBWqBNQybocAxci6zGHhYjIlP79gQ8/RKSyDMsxF0XohCwMQTGiUYxozMYyKPW5L5YZy3cpLQWyspj7QmRL7GEhIu9kpv5/KTrgLTzLYSMiO+OQEBGRVPXr/8+da7Dqoi5wsdWw0dixQE0NE3aJdBiwEBFZw8Ry0aXogDO4HbfjDABY3fuio1QCS5eCSwSQ12PAQkTUFCYCF4NDmjBsVB97X8ibMWAhIrIFM3ku+kOMDhspISSuKN1Q/d6XVq0YxJBnY8BCRGRLZvJc9IfYeNioPibvkqdiwEJEZC8Shov0hzbofZG+orRxrLhLnoYBCxGRvckMXM7gdrRELWrH/hXfdx2PuenBlk4zydjUaebAkDtiwEJE5CgS8lwaUSpROu9dvHXmQaza2hFqjfW9Lg2xF4bcCQMWIiJHk5DnYvQ0ROLM2P9By8cfRW2rUHz/PTBvnvTYxxT2wpA7YMBCRORMMoaL9Op1jZQiEmfOAC1bAps3y7uMzLcCwF4Ych4GLERErsCawMVIVbmGo071e0+agr0w5GwMWIiIXIk1eS5Ao/nMulGn22/XvmzNJaViPRhyBAYsRESuyMo8F3OFWHSX1A0f2boXxlgz2AtDtsKAhYjI1TUxzwWA0eQTZ/fCsDeG5GDAQkTkLqwZLjKWfGKmDK4je2HqN5GJvWQJAxYiIndj7XCRjoz6/Y7shTGX2MveGGLAQkTkzqwZLtKxcuGh+r0wtbWwWT0YKTi05L0YsBAReYKmBC5Gpkdb8/bGhpIcydjQEoMZz8GAhYjIkzS1EIuNpvc4sxcG0N5G/VtmMOP+GLAQEXkiY8knDhw2MtckXRDjyMTe+kwFM/VjNIBBjathwEJE5C2cPGxkrlmOSuyVwljgZC6oYTDjGAxYiIi8jbXVdHVs2OtiirHeGGcMLZkidUYTwKDGVhiwEBF5K1tOjwYc9s0sZWhJobDtIpDWsLT+EsBgRg4GLERE1LReF5nF6eyl4dCSqQJ4rh7MsIfGOAYsRER0i63mJzsxcDFGSjCjw6DGNTFgISIi09x02EiOhkNMUoMawP4zmiyRG9S486wnBixERCRNU6vqAk4fNrKWqaDG3CiaKwY19feZqktjrIKw7hhnBjoMWIiISJ6mFqfTsVGROmczNaPJXFDjKsEM0LgujbHXAef34jBgISIi69iqOJ2OHWu9OJs799BIYaytSiXw4YdAaqpt3oMBCxER2U5Tho3q85DeFyms6aHRcfWgRqUCiops89HJ+f5WWvMGq1evRqdOneDn54eEhATk5OSYPDYjIwMKhcJg8/PzMzhGCIGFCxciPDwcLVq0QFJSEgoKCqxpGhER2VpkJLB8OXD+PDB7tvYbC7g19UYqIYAVK4ABA4ChQ4GOHYE5c7Tf7h4mMhIYMgTo39/wZ2TkrT/OoiIgKwvIyTH8WVys3er/UTekUGh7O5xBrdYGY44mu4dl06ZNmDhxItasWYOEhAS8+eab2LJlC/Lz89G+fftGx2dkZGDGjBnIz8+/9aYKBUJDQ/XPX3/9daSnp2PDhg3o3LkzFixYgBMnTuDUqVONghtj2MNCRORA9hw2cucpL3ZgqafG2ro0TenFcVYPi+yAJSEhAf3798e7774LANBoNIiKisIzzzyDefPmNTo+IyMDzz33HCorK41eTwiBiIgIzJo1C7NnzwYAVFVVITQ0FBkZGRg3bpzFNjFgISJysqYuDdCQFw0f2YqpujT1Ax25Q1MNAx+VCvjgAzfIYamrq4O/vz+2bt2K0aNH6/dPmjQJlZWV+Pzzzxudk5GRgSlTpqBDhw7QaDTo27cvlixZgp49ewIAzp07h9tuuw0//PADevfurT9v8ODB6N27N956661G17x+/TquX79ucMNRUVEMWIiInK1hl4C1tV4a8uDkXWeT2ouj2+esWULN5Fz40qVLUKvVBsM5ABAaGoqffvrJ6DndunXDxx9/jF69eqGqqgorVqzAwIED8eOPPyIyMhLl5eX6azS8pu61htLT0/Hyyy/LaToRETmCLklDZ8gQYNy4pve+aDTACy9oH7P3xaYafmTGXncFdk/ZSUxMxMSJE9G7d28MHjwY27ZtQ7t27fDBBx9Yfc358+ejqqpKv5WUlNiwxUREZFPGskzNZZRa0jB5Nzpae/2sLCA3V/vTAxN5vZ2sHpaQkBCoVCpUVFQY7K+oqEBYWJikazRv3hx9+vTBmT9SjHXnVVRUIDw83OCa9YeI6vP19YWvr6+cphMRkbPV/698//7akqy6JQLmzbNN74uOG1beJfNk9bD4+PggPj4emZmZ+n0ajQaZmZlITEyUdA21Wo0TJ07og5POnTsjLCzM4JrV1dU4cuSI5GsSEZEb0s39nT3bdr0vOrpemPpTp0tL2fvixqya1jxp0iR88MEHGDBgAN58801s3rwZP/30E0JDQzFx4kR06NAB6enpAIBXXnkFd911F26//XZUVlZi+fLl+Oyzz3D06FH06NEDgHZa89KlSw2mNR8/fpzTmomIvJWtk3fN1aJnDozT2C3pFgBSUlJw8eJFLFy4EOXl5ejduzd27dqlT5otLi6Gsl41m99++w1PPvkkysvL0bp1a8THx+PQoUP6YAUAXnjhBdTW1mLq1KmorKzE3XffjV27dkkKVoiIyAPZOnm3/v/Ndb0vK1Zon7vB6tPE0vxERORujPW+NCUHRoe9MA7HtYSIiMi71A9iNm9u+rpHDTGJ1y4YsBARkXdrWHnXVisKchkBm2LAQkREBBhf98hWywfoMAfGagxYiIiITGk4fGTLXhiFgjkwMjBgISIikspZvTAcUmLAQkRE1CSmemFsQdcLU/+5l/bGMGAhIiKyJV0AY6sp1OZ4UWIvAxYiIiJ7sWcOjCke2gvDgIWIiMhRHJED05CxXhg37I1hwEJERORM5nphFArbFrVryI2GlBiwEBERuZKGvTD2Sug1xUWHlBiwEBERuQt7rY1kjosMKTFgISIicmf2nFZtiQNrxjBgISIi8iTO6IUxNutJqQQ+/BBITbXJWzBgISIi8nQNgxhHBTMqFVBUZJOeFjnf382a/G5ERETkeJGRxoOGIUOAcePsN6SkVmuv7eCkXQYsREREnqZ+MNO/vzYfxVZDSirVrdlODsSAhYiIyNM17I1p2AujG1KyVDNGpQI++MApU6KZw0JERES3mKoZU1ur3eekWULsYSEiIqJbGvbGuECBOQBQOrsBRERERJYwYCEiIiKXx4CFiIiIXB4DFiIiInJ5DFiIiIjI5TFgISIiIpfHgIWIiIhcHgMWIiIicnkMWIiIiMjlMWAhIiIil8eAhYiIiFyeR6wlpFu/sbq62sktISIiIql039tS1mH2iIDlypUrAICoqCgnt4SIiIjkunLlCoKCgsweoxBSwhoXp9Fo8MsvvyAgIAAKhcKm166urkZUVBRKSkosLn3trjz9Hj39/gDeoyfw9PsDeI+ewNb3J4TAlStXEBERAaXSfJaKR/SwKJVKRNp5+evAwECP/MtXn6ffo6ffH8B79ASefn8A79ET2PL+LPWs6DDploiIiFweAxYiIiJyeQxYLPD19cWiRYvg6+vr7KbYjaffo6ffH8B79ASefn8A79ETOPP+PCLploiIiDwbe1iIiIjI5TFgISIiIpfHgIWIiIhcHgMWIiIicnkMWCxYvXo1OnXqBD8/PyQkJCAnJ8fZTbJKeno6+vfvj4CAALRv3x6jR49Gfn6+wTFDhgyBQqEw2J5++mkntVi+xYsXN2r/HXfcoX/92rVrSEtLQ9u2bdGqVSv8+c9/RkVFhRNbLE+nTp0a3Z9CoUBaWhoA9/z8vvvuO4wcORIRERFQKBT47LPPDF4XQmDhwoUIDw9HixYtkJSUhIKCAoNjfv31V0yYMAGBgYEIDg5GamoqampqHHgX5pm7xxs3bmDu3LmIjY1Fy5YtERERgYkTJ+KXX34xuIaxz37p0qUOvhPjLH2GkydPbtT24cOHGxzjzp8hAKP/LhUKBZYvX64/xpU/QynfD1J+fxYXF+Ohhx6Cv78/2rdvjzlz5uDmzZs2aycDFjM2bdqEmTNnYtGiRTh27Bji4uKQnJyMCxcuOLtpsu3btw9paWk4fPgw9uzZgxs3buCBBx5AbW2twXFPPvkkysrK9NuyZcuc1GLr9OzZ06D9Bw4c0L/2/PPP4//+7/+wZcsW7Nu3D7/88gseffRRJ7ZWntzcXIN727NnDwBgzJgx+mPc7fOrra1FXFwcVq9ebfT1ZcuW4e2338aaNWtw5MgRtGzZEsnJybh27Zr+mAkTJuDHH3/Enj17sGPHDnz33XeYOnWqo27BInP3ePXqVRw7dgwLFizAsWPHsG3bNuTn5+Phhx9udOwrr7xi8Nk+88wzjmi+RZY+QwAYPny4Qds3btxo8Lo7f4YADO6trKwMH3/8MRQKBf785z8bHOeqn6GU7wdLvz/VajUeeugh1NXV4dChQ9iwYQMyMjKwcOFC2zVUkEkDBgwQaWlp+udqtVpERESI9PR0J7bKNi5cuCAAiH379un3DR48WMyYMcN5jWqiRYsWibi4OKOvVVZWiubNm4stW7bo950+fVoAENnZ2Q5qoW3NmDFD3HbbbUKj0Qgh3P/zAyC2b9+uf67RaERYWJhYvny5fl9lZaXw9fUVGzduFEIIcerUKQFA5Obm6o/56quvhEKhEP/9738d1napGt6jMTk5OQKAOH/+vH5fdHS0WLVqlX0bZwPG7m/SpEli1KhRJs/xxM9w1KhRYujQoQb73OUzFKLx94OU3587d+4USqVSlJeX6495//33RWBgoLh+/bpN2sUeFhPq6upw9OhRJCUl6fcplUokJSUhOzvbiS2zjaqqKgBAmzZtDPb/85//REhICO68807Mnz8fV69edUbzrFZQUICIiAh06dIFEyZMQHFxMQDg6NGjuHHjhsHneccdd6Bjx45u+XnW1dXhH//4B/76178aLPjp7p9ffYWFhSgvLzf4zIKCgpCQkKD/zLKzsxEcHIx+/frpj0lKSoJSqcSRI0cc3mZbqKqqgkKhQHBwsMH+pUuXom3btujTpw+WL19u0652e9u7dy/at2+Pbt26Ydq0abh8+bL+NU/7DCsqKvDll18iNTW10Wvu8hk2/H6Q8vszOzsbsbGxCA0N1R+TnJyM6upq/PjjjzZpl0csfmgPly5dglqtNvjDB4DQ0FD89NNPTmqVbWg0Gjz33HMYNGgQ7rzzTv3+//f//h+io6MRERGB48ePY+7cucjPz8e2bduc2FrpEhISkJGRgW7duqGsrAwvv/wy7rnnHpw8eRLl5eXw8fFp9CUQGhqK8vJy5zS4CT777DNUVlZi8uTJ+n3u/vk1pPtcjP0b1L1WXl6O9u3bG7zerFkztGnTxi0/12vXrmHu3LkYP368wcJyzz77LPr27Ys2bdrg0KFDmD9/PsrKyrBy5Uontlaa4cOH49FHH0Xnzp1x9uxZ/M///A9GjBiB7OxsqFQqj/sMN2zYgICAgEbDze7yGRr7fpDy+7O8vNzov1Xda7bAgMULpaWl4eTJkwb5HQAMxoxjY2MRHh6OYcOG4ezZs7jtttsc3UzZRowYoX/cq1cvJCQkIDo6Gps3b0aLFi2c2DLbW7duHUaMGIGIiAj9Pnf//LzdjRs3MHbsWAgh8P777xu8NnPmTP3jXr16wcfHB0899RTS09NdvgT8uHHj9I9jY2PRq1cv3Hbbbdi7dy+GDRvmxJbZx8cff4wJEybAz8/PYL+7fIamvh9cAYeETAgJCYFKpWqUBV1RUYGwsDAntarppk+fjh07diArKwuRkZFmj01ISAAAnDlzxhFNs7ng4GDExMTgzJkzCAsLQ11dHSorKw2OccfP8/z58/jmm28wZcoUs8e5++en+1zM/RsMCwtrlAR/8+ZN/Prrr271ueqClfPnz2PPnj0GvSvGJCQk4ObNmygqKnJMA22oS5cuCAkJ0f+99JTPEAD279+P/Px8i/82Adf8DE19P0j5/RkWFmb036ruNVtgwGKCj48P4uPjkZmZqd+n0WiQmZmJxMREJ7bMOkIITJ8+Hdu3b8e3336Lzp07WzwnLy8PABAeHm7n1tlHTU0Nzp49i/DwcMTHx6N58+YGn2d+fj6Ki4vd7vNcv3492rdvj4ceesjsce7++XXu3BlhYWEGn1l1dTWOHDmi/8wSExNRWVmJo0eP6o/59ttvodFo9AGbq9MFKwUFBfjmm2/Qtm1bi+fk5eVBqVQ2GkpxB6Wlpbh8+bL+76UnfIY669atQ3x8POLi4iwe60qfoaXvBym/PxMTE3HixAmD4FMXfPfo0cNmDSUTPv30U+Hr6ysyMjLEqVOnxNSpU0VwcLBBFrS7mDZtmggKChJ79+4VZWVl+u3q1atCCCHOnDkjXnnlFfH999+LwsJC8fnnn4suXbqIe++918ktl27WrFli7969orCwUBw8eFAkJSWJkJAQceHCBSGEEE8//bTo2LGj+Pbbb8X3338vEhMTRWJiopNbLY9arRYdO3YUc+fONdjvrp/flStXxA8//CB++OEHAUCsXLlS/PDDD/oZMkuXLhXBwcHi888/F8ePHxejRo0SnTt3Fr///rv+GsOHDxd9+vQRR44cEQcOHBBdu3YV48ePd9YtNWLuHuvq6sTDDz8sIiMjRV5ensG/Td3MikOHDolVq1aJvLw8cfbsWfGPf/xDtGvXTkycONHJd6Zl7v6uXLkiZs+eLbKzs0VhYaH45ptvRN++fUXXrl3FtWvX9Ndw589Qp6qqSvj7+4v333+/0fmu/hla+n4QwvLvz5s3b4o777xTPPDAAyIvL0/s2rVLtGvXTsyfP99m7WTAYsE777wjOnbsKHx8fMSAAQPE4cOHnd0kqwAwuq1fv14IIURxcbG49957RZs2bYSvr6+4/fbbxZw5c0RVVZVzGy5DSkqKCA8PFz4+PqJDhw4iJSVFnDlzRv/677//Lv72t7+J1q1bC39/f/HII4+IsrIyJ7ZYvt27dwsAIj8/32C/u35+WVlZRv9eTpo0SQihndq8YMECERoaKnx9fcWwYcMa3fvly5fF+PHjRatWrURgYKB44oknxJUrV5xwN8aZu8fCwkKT/zazsrKEEEIcPXpUJCQkiKCgIOHn5ye6d+8ulixZYvCF70zm7u/q1avigQceEO3atRPNmzcX0dHR4sknn2z0nz53/gx1PvjgA9GiRQtRWVnZ6HxX/wwtfT8IIe33Z1FRkRgxYoRo0aKFCAkJEbNmzRI3btywWTsVfzSWiIiIyGUxh4WIiIhcHgMWIiIicnkMWIiIiMjlMWAhIiIil8eAhYiIiFweAxYiIiJyeQxYiIiIyOUxYCEiIiKXx4CFiIiIXB4DFiIiInJ5DFiIiIjI5TFgISIiIpf3/wEEu/K7HY/vJwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG5HzDNFUAIL"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slHFioCFUAIL",
        "outputId": "d35db807-700a-4da5-ebdb-1b6e25a07624",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7292\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7240\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7240\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7240\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7812 - val_loss: 0.5029 - val_accuracy: 0.7240\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 0.5028 - val_accuracy: 0.7240\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7240\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7240\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7240\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7830 - val_loss: 0.5024 - val_accuracy: 0.7240\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7240\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7240\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7847 - val_loss: 0.5021 - val_accuracy: 0.7240\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7240\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7240\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7240\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7240\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7865 - val_loss: 0.5017 - val_accuracy: 0.7240\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7240\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7240\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7240\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7240\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7240\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7240\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7240\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7240\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7240\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7240\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7240\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7240\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7240\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7240\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7240\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7292\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7292\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7344\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7344\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7882 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7917 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7917 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7899 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7917 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7917 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7917 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7917 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7396\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7899 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7917 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7899 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7899 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7899 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7899 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7899 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7344\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7344\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7344\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n"
          ]
        }
      ],
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "jBy7i6XSUAIL",
        "outputId": "187a82ce-4a0a-4af5-8215-96517e36c911"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x17ba4c3d0c0>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history\n",
        " [\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x696YhRJUAIM"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720x50Nrg7oG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6K5p_8gw0i"
      },
      "source": [
        "**Student Answer:**\n",
        "\n",
        "---\n",
        "จากกราฟ n epoh ที่เหมาะสม คือ 200 เพราะมากกว่านี้  validation loss ก็ไม่ขยับลงแล้ว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CylpfYBYUAIM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp9yOAXQUAIM"
      },
      "source": [
        "# <span style=\"color:blue\">แบบฝึกปฏิบัติ</span>\n",
        "\n",
        "(รวม 100 คะแนน) ให้นิสิตใช้พื้นที่ต่อไปนี้ ในการเพิ่มโค้ดให้เป็นไปตามข้อกำหนดต่อไปนี้\n",
        "1. (50 คะแนน) เพิ่มเซลโค้ด เพื่อ\n",
        "   * สร้างโมเดลที่มีเลเยอร์ hidden 2 ชั้น แต่ละชั้นมี 6 โหนด\n",
        "   * ปรับโค้ดให้สามารถรับอินพุตที่มีจำนวน feature ตามข้อมูลเทรนที่จะถูกส่งเข้ามา (ปราศจากการใช้ค่าคงที่ 8 ที่ถูกระบุอยู่ในโค้ด ณ ตอนนี้)\n",
        "   * สำหรับเลเยอร์ hidden ให้ใช้ activation function เป็น \"relu\" และเลเยอร์ output เป็น \"sigmoid\"\n",
        "   * ใช้ learning rate เท่ากับ 0.003 และเทรนด้วยจำนวน 1500 epochs ส่วนสำหรับ Hyperparameter ที่เหลือให้ใช้ค่าคงเดิม\n",
        "   * วาดกราฟของค่า loss และ accuracy ด้วยทั้งชุดข้อมูล train และ test (ดังตัวอย่างในรูปนี้)\n",
        "  <img src=\"https://drive.google.com/uc?id=1GuN0KQf64rGMa4oCY2upnbOTMzWaXmbT\" style=\"height:360px\">\n",
        "2. (50 คะแนน) เพิ่มอีกเซลโค้ด เพื่อสร้างโมเดลที่มีการปรับโครงสร้างที่เหมาะสมขึ้น รวมถึงการปรับค่า Hyperparameter ต่าง ๆ เพื่อให้โมเดลใหม่ได้ผลลัพธ์ที่ดีขึ้น (โดยพิจารณาจากค่า accuracy) และในการเทรนโมเดลใหม่นี้ ห้ามมีการใช้ Early Stopping\n",
        "   * ให้วาดกราฟของค่า loss และ accuracy ของโมเดลใหม่นี้ด้วย\n",
        "   * อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itoIvUsoh1qX"
      },
      "source": [
        "ข้อ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kagzZns5jFmJ",
        "outputId": "daaa0e3b-d0a5-4300-cbfb-6f47f8de4ae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(576, 8)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "yGLKGsGIh1CF"
      },
      "outputs": [],
      "source": [
        "model_1n = Sequential([\n",
        "    Dense(6, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8gnOFsEjnUp",
        "outputId": "2e4a8021-360c-4bdb-879b-6cf0e2281533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103\n",
            "Trainable params: 103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1n.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "r9aHCvg0jwQQ"
      },
      "outputs": [],
      "source": [
        "# compile new_model_1\n",
        "model_1n.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDSACFWkOMu",
        "outputId": "46d8cae6-6773-4aa4-db7a-ac488c73c0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6562 - val_loss: 0.6374 - val_accuracy: 0.6927\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6580 - val_loss: 0.6355 - val_accuracy: 0.6771\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6632 - val_loss: 0.6337 - val_accuracy: 0.6771\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6615 - val_loss: 0.6320 - val_accuracy: 0.6771\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6615 - val_loss: 0.6303 - val_accuracy: 0.6615\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6632 - val_loss: 0.6287 - val_accuracy: 0.6562\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6597 - val_loss: 0.6271 - val_accuracy: 0.6615\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6597 - val_loss: 0.6257 - val_accuracy: 0.6667\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6580 - val_loss: 0.6242 - val_accuracy: 0.6615\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6545 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6528 - val_loss: 0.6215 - val_accuracy: 0.6667\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6562 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6562 - val_loss: 0.6189 - val_accuracy: 0.6615\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6545 - val_loss: 0.6177 - val_accuracy: 0.6510\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6562 - val_loss: 0.6166 - val_accuracy: 0.6458\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6562 - val_loss: 0.6154 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6615 - val_loss: 0.6143 - val_accuracy: 0.6458\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6580 - val_loss: 0.6132 - val_accuracy: 0.6406\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6562 - val_loss: 0.6122 - val_accuracy: 0.6406\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6545 - val_loss: 0.6112 - val_accuracy: 0.6406\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6545 - val_loss: 0.6102 - val_accuracy: 0.6406\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6545 - val_loss: 0.6092 - val_accuracy: 0.6354\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6562 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6545 - val_loss: 0.6074 - val_accuracy: 0.6458\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6615 - val_loss: 0.6065 - val_accuracy: 0.6510\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6615 - val_loss: 0.6057 - val_accuracy: 0.6510\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6615 - val_loss: 0.6048 - val_accuracy: 0.6458\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6632 - val_loss: 0.6040 - val_accuracy: 0.6510\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6632 - val_loss: 0.6032 - val_accuracy: 0.6510\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6649 - val_loss: 0.6024 - val_accuracy: 0.6562\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6649 - val_loss: 0.6016 - val_accuracy: 0.6562\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6649 - val_loss: 0.6008 - val_accuracy: 0.6562\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6649 - val_loss: 0.6001 - val_accuracy: 0.6562\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6667 - val_loss: 0.5994 - val_accuracy: 0.6562\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6684 - val_loss: 0.5986 - val_accuracy: 0.6562\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6684 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6684 - val_loss: 0.5972 - val_accuracy: 0.6562\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6684 - val_loss: 0.5965 - val_accuracy: 0.6562\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6701 - val_loss: 0.5958 - val_accuracy: 0.6562\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6701 - val_loss: 0.5951 - val_accuracy: 0.6562\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6701 - val_loss: 0.5945 - val_accuracy: 0.6562\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6736 - val_loss: 0.5938 - val_accuracy: 0.6562\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.6736 - val_loss: 0.5931 - val_accuracy: 0.6562\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6753 - val_loss: 0.5925 - val_accuracy: 0.6562\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6753 - val_loss: 0.5918 - val_accuracy: 0.6562\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6753 - val_loss: 0.5912 - val_accuracy: 0.6615\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6753 - val_loss: 0.5906 - val_accuracy: 0.6615\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6753 - val_loss: 0.5899 - val_accuracy: 0.6615\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6736 - val_loss: 0.5893 - val_accuracy: 0.6615\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6736 - val_loss: 0.5887 - val_accuracy: 0.6615\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6736 - val_loss: 0.5881 - val_accuracy: 0.6615\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6736 - val_loss: 0.5875 - val_accuracy: 0.6615\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6736 - val_loss: 0.5869 - val_accuracy: 0.6615\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6736 - val_loss: 0.5863 - val_accuracy: 0.6615\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.6736 - val_loss: 0.5857 - val_accuracy: 0.6615\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6736 - val_loss: 0.5852 - val_accuracy: 0.6615\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6736 - val_loss: 0.5846 - val_accuracy: 0.6615\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6736 - val_loss: 0.5841 - val_accuracy: 0.6615\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6736 - val_loss: 0.5835 - val_accuracy: 0.6615\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6771 - val_loss: 0.5830 - val_accuracy: 0.6615\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6771 - val_loss: 0.5824 - val_accuracy: 0.6615\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.6771 - val_loss: 0.5819 - val_accuracy: 0.6615\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6753 - val_loss: 0.5814 - val_accuracy: 0.6615\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.6788 - val_loss: 0.5808 - val_accuracy: 0.6615\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6771 - val_loss: 0.5803 - val_accuracy: 0.6615\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6771 - val_loss: 0.5798 - val_accuracy: 0.6615\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6771 - val_loss: 0.5793 - val_accuracy: 0.6615\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6788 - val_loss: 0.5788 - val_accuracy: 0.6615\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6788 - val_loss: 0.5783 - val_accuracy: 0.6615\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.6788 - val_loss: 0.5778 - val_accuracy: 0.6615\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.6788 - val_loss: 0.5773 - val_accuracy: 0.6562\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.6788 - val_loss: 0.5768 - val_accuracy: 0.6562\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6806 - val_loss: 0.5763 - val_accuracy: 0.6562\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.6788 - val_loss: 0.5758 - val_accuracy: 0.6562\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6788 - val_loss: 0.5754 - val_accuracy: 0.6562\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.6823 - val_loss: 0.5749 - val_accuracy: 0.6562\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6823 - val_loss: 0.5744 - val_accuracy: 0.6562\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.6823 - val_loss: 0.5739 - val_accuracy: 0.6562\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6823 - val_loss: 0.5734 - val_accuracy: 0.6562\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.6823 - val_loss: 0.5730 - val_accuracy: 0.6562\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6823 - val_loss: 0.5725 - val_accuracy: 0.6562\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.6840 - val_loss: 0.5720 - val_accuracy: 0.6562\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.6858 - val_loss: 0.5715 - val_accuracy: 0.6562\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6858 - val_loss: 0.5711 - val_accuracy: 0.6615\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.6858 - val_loss: 0.5706 - val_accuracy: 0.6615\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.6875 - val_loss: 0.5701 - val_accuracy: 0.6615\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.6875 - val_loss: 0.5696 - val_accuracy: 0.6615\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.6910 - val_loss: 0.5692 - val_accuracy: 0.6615\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.6910 - val_loss: 0.5687 - val_accuracy: 0.6615\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.6910 - val_loss: 0.5683 - val_accuracy: 0.6615\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.6910 - val_loss: 0.5678 - val_accuracy: 0.6615\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.6892 - val_loss: 0.5674 - val_accuracy: 0.6615\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.6892 - val_loss: 0.5669 - val_accuracy: 0.6615\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.6892 - val_loss: 0.5665 - val_accuracy: 0.6615\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.6910 - val_loss: 0.5661 - val_accuracy: 0.6615\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.6892 - val_loss: 0.5657 - val_accuracy: 0.6615\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.6910 - val_loss: 0.5653 - val_accuracy: 0.6615\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.6927 - val_loss: 0.5649 - val_accuracy: 0.6667\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6944 - val_loss: 0.5645 - val_accuracy: 0.6719\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.6944 - val_loss: 0.5640 - val_accuracy: 0.6719\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.6979 - val_loss: 0.5636 - val_accuracy: 0.6719\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.6979 - val_loss: 0.5632 - val_accuracy: 0.6719\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.6997 - val_loss: 0.5628 - val_accuracy: 0.6719\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7049 - val_loss: 0.5625 - val_accuracy: 0.6719\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7031 - val_loss: 0.5621 - val_accuracy: 0.6719\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7049 - val_loss: 0.5617 - val_accuracy: 0.6719\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7049 - val_loss: 0.5613 - val_accuracy: 0.6719\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7066 - val_loss: 0.5609 - val_accuracy: 0.6719\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7066 - val_loss: 0.5605 - val_accuracy: 0.6771\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7101 - val_loss: 0.5601 - val_accuracy: 0.6771\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7135 - val_loss: 0.5597 - val_accuracy: 0.6771\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7153 - val_loss: 0.5594 - val_accuracy: 0.6771\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7170 - val_loss: 0.5590 - val_accuracy: 0.6771\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7170 - val_loss: 0.5586 - val_accuracy: 0.6771\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7170 - val_loss: 0.5583 - val_accuracy: 0.6823\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7170 - val_loss: 0.5579 - val_accuracy: 0.6823\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7135 - val_loss: 0.5576 - val_accuracy: 0.6823\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7153 - val_loss: 0.5572 - val_accuracy: 0.6823\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7118 - val_loss: 0.5569 - val_accuracy: 0.6875\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7118 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7135 - val_loss: 0.5562 - val_accuracy: 0.6875\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7135 - val_loss: 0.5559 - val_accuracy: 0.6875\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7135 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7135 - val_loss: 0.5552 - val_accuracy: 0.6875\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7135 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7153 - val_loss: 0.5546 - val_accuracy: 0.6823\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7153 - val_loss: 0.5542 - val_accuracy: 0.6823\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7153 - val_loss: 0.5539 - val_accuracy: 0.6823\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7153 - val_loss: 0.5536 - val_accuracy: 0.6823\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7135 - val_loss: 0.5533 - val_accuracy: 0.6823\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7101 - val_loss: 0.5530 - val_accuracy: 0.6823\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7135 - val_loss: 0.5526 - val_accuracy: 0.6875\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7118 - val_loss: 0.5523 - val_accuracy: 0.6875\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7118 - val_loss: 0.5520 - val_accuracy: 0.6875\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7118 - val_loss: 0.5516 - val_accuracy: 0.6875\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7118 - val_loss: 0.5513 - val_accuracy: 0.6875\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7118 - val_loss: 0.5510 - val_accuracy: 0.6875\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7135 - val_loss: 0.5506 - val_accuracy: 0.6823\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7135 - val_loss: 0.5503 - val_accuracy: 0.6823\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7135 - val_loss: 0.5500 - val_accuracy: 0.6823\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7153 - val_loss: 0.5497 - val_accuracy: 0.6823\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7153 - val_loss: 0.5493 - val_accuracy: 0.6823\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7153 - val_loss: 0.5490 - val_accuracy: 0.6823\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7153 - val_loss: 0.5487 - val_accuracy: 0.6823\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7153 - val_loss: 0.5484 - val_accuracy: 0.6823\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7153 - val_loss: 0.5481 - val_accuracy: 0.6823\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7153 - val_loss: 0.5478 - val_accuracy: 0.6771\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7188 - val_loss: 0.5475 - val_accuracy: 0.6771\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7205 - val_loss: 0.5472 - val_accuracy: 0.6771\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7205 - val_loss: 0.5469 - val_accuracy: 0.6771\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7240 - val_loss: 0.5466 - val_accuracy: 0.6771\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7205 - val_loss: 0.5463 - val_accuracy: 0.6771\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7240 - val_loss: 0.5460 - val_accuracy: 0.6771\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7240 - val_loss: 0.5457 - val_accuracy: 0.6771\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7257 - val_loss: 0.5454 - val_accuracy: 0.6771\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7274 - val_loss: 0.5451 - val_accuracy: 0.6771\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7274 - val_loss: 0.5448 - val_accuracy: 0.6823\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7274 - val_loss: 0.5445 - val_accuracy: 0.6823\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7274 - val_loss: 0.5442 - val_accuracy: 0.6823\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7274 - val_loss: 0.5439 - val_accuracy: 0.6823\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7257 - val_loss: 0.5436 - val_accuracy: 0.6823\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7292 - val_loss: 0.5433 - val_accuracy: 0.6823\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7309 - val_loss: 0.5430 - val_accuracy: 0.6823\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7309 - val_loss: 0.5427 - val_accuracy: 0.6823\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7326 - val_loss: 0.5424 - val_accuracy: 0.6823\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7326 - val_loss: 0.5421 - val_accuracy: 0.6823\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7326 - val_loss: 0.5418 - val_accuracy: 0.6823\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7344 - val_loss: 0.5415 - val_accuracy: 0.6771\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7344 - val_loss: 0.5412 - val_accuracy: 0.6771\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7344 - val_loss: 0.5409 - val_accuracy: 0.6771\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7344 - val_loss: 0.5406 - val_accuracy: 0.6771\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7344 - val_loss: 0.5403 - val_accuracy: 0.6771\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7344 - val_loss: 0.5401 - val_accuracy: 0.6771\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7344 - val_loss: 0.5398 - val_accuracy: 0.6771\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7344 - val_loss: 0.5395 - val_accuracy: 0.6771\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7344 - val_loss: 0.5392 - val_accuracy: 0.6771\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7344 - val_loss: 0.5389 - val_accuracy: 0.6771\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7344 - val_loss: 0.5387 - val_accuracy: 0.6771\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7344 - val_loss: 0.5384 - val_accuracy: 0.6771\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7344 - val_loss: 0.5381 - val_accuracy: 0.6771\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7344 - val_loss: 0.5379 - val_accuracy: 0.6771\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7344 - val_loss: 0.5376 - val_accuracy: 0.6771\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7344 - val_loss: 0.5373 - val_accuracy: 0.6823\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7326 - val_loss: 0.5371 - val_accuracy: 0.6823\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7361 - val_loss: 0.5368 - val_accuracy: 0.6823\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7378 - val_loss: 0.5366 - val_accuracy: 0.6875\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7326 - val_loss: 0.5363 - val_accuracy: 0.6875\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7344 - val_loss: 0.5361 - val_accuracy: 0.6875\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7361 - val_loss: 0.5358 - val_accuracy: 0.6927\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7361 - val_loss: 0.5356 - val_accuracy: 0.6927\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7396 - val_loss: 0.5353 - val_accuracy: 0.6927\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7361 - val_loss: 0.5351 - val_accuracy: 0.6927\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7378 - val_loss: 0.5348 - val_accuracy: 0.6927\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7378 - val_loss: 0.5346 - val_accuracy: 0.6927\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7396 - val_loss: 0.5344 - val_accuracy: 0.6927\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7378 - val_loss: 0.5341 - val_accuracy: 0.6927\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7448 - val_loss: 0.5339 - val_accuracy: 0.6927\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7448 - val_loss: 0.5337 - val_accuracy: 0.6927\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7448 - val_loss: 0.5335 - val_accuracy: 0.6927\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7448 - val_loss: 0.5332 - val_accuracy: 0.6979\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7465 - val_loss: 0.5330 - val_accuracy: 0.6979\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7465 - val_loss: 0.5328 - val_accuracy: 0.6979\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7465 - val_loss: 0.5326 - val_accuracy: 0.6979\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7483 - val_loss: 0.5323 - val_accuracy: 0.6979\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7483 - val_loss: 0.5321 - val_accuracy: 0.6979\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7500 - val_loss: 0.5319 - val_accuracy: 0.6979\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7500 - val_loss: 0.5317 - val_accuracy: 0.6979\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.5315 - val_accuracy: 0.6979\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.6979\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7483 - val_loss: 0.5310 - val_accuracy: 0.6979\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7483 - val_loss: 0.5308 - val_accuracy: 0.6979\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7483 - val_loss: 0.5306 - val_accuracy: 0.6979\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7483 - val_loss: 0.5303 - val_accuracy: 0.6979\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7483 - val_loss: 0.5301 - val_accuracy: 0.6979\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7483 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7483 - val_loss: 0.5297 - val_accuracy: 0.6979\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7483 - val_loss: 0.5295 - val_accuracy: 0.6979\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7483 - val_loss: 0.5292 - val_accuracy: 0.6979\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7483 - val_loss: 0.5290 - val_accuracy: 0.6979\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7500 - val_loss: 0.5288 - val_accuracy: 0.6979\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7517 - val_loss: 0.5286 - val_accuracy: 0.6979\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7517 - val_loss: 0.5284 - val_accuracy: 0.6979\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7517 - val_loss: 0.5282 - val_accuracy: 0.6979\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7517 - val_loss: 0.5279 - val_accuracy: 0.6979\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7517 - val_loss: 0.5277 - val_accuracy: 0.6979\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7535 - val_loss: 0.5275 - val_accuracy: 0.6979\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7535 - val_loss: 0.5273 - val_accuracy: 0.6979\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7535 - val_loss: 0.5271 - val_accuracy: 0.6979\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7535 - val_loss: 0.5269 - val_accuracy: 0.6979\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7535 - val_loss: 0.5267 - val_accuracy: 0.6979\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7552 - val_loss: 0.5265 - val_accuracy: 0.6979\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7569 - val_loss: 0.5263 - val_accuracy: 0.6979\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5261 - val_accuracy: 0.6979\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7569 - val_loss: 0.5260 - val_accuracy: 0.6979\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7569 - val_loss: 0.5258 - val_accuracy: 0.6979\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7569 - val_loss: 0.5256 - val_accuracy: 0.6979\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7569 - val_loss: 0.5254 - val_accuracy: 0.6979\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7587 - val_loss: 0.5252 - val_accuracy: 0.6979\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7587 - val_loss: 0.5250 - val_accuracy: 0.7031\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7587 - val_loss: 0.5248 - val_accuracy: 0.7031\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7587 - val_loss: 0.5246 - val_accuracy: 0.7031\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7587 - val_loss: 0.5244 - val_accuracy: 0.7031\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7031\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7031\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7031\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7031\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.5235 - val_accuracy: 0.7031\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5233 - val_accuracy: 0.7031\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7031\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7135\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.5228 - val_accuracy: 0.7083\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7083\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7135\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5220 - val_accuracy: 0.7135\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7188\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7188\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7188\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7188\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7188\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7188\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7188\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7188\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7188\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.5183 - val_accuracy: 0.7188\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.5181 - val_accuracy: 0.7240\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7240\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7240\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7240\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7778 - val_loss: 0.5173 - val_accuracy: 0.7240\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7240\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7778 - val_loss: 0.5170 - val_accuracy: 0.7240\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7795 - val_loss: 0.5169 - val_accuracy: 0.7240\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7778 - val_loss: 0.5168 - val_accuracy: 0.7240\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7240\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.5165 - val_accuracy: 0.7240\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7795 - val_loss: 0.5164 - val_accuracy: 0.7240\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7240\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7240\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7795 - val_loss: 0.5160 - val_accuracy: 0.7240\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7795 - val_loss: 0.5159 - val_accuracy: 0.7240\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7240\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7240\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.5155 - val_accuracy: 0.7240\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7795 - val_loss: 0.5154 - val_accuracy: 0.7240\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7240\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.5150 - val_accuracy: 0.7240\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7240\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7240\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7240\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7292\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7292\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7292\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7292\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7292\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7292\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.5136 - val_accuracy: 0.7292\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7292\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7292\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7292\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7812 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7292\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7292\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.5115 - val_accuracy: 0.7292\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7292\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.5113 - val_accuracy: 0.7292\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7292\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7344\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7344\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7344\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7344\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7344\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7344\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5089 - val_accuracy: 0.7344\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7344\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7396\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7847 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7448\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7344\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7344\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7344\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.5026 - val_accuracy: 0.7344\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7847 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7847 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7847 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7934 - val_loss: 0.4974 - val_accuracy: 0.7500\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7934 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7951 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.7448\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.4953 - val_accuracy: 0.7448\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7396\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7396\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7396\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7396\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7396\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7396\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7396\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7396\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7396\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7396\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7396\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7396\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.7396\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7396\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7396\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7396\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7396\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7396\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4927 - val_accuracy: 0.7396\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7396\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7396\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7396\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7396\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7917 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7917 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7917 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7344\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7344\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7344\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7344\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4904 - val_accuracy: 0.7344\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4905 - val_accuracy: 0.7344\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4906 - val_accuracy: 0.7344\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4907 - val_accuracy: 0.7344\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4908 - val_accuracy: 0.7344\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7344\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.4910 - val_accuracy: 0.7344\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4911 - val_accuracy: 0.7344\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7344\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7396\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7396\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4940 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "run_hist_model_1n = model_1n.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mrmb-lSdtDfN",
        "outputId": "1e9be1be-f556-451d-a2ef-93de5935c229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1n = model_1n.predict(X_test_norm)\n",
        "y_pred_class_model_1n = (y_pred_prob_model_1n >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QkQq0uEPuJfr",
        "outputId": "60822352-0435-4bdc-d808-d6e510378e8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.72666335],\n",
              "       [0.56874466],\n",
              "       [0.83608484],\n",
              "       [0.05594952],\n",
              "       [0.5474848 ],\n",
              "       [0.8061171 ],\n",
              "       [0.6446457 ],\n",
              "       [0.08658028],\n",
              "       [0.07595377],\n",
              "       [0.90766746]], dtype=float32)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_prob_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jtinq5fstmj4",
        "outputId": "2ee875ea-ed25-41e9-a5e9-6f864fe60ae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_class_model_1n[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "30JuS6TgutWr",
        "outputId": "39086984-dc76-4ea1-e416-1a30e88d07ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 0.750\n",
            "roc-auc is 0.811\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1n)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1n)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1n, 'new mode 1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qhvgY9a6zG32",
        "outputId": "cf605975-9eb7-49ee-80bc-b00078d2a59e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_hist_model_1n.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hkBOaxXizL-5",
        "outputId": "3864917a-33a6-48e8-bb5a-4370e406e076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x17e76e62800>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1n.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1n.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1n.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1n.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlDTP-7r03st"
      },
      "source": [
        "ข้อ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKa3-6vo1NY5",
        "outputId": "03d6dbda-83c5-4a08-ac45-333e546e723f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model_1nc = Sequential([\n",
        "    Dense(12, input_shape=X_train_norm.shape[1:], activation=\"relu\"),\n",
        "    Dense(12, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "model_1nc.summary()\n",
        "# compile new_model_1\n",
        "# model_1nc.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_1nc.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIz6BYz91WIx",
        "outputId": "032922d1-5adc-4ba9-b5eb-e53064f38678"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "run_hist_model_1nc = model_1nc.fit(X_train_norm, y_train, validation_data=(X_test_norm,y_test), epochs=1500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcufQ9u1Zn1",
        "outputId": "7ae066aa-fc19-4030-8ce4-857d7b2b2d28"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "y_pred_prob_model_1nc= model_1nc.predict(X_test_norm)\n",
        "y_pred_class_model_1nc = (y_pred_prob_model_1nc >= 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "0yhnpS_B1e7F",
        "outputId": "49aa2191-bb96-4fc9-c6df-ac233967eb36"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_model_1nc)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_model_1nc)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_model_1nc, 'new mode 1nCustom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anGBXOJd1g-7",
        "outputId": "a152f14a-66f8-4d04-bbb6-6ce338f8e4bd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "run_hist_model_1nc.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "jUfvnSU-1iS9",
        "outputId": "3b1ac63f-af47-46b0-8acb-3aedae687ca0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel dl_env_new1 is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_model_1nc.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_model_1nc.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "\n",
        "fig, ay = plt.subplots()\n",
        "ay.plot(run_hist_model_1nc.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
        "ay.plot(run_hist_model_1nc.history[\"val_accuracy\"],'b', marker='.', label=\"Validation Accuracy\")\n",
        "ay.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkYhvnPLUAIM"
      },
      "source": [
        "ตอบ ข้อ 2 จากการปรับโครงสร้าง model ที่มี (2 hidden layer) แบบ (layer ละ 6 node) เป็น (layer ละ 16 node) และปรับค่า (hyperparameters เช่น learning_rate,batch_size จาก 0.003,32 เป็น 0.0004,16) ทำให้สามารถ train model ได้ดรขึ้นโดยเทียบจาก accuracy จาก 75% เป็น 76.6% และจากกราฟ loss เทียบในช่วงค่าเดียวกัน มีค่า แคบและต่ำลง รวมถึง กราฟ accuracy มีลำดับเป็นขั้นบรรได จากก่อนหน้าที่ขึ้นลงไม่สม่ำเสมอ ทำให้เห็นว่า model มีการเรียนรู้ที่ดีขึ้นโดยจากการทดลองปรับโครงสร้างและ hyperparameters พบว่าเมื่อปรับ ให้ ใช้ batch_size ที่น้อยลง และ learning_rate ต่ำลงควบคู่กันททำให้ model สามารถเรียนรู้ได้ละเอียดขึ้นแต่อาจได้ค่าไม่ถึงหรือต่ำลง แต่ก็ทำให้ validation accuracy เข้าไกล้ train accuracy จึงทำการปรับให้ train accuracy ขึ้นพอสมควร โดยใช้ระบบ learning_rate คงที่ +/- นิดหน่อย และให้ hidden_layer มี node เพิ่มขึ้นทำให้ได้ valid accuracy ไกล้กับ train accuracy มากขึ้นใน scale ที่สูงขึ้น"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_env_new1",
      "language": "python",
      "name": "dl_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
